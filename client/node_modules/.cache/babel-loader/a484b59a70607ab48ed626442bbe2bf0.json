{"ast":null,"code":"import _slicedToArray from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _createClass from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _get from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _classCallCheck from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _inherits from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\n/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = this && this.__rest || function (s, e) {\n  var t = {};\n\n  for (var p in s) {\n    if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];\n  }\n\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\") for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n    if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];\n  }\n  return t;\n};\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\n\nvar ConvRNN2DCell = /*#__PURE__*/function (_RNNCell) {\n  _inherits(ConvRNN2DCell, _RNNCell);\n\n  var _super = _createSuper(ConvRNN2DCell);\n\n  function ConvRNN2DCell() {\n    _classCallCheck(this, ConvRNN2DCell);\n\n    return _super.apply(this, arguments);\n  }\n\n  return ConvRNN2DCell;\n}(RNNCell);\n/**\n * Base class for convolutional-recurrent layers.\n */\n\n\nvar ConvRNN2D = /*#__PURE__*/function (_RNN) {\n  _inherits(ConvRNN2D, _RNN);\n\n  var _super2 = _createSuper(ConvRNN2D);\n\n  function ConvRNN2D(args) {\n    var _this;\n\n    _classCallCheck(this, ConvRNN2D);\n\n    if (args.unroll) {\n      throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n    }\n\n    _this = _super2.call(this, args);\n    _this.inputSpec = [new InputSpec({\n      ndim: 5\n    })];\n    return _this;\n  }\n\n  _createClass(ConvRNN2D, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n\n      return tfc.tidy(function () {\n        if (_this2.cell.dropoutMask != null) {\n          tfc.dispose(_this2.cell.dropoutMask);\n          _this2.cell.dropoutMask = null;\n        }\n\n        if (_this2.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this2.cell.recurrentDropoutMask);\n          _this2.cell.recurrentDropoutMask = null;\n        }\n\n        if (kwargs && kwargs['constants']) {\n          throw new ValueError('ConvRNN2D cell does not support constants');\n        }\n\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(ConvRNN2D.prototype), \"call\", _this2).call(_this2, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      var outShape = this.computeSingleOutputShape(inputShape);\n\n      if (!this.returnSequences) {\n        outShape = [outShape[0]].concat(_toConsumableArray(outShape.slice(2)));\n      }\n\n      if (this.returnState) {\n        outShape = [outShape].concat(_toConsumableArray(Array(2).fill([inputShape[0]].concat(_toConsumableArray(outShape.slice(-3))))));\n      }\n\n      return outShape;\n    }\n  }, {\n    key: \"getInitialState\",\n    value: function getInitialState(inputs) {\n      var _this3 = this;\n\n      return tfc.tidy(function () {\n        var stateSize = _this3.cell.stateSize;\n        var inputShape = inputs.shape;\n\n        var outputShape = _this3.computeSingleOutputShape(inputShape);\n\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var initialState = tfc.zeros(stateShape);\n\n        if (Array.isArray(stateSize)) {\n          return Array(stateSize.length).fill(initialState);\n        }\n\n        return [initialState];\n      });\n    }\n  }, {\n    key: \"resetStates\",\n    value: function resetStates(states) {\n      var _this4 = this;\n\n      var training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      tfc.tidy(function () {\n        if (!_this4.stateful) {\n          throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n        }\n\n        var inputShape = _this4.inputSpec[0].shape;\n\n        var outputShape = _this4.computeSingleOutputShape(inputShape);\n\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var batchSize = inputShape[0];\n\n        if (batchSize == null) {\n          throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n        } // Initialize state if null.\n\n\n        if (_this4.getStates() == null) {\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_ = [tfc.zeros(stateShape)];\n          }\n        } else if (states == null) {\n          // Dispose old state tensors.\n          tfc.dispose(_this4.states_); // For stateful RNNs, fully dispose kept old states.\n\n          if (_this4.keptStates != null) {\n            tfc.dispose(_this4.keptStates);\n            _this4.keptStates = [];\n          }\n\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_[0] = tfc.zeros(stateShape);\n          }\n        } else {\n          if (!Array.isArray(states)) {\n            states = [states];\n          }\n\n          if (states.length !== _this4.states_.length) {\n            throw new ValueError(\"Layer \".concat(_this4.name, \" expects \").concat(_this4.states_.length, \" state(s), \") + \"but it received \".concat(states.length, \" state value(s). Input \") + \"received: \".concat(states));\n          }\n\n          if (training) {\n            // Store old state tensors for complete disposal later, i.e., during\n            // the next no-arg call to this method. We do not dispose the old\n            // states immediately because that BPTT (among other things) require\n            // them.\n            _this4.keptStates.push(_this4.states_.slice());\n          } else {\n            tfc.dispose(_this4.states_);\n          }\n\n          for (var index = 0; index < _this4.states_.length; ++index) {\n            var value = states[index];\n            var expectedShape = stateShape;\n\n            if (!util.arraysEqual(value.shape, expectedShape)) {\n              throw new ValueError(\"State \".concat(index, \" is incompatible with layer \").concat(_this4.name, \": \") + \"expected shape=\".concat(expectedShape, \", received shape=\").concat(value.shape));\n            }\n\n            _this4.states_[index] = value;\n          }\n        }\n\n        _this4.states_ = _this4.states_.map(function (state) {\n          return tfc.keep(state.clone());\n        });\n      });\n    }\n  }, {\n    key: \"computeSingleOutputShape\",\n    value: function computeSingleOutputShape(inputShape) {\n      var _this$cell = this.cell,\n          dataFormat = _this$cell.dataFormat,\n          filters = _this$cell.filters,\n          kernelSize = _this$cell.kernelSize,\n          padding = _this$cell.padding,\n          strides = _this$cell.strides,\n          dilationRate = _this$cell.dilationRate;\n      var isChannelsFirst = dataFormat === 'channelsFirst';\n      var h = inputShape[isChannelsFirst ? 3 : 2];\n      var w = inputShape[isChannelsFirst ? 4 : 3];\n      var hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n      var wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n      var outShape = [].concat(_toConsumableArray(inputShape.slice(0, 2)), _toConsumableArray(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]));\n      return outShape;\n    }\n  }]);\n\n  return ConvRNN2D;\n}(RNN);\n/** @nocollapse */\n\n\nConvRNN2D.className = 'ConvRNN2D';\nexport var ConvLSTM2DCell = /*#__PURE__*/function (_LSTMCell) {\n  _inherits(ConvLSTM2DCell, _LSTMCell);\n\n  var _super3 = _createSuper(ConvLSTM2DCell);\n\n  function ConvLSTM2DCell(args) {\n    var _this5;\n\n    _classCallCheck(this, ConvLSTM2DCell);\n\n    var filters = args.filters,\n        kernelSize = args.kernelSize,\n        strides = args.strides,\n        padding = args.padding,\n        dataFormat = args.dataFormat,\n        dilationRate = args.dilationRate;\n    _this5 = _super3.call(this, Object.assign({}, args, {\n      units: filters\n    }));\n    _this5.filters = filters;\n    assertPositiveInteger(_this5.filters, 'filters');\n    _this5.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n\n    _this5.kernelSize.forEach(function (size) {\n      return assertPositiveInteger(size, 'kernelSize');\n    });\n\n    _this5.strides = normalizeArray(strides || 1, 2, 'strides');\n\n    _this5.strides.forEach(function (stride) {\n      return assertPositiveInteger(stride, 'strides');\n    });\n\n    _this5.padding = padding || 'valid';\n    checkPaddingMode(_this5.padding);\n    _this5.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(_this5.dataFormat);\n    _this5.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n\n    _this5.dilationRate.forEach(function (rate) {\n      return assertPositiveInteger(rate, 'dilationRate');\n    });\n\n    return _this5;\n  }\n\n  _createClass(ConvLSTM2DCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      var _a;\n\n      inputShape = getExactlyOneShape(inputShape);\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n      if (inputShape[channelAxis] == null) {\n        throw new ValueError(\"The channel dimension of the input should be defined. \" + \"Found \".concat(inputShape[channelAxis]));\n      }\n\n      var inputDim = inputShape[channelAxis];\n      var numOfKernels = 4;\n      var kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n      this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      var recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n\n      if (this.useBias) {\n        var biasInitializer;\n\n        if (this.unitForgetBias) {\n          var init = this.biasInitializer;\n          var filters = this.filters;\n          biasInitializer = new (_a = /*#__PURE__*/function (_Initializer) {\n            _inherits(CustomInit, _Initializer);\n\n            var _super4 = _createSuper(CustomInit);\n\n            function CustomInit() {\n              _classCallCheck(this, CustomInit);\n\n              return _super4.apply(this, arguments);\n            }\n\n            _createClass(CustomInit, [{\n              key: \"apply\",\n              value: function apply(shape, dtype) {\n                var biasI = init.apply([filters]);\n                var biasF = tfc.ones([filters]);\n                var biasCAndO = init.apply([filters * 2]);\n                return K.concatenate([biasI, biasF, biasCAndO]);\n              }\n            }]);\n\n            return CustomInit;\n          }(Initializer),\n          /** @nocollapse */\n          _a.className = 'CustomInit', _a)();\n        } else {\n          biasInitializer = this.biasInitializer;\n        }\n\n        this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this6 = this;\n\n      return tfc.tidy(function () {\n        if (inputs.length !== 3) {\n          throw new ValueError(\"ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got \" + \"\".concat(inputs.length, \".\"));\n        }\n\n        var training = kwargs['training'] || false;\n        var x = inputs[0]; // Current input\n\n        var hTMinus1 = inputs[1]; // Previous memory state.\n\n        var cTMinus1 = inputs[2]; // Previous carry state.\n\n        var numOfKernels = 4;\n\n        if (0 < _this6.dropout && _this6.dropout < 1 && _this6.dropoutMask == null) {\n          _this6.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(x);\n            },\n            rate: _this6.dropout,\n            training: training,\n            count: numOfKernels\n          });\n        }\n\n        var dropoutMask = _this6.dropoutMask;\n\n        var applyDropout = function applyDropout(x, mask, index) {\n          if (!mask || !mask[index]) {\n            return x;\n          }\n\n          return tfc.mul(mask[index], x);\n        };\n\n        var xI = applyDropout(x, dropoutMask, 0);\n        var xF = applyDropout(x, dropoutMask, 1);\n        var xC = applyDropout(x, dropoutMask, 2);\n        var xO = applyDropout(x, dropoutMask, 3);\n\n        if (0 < _this6.recurrentDropout && _this6.recurrentDropout < 1 && _this6.recurrentDropoutMask == null) {\n          _this6.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(hTMinus1);\n            },\n            rate: _this6.recurrentDropout,\n            training: training,\n            count: numOfKernels\n          });\n        }\n\n        var recDropoutMask = _this6.recurrentDropoutMask;\n        var hI = applyDropout(hTMinus1, recDropoutMask, 0);\n        var hF = applyDropout(hTMinus1, recDropoutMask, 1);\n        var hC = applyDropout(hTMinus1, recDropoutMask, 2);\n        var hO = applyDropout(hTMinus1, recDropoutMask, 3);\n        var kernelChannelAxis = 3;\n\n        var _tfc$split = tfc.split(_this6.kernel.read(), numOfKernels, kernelChannelAxis),\n            _tfc$split2 = _slicedToArray(_tfc$split, 4),\n            kernelI = _tfc$split2[0],\n            kernelF = _tfc$split2[1],\n            kernelC = _tfc$split2[2],\n            kernelO = _tfc$split2[3];\n\n        var _ref = _this6.useBias ? tfc.split(_this6.bias.read(), numOfKernels) : [null, null, null, null],\n            _ref2 = _slicedToArray(_ref, 4),\n            biasI = _ref2[0],\n            biasF = _ref2[1],\n            biasC = _ref2[2],\n            biasO = _ref2[3];\n\n        xI = _this6.inputConv(xI, kernelI, biasI, _this6.padding);\n        xF = _this6.inputConv(xF, kernelF, biasF, _this6.padding);\n        xC = _this6.inputConv(xC, kernelC, biasC, _this6.padding);\n        xO = _this6.inputConv(xO, kernelO, biasO, _this6.padding);\n\n        var _tfc$split3 = tfc.split(_this6.recurrentKernel.read(), numOfKernels, kernelChannelAxis),\n            _tfc$split4 = _slicedToArray(_tfc$split3, 4),\n            recKernelI = _tfc$split4[0],\n            recKernelF = _tfc$split4[1],\n            recKernelC = _tfc$split4[2],\n            recKernelO = _tfc$split4[3];\n\n        hI = _this6.recurrentConv(hI, recKernelI);\n        hF = _this6.recurrentConv(hF, recKernelF);\n        hC = _this6.recurrentConv(hC, recKernelC);\n        hO = _this6.recurrentConv(hO, recKernelO);\n\n        var i = _this6.recurrentActivation.apply(tfc.add(xI, hI));\n\n        var f = _this6.recurrentActivation.apply(tfc.add(xF, hF));\n\n        var c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, _this6.activation.apply(tfc.add(xC, hC))));\n        var h = tfc.mul(_this6.recurrentActivation.apply(tfc.add(xO, hO)), _this6.activation.apply(c));\n        return [h, h, c];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var _a = _get(_getPrototypeOf(ConvLSTM2DCell.prototype), \"getConfig\", this).call(this),\n          _ = _a['units'],\n          baseConfig = __rest(_a, ['units']);\n\n      var config = {\n        filters: this.filters,\n        kernelSize: this.kernelSize,\n        padding: this.padding,\n        dataFormat: this.dataFormat,\n        dilationRate: this.dilationRate,\n        strides: this.strides\n      };\n      return Object.assign({}, baseConfig, config);\n    }\n  }, {\n    key: \"inputConv\",\n    value: function inputConv(x, w, b, padding) {\n      var out = tfc.conv2d(x, w, this.strides, padding || 'valid', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n\n      if (b) {\n        return K.biasAdd(out, b, this.dataFormat);\n      }\n\n      return out;\n    }\n  }, {\n    key: \"recurrentConv\",\n    value: function recurrentConv(x, w) {\n      var strides = 1;\n      return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n    }\n  }]);\n\n  return ConvLSTM2DCell;\n}(LSTMCell);\n/** @nocollapse */\n\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport var ConvLSTM2D = /*#__PURE__*/function (_ConvRNN2D) {\n  _inherits(ConvLSTM2D, _ConvRNN2D);\n\n  var _super5 = _createSuper(ConvLSTM2D);\n\n  function ConvLSTM2D(args) {\n    _classCallCheck(this, ConvLSTM2D);\n\n    var cell = new ConvLSTM2DCell(args);\n    return _super5.call(this, Object.assign({}, args, {\n      cell: cell\n    }));\n  }\n  /** @nocollapse */\n\n\n  _createClass(ConvLSTM2D, null, [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config);\n    }\n  }]);\n\n  return ConvLSTM2D;\n}(ConvRNN2D);\n/** @nocollapse */\n\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);","map":{"version":3,"sources":["../../src/layers/convolutional_recurrent.ts"],"names":[],"mappings":";;;;;;;;;AAAA;;;;;;;;AAQG;;;;;;;;;;;;;;AAEH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAgB,IAAhB,QAA2B,uBAA3B;AAGA,OAAO,KAAK,CAAZ,MAAmB,yBAAnB;AACA,SAAQ,eAAR,EAAyB,gBAAzB,QAAgD,WAAhD;AAEA,SAAQ,SAAR,QAAwB,oBAAxB;AACA,SAAQ,cAAR,EAAwB,mBAAxB,EAA6C,UAA7C,QAA8D,WAA9D;AACA,SAAQ,WAAR,QAA0B,iBAA1B;AAIA,SAAQ,gBAAR,EAA0B,cAA1B,QAA+C,qBAA/C;AACA,SAAQ,qBAAR,QAAoC,wBAApC;AACA,SAAQ,kBAAR,QAAiC,sBAAjC;AAEA,SAA0B,mBAA1B,EAA+C,QAA/C,EAA2F,GAA3F,EAAgG,OAAhG,QAAoJ,aAApJ;;IAsDe,a;;;;;;;;;;;;EAAsB,O;AA8BrC;;AAEG;;;IACG,S;;;;;AAMJ,qBAAY,IAAZ,EAAoC;AAAA;;AAAA;;AAClC,QAAI,IAAI,CAAC,MAAT,EAAiB;AACf,YAAM,IAAI,mBAAJ,CACF,oDADE,CAAN;AAED;;AAED,QAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAJ,EAA8B;AAC5B,YAAM,IAAI,mBAAJ,CACF,gEADE,CAAN;AAED;;AAED,+BAAM,IAAN;AAEA,UAAK,SAAL,GAAiB,CAAC,IAAI,SAAJ,CAAc;AAAC,MAAA,IAAI,EAAE;AAAP,KAAd,CAAD,CAAjB;AAbkC;AAcnC;;;;WAED,cAAK,MAAL,EAA8B,MAA9B,EAA4C;AAAA;;AAC1C,aAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;AACnB,YAAI,MAAI,CAAC,IAAL,CAAU,WAAV,IAAyB,IAA7B,EAAmC;AACjC,UAAA,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,IAAL,CAAU,WAAtB;AAEA,UAAA,MAAI,CAAC,IAAL,CAAU,WAAV,GAAwB,IAAxB;AACD;;AAED,YAAI,MAAI,CAAC,IAAL,CAAU,oBAAV,IAAkC,IAAtC,EAA4C;AAC1C,UAAA,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,IAAL,CAAU,oBAAtB;AAEA,UAAA,MAAI,CAAC,IAAL,CAAU,oBAAV,GAAiC,IAAjC;AACD;;AAED,YAAI,MAAM,IAAI,MAAM,CAAC,WAAD,CAApB,EAAmC;AACjC,gBAAM,IAAI,UAAJ,CAAe,2CAAf,CAAN;AACD;;AAED,YAAM,IAAI,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,MAAD,CAA3C;AAEA,YAAM,QAAQ,GAAG,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,UAAD,CAA/C;AAEA,YAAM,YAAY,GACd,MAAM,IAAI,IAAV,GAAiB,IAAjB,GAAwB,MAAM,CAAC,cAAD,CADlC;AAGA,uFAAkB,MAAlB,EAA0B;AAAC,UAAA,IAAI,EAAJ,IAAD;AAAO,UAAA,QAAQ,EAAR,QAAP;AAAiB,UAAA,YAAY,EAAZ;AAAjB,SAA1B;AACD,OAzBM,CAAP;AA0BD;;;WAED,4BAAmB,UAAnB,EAAoC;AAClC,UAAI,QAAQ,GAAU,KAAK,wBAAL,CAA8B,UAA9B,CAAtB;;AAEA,UAAI,CAAC,KAAK,eAAV,EAA2B;AACzB,QAAA,QAAQ,IAAI,QAAQ,CAAC,CAAD,CAAZ,4BAAoB,QAAQ,CAAC,KAAT,CAAe,CAAf,CAApB,EAAR;AACD;;AAED,UAAI,KAAK,WAAT,EAAsB;AACpB,QAAA,QAAQ,IACH,QADG,4BACU,KAAK,CAAC,CAAD,CAAL,CAAS,IAAT,EAAe,UAAU,CAAC,CAAD,CAAzB,4BAAiC,QAAQ,CAAC,KAAT,CAAe,CAAC,CAAhB,CAAjC,GADV,EAAR;AAED;;AAED,aAAO,QAAP;AACD;;;WAED,yBAAgB,MAAhB,EAAkC;AAAA;;AAChC,aAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;AAAA,YACZ,SADY,GACC,MAAI,CAAC,IADN,CACZ,SADY;AAGnB,YAAM,UAAU,GAAG,MAAM,CAAC,KAA1B;;AAEA,YAAM,WAAW,GAAG,MAAI,CAAC,wBAAL,CAA8B,UAA9B,CAApB;;AAEA,YAAM,UAAU,IAAI,WAAW,CAAC,CAAD,CAAf,4BAAuB,WAAW,CAAC,KAAZ,CAAkB,CAAlB,CAAvB,EAAhB;AAEA,YAAM,YAAY,GAAG,GAAG,CAAC,KAAJ,CAAU,UAAV,CAArB;;AAEA,YAAI,KAAK,CAAC,OAAN,CAAc,SAAd,CAAJ,EAA8B;AAC5B,iBAAO,KAAK,CAAC,SAAS,CAAC,MAAX,CAAL,CAAwB,IAAxB,CAA6B,YAA7B,CAAP;AACD;;AAED,eAAO,CAAC,YAAD,CAAP;AACD,OAhBM,CAAP;AAiBD;;;WAED,qBAAY,MAAZ,EAAsD;AAAA;;AAAA,UAAhB,QAAgB,uEAAL,KAAK;AACpD,MAAA,GAAG,CAAC,IAAJ,CAAS,YAAK;AACZ,YAAI,CAAC,MAAI,CAAC,QAAV,EAAoB;AAClB,gBAAM,IAAI,cAAJ,CACF,iEADE,CAAN;AAED;;AAED,YAAM,UAAU,GAAG,MAAI,CAAC,SAAL,CAAe,CAAf,EAAkB,KAArC;;AAEA,YAAM,WAAW,GAAG,MAAI,CAAC,wBAAL,CAA8B,UAA9B,CAApB;;AAEA,YAAM,UAAU,IAAI,WAAW,CAAC,CAAD,CAAf,4BAAuB,WAAW,CAAC,KAAZ,CAAkB,CAAlB,CAAvB,EAAhB;AAEA,YAAM,SAAS,GAAG,UAAU,CAAC,CAAD,CAA5B;;AAEA,YAAI,SAAS,IAAI,IAAjB,EAAuB;AACrB,gBAAM,IAAI,UAAJ,CACF,qEACA,0CADA,GAEA,2DAFA,GAGA,2DAHA,GAIA,2DAJA,GAKA,oDANE,CAAN;AAOD,SAtBW,CAwBZ;;;AACA,YAAI,MAAI,CAAC,SAAL,MAAoB,IAAxB,EAA8B;AAC5B,cAAI,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,CAAJ,EAAwC;AACtC,YAAA,MAAI,CAAC,OAAL,GAAe,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,GAApB,CAAwB;AAAA,qBAAM,GAAG,CAAC,KAAJ,CAAU,UAAV,CAAN;AAAA,aAAxB,CAAf;AACD,WAFD,MAEO;AACL,YAAA,MAAI,CAAC,OAAL,GAAe,CAAC,GAAG,CAAC,KAAJ,CAAU,UAAV,CAAD,CAAf;AACD;AACF,SAND,MAMO,IAAI,MAAM,IAAI,IAAd,EAAoB;AACzB;AACA,UAAA,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,OAAjB,EAFyB,CAIzB;;AACA,cAAI,MAAI,CAAC,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,YAAA,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,UAAjB;AACA,YAAA,MAAI,CAAC,UAAL,GAAkB,EAAlB;AACD;;AAED,cAAI,KAAK,CAAC,OAAN,CAAc,MAAI,CAAC,IAAL,CAAU,SAAxB,CAAJ,EAAwC;AACtC,YAAA,MAAI,CAAC,OAAL,GAAe,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,GAApB,CAAwB;AAAA,qBAAM,GAAG,CAAC,KAAJ,CAAU,UAAV,CAAN;AAAA,aAAxB,CAAf;AACD,WAFD,MAEO;AACL,YAAA,MAAI,CAAC,OAAL,CAAa,CAAb,IAAkB,GAAG,CAAC,KAAJ,CAAU,UAAV,CAAlB;AACD;AACF,SAfM,MAeA;AACL,cAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;AAC1B,YAAA,MAAM,GAAG,CAAC,MAAD,CAAT;AACD;;AAED,cAAI,MAAM,CAAC,MAAP,KAAkB,MAAI,CAAC,OAAL,CAAa,MAAnC,EAA2C;AACzC,kBAAM,IAAI,UAAJ,CACF,gBAAS,MAAI,CAAC,IAAd,sBAA8B,MAAI,CAAC,OAAL,CAAa,MAA3C,6CACmB,MAAM,CAAC,MAD1B,mDAEa,MAFb,CADE,CAAN;AAID;;AAED,cAAI,QAAJ,EAAc;AACZ;AACA;AACA;AACA;AACA,YAAA,MAAI,CAAC,UAAL,CAAgB,IAAhB,CAAqB,MAAI,CAAC,OAAL,CAAa,KAAb,EAArB;AACD,WAND,MAMO;AACL,YAAA,GAAG,CAAC,OAAJ,CAAY,MAAI,CAAC,OAAjB;AACD;;AAED,eAAK,IAAI,KAAK,GAAG,CAAjB,EAAoB,KAAK,GAAG,MAAI,CAAC,OAAL,CAAa,MAAzC,EAAiD,EAAE,KAAnD,EAA0D;AACxD,gBAAM,KAAK,GAAG,MAAM,CAAC,KAAD,CAApB;AAEA,gBAAM,aAAa,GAAG,UAAtB;;AAEA,gBAAI,CAAC,IAAI,CAAC,WAAL,CAAiB,KAAK,CAAC,KAAvB,EAA8B,aAA9B,CAAL,EAAmD;AACjD,oBAAM,IAAI,UAAJ,CACF,gBAAS,KAAT,yCAA6C,MAAI,CAAC,IAAlD,mCACkB,aADlB,8BAEI,KAAK,CAAC,KAFV,CADE,CAAN;AAID;;AAED,YAAA,MAAI,CAAC,OAAL,CAAa,KAAb,IAAsB,KAAtB;AACD;AACF;;AAED,QAAA,MAAI,CAAC,OAAL,GAAe,MAAI,CAAC,OAAL,CAAa,GAAb,CAAiB,UAAA,KAAK;AAAA,iBAAI,GAAG,CAAC,IAAJ,CAAS,KAAK,CAAC,KAAN,EAAT,CAAJ;AAAA,SAAtB,CAAf;AACD,OArFD;AAsFD;;;WAES,kCAAyB,UAAzB,EAA0C;AAAA,uBAE9C,KAAK,IAFyC;AAAA,UAC3C,UAD2C,cAC3C,UAD2C;AAAA,UAC/B,OAD+B,cAC/B,OAD+B;AAAA,UACtB,UADsB,cACtB,UADsB;AAAA,UACV,OADU,cACV,OADU;AAAA,UACD,OADC,cACD,OADC;AAAA,UACQ,YADR,cACQ,YADR;AAIlD,UAAM,eAAe,GAAG,UAAU,KAAK,eAAvC;AAEA,UAAM,CAAC,GAAG,UAAU,CAAC,eAAe,GAAG,CAAH,GAAO,CAAvB,CAApB;AACA,UAAM,CAAC,GAAG,UAAU,CAAC,eAAe,GAAG,CAAH,GAAO,CAAvB,CAApB;AAEA,UAAM,IAAI,GAAG,gBAAgB,CACzB,CADyB,EACtB,UAAU,CAAC,CAAD,CADY,EACP,OADO,EACE,OAAO,CAAC,CAAD,CADT,EACc,YAAY,CAAC,CAAD,CAD1B,CAA7B;AAEA,UAAM,IAAI,GAAG,gBAAgB,CACzB,CADyB,EACtB,UAAU,CAAC,CAAD,CADY,EACP,OADO,EACE,OAAO,CAAC,CAAD,CADT,EACc,YAAY,CAAC,CAAD,CAD1B,CAA7B;AAGA,UAAM,QAAQ,gCACT,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,CAApB,CADS,sBAER,eAAe,GAAG,CAAC,OAAD,EAAU,IAAV,EAAgB,IAAhB,CAAH,GAA2B,CAAC,IAAD,EAAO,IAAP,EAAa,OAAb,CAFlC,EAAd;AAKA,aAAO,QAAP;AACD;;;;EAnMqB,G;AACtB;;;AACO,SAAA,CAAA,SAAA,GAAY,WAAZ;AAuMT,WAAa,cAAb;AAAA;;AAAA;;AAWE,0BAAY,IAAZ,EAAoC;AAAA;;AAAA;;AAAA,QAEhC,OAFgC,GAQ9B,IAR8B,CAEhC,OAFgC;AAAA,QAGhC,UAHgC,GAQ9B,IAR8B,CAGhC,UAHgC;AAAA,QAIhC,OAJgC,GAQ9B,IAR8B,CAIhC,OAJgC;AAAA,QAKhC,OALgC,GAQ9B,IAR8B,CAKhC,OALgC;AAAA,QAMhC,UANgC,GAQ9B,IAR8B,CAMhC,UANgC;AAAA,QAOhC,YAPgC,GAQ9B,IAR8B,CAOhC,YAPgC;AAUlC,gCAAK,MAAA,CAAA,MAAA,CAAA,EAAA,EAAK,IAAL,EAAS;AAAE,MAAA,KAAK,EAAE;AAAT,KAAT,CAAL;AAEA,WAAK,OAAL,GAAe,OAAf;AACA,IAAA,qBAAqB,CAAC,OAAK,OAAN,EAAe,SAAf,CAArB;AAEA,WAAK,UAAL,GAAkB,cAAc,CAAC,UAAD,EAAa,CAAb,EAAgB,YAAhB,CAAhC;;AACA,WAAK,UAAL,CAAgB,OAAhB,CAAwB,UAAA,IAAI;AAAA,aAAI,qBAAqB,CAAC,IAAD,EAAO,YAAP,CAAzB;AAAA,KAA5B;;AAEA,WAAK,OAAL,GAAe,cAAc,CAAC,OAAO,IAAI,CAAZ,EAAe,CAAf,EAAkB,SAAlB,CAA7B;;AACA,WAAK,OAAL,CAAa,OAAb,CAAqB,UAAA,MAAM;AAAA,aAAI,qBAAqB,CAAC,MAAD,EAAS,SAAT,CAAzB;AAAA,KAA3B;;AAEA,WAAK,OAAL,GAAe,OAAO,IAAI,OAA1B;AACA,IAAA,gBAAgB,CAAC,OAAK,OAAN,CAAhB;AAEA,WAAK,UAAL,GAAkB,UAAU,IAAI,cAAhC;AACA,IAAA,eAAe,CAAC,OAAK,UAAN,CAAf;AAEA,WAAK,YAAL,GAAoB,cAAc,CAAC,YAAY,IAAI,CAAjB,EAAoB,CAApB,EAAuB,cAAvB,CAAlC;;AACA,WAAK,YAAL,CAAkB,OAAlB,CACI,UAAA,IAAI;AAAA,aAAI,qBAAqB,CAAC,IAAD,EAAO,cAAP,CAAzB;AAAA,KADR;;AA5BkC;AA8BnC;;AAzCH;AAAA;AAAA,WA2CS,eAAM,UAAN,EAA+B;;;AACpC,MAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;AAEA,UAAM,WAAW,GACb,KAAK,UAAL,KAAoB,eAApB,GAAsC,CAAtC,GAA0C,UAAU,CAAC,MAAX,GAAoB,CADlE;;AAGA,UAAI,UAAU,CAAC,WAAD,CAAV,IAA2B,IAA/B,EAAqC;AACnC,cAAM,IAAI,UAAJ,CACF,2EACS,UAAU,CAAC,WAAD,CADnB,CADE,CAAN;AAGD;;AAED,UAAM,QAAQ,GAAG,UAAU,CAAC,WAAD,CAA3B;AAEA,UAAM,YAAY,GAAG,CAArB;AAEA,UAAM,WAAW,GACb,KAAK,UAAL,CAAgB,MAAhB,CAAuB,CAAC,QAAD,EAAW,KAAK,OAAL,GAAe,YAA1B,CAAvB,CADJ;AAGA,WAAK,MAAL,GAAc,KAAK,SAAL,CACV,QADU,EACA,WADA,EACa,IADb,EACmB,KAAK,iBADxB,EAEV,KAAK,iBAFK,EAEc,IAFd,EAEoB,KAAK,gBAFzB,CAAd;AAIA,UAAM,oBAAoB,GACtB,KAAK,UAAL,CAAgB,MAAhB,CAAuB,CAAC,KAAK,OAAN,EAAe,KAAK,OAAL,GAAe,YAA9B,CAAvB,CADJ;AAGA,WAAK,eAAL,GAAuB,KAAK,SAAL,CACnB,kBADmB,EACC,oBADD,EACuB,IADvB,EAEnB,KAAK,oBAFc,EAEQ,KAAK,oBAFb,EAEmC,IAFnC,EAGnB,KAAK,mBAHc,CAAvB;;AAKA,UAAI,KAAK,OAAT,EAAkB;AAChB,YAAI,eAAJ;;AAEA,YAAI,KAAK,cAAT,EAAyB;AACvB,cAAM,IAAI,GAAG,KAAK,eAAlB;AAEA,cAAM,OAAO,GAAG,KAAK,OAArB;AAEA,UAAA,eAAe,GAAG,KAAI,EAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,qBAIpB,eAAM,KAAN,EAAoB,KAApB,EAAoC;AAClC,oBAAM,KAAK,GAAG,IAAI,CAAC,KAAL,CAAW,CAAC,OAAD,CAAX,CAAd;AACA,oBAAM,KAAK,GAAG,GAAG,CAAC,IAAJ,CAAS,CAAC,OAAD,CAAT,CAAd;AACA,oBAAM,SAAS,GAAG,IAAI,CAAC,KAAL,CAAW,CAAC,OAAO,GAAG,CAAX,CAAX,CAAlB;AACA,uBAAO,CAAC,CAAC,WAAF,CAAc,CAAC,KAAD,EAAQ,KAAR,EAAe,SAAf,CAAd,CAAP;AACD;AATmB;;AAAA;AAAA,YAA0B,WAA1B,CAAA;AACpB;AACO,UAAA,EAAA,CAAA,SAAA,GAAY,YAFC,EAUpB,EAVgB,GAAlB;AAWD,SAhBD,MAgBO;AACL,UAAA,eAAe,GAAG,KAAK,eAAvB;AACD;;AAED,aAAK,IAAL,GAAY,KAAK,SAAL,CACR,MADQ,EACA,CAAC,KAAK,OAAL,GAAe,YAAhB,CADA,EAC+B,IAD/B,EACqC,eADrC,EAER,KAAK,eAFG,EAEc,IAFd,EAEoB,KAAK,cAFzB,CAAZ;AAGD;;AAED,WAAK,KAAL,GAAa,IAAb;AACD;AAvGH;AAAA;AAAA,WAyGE,cAAK,MAAL,EAA2B,MAA3B,EAAyC;AAAA;;AACvC,aAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;AACnB,YAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;AACvB,gBAAM,IAAI,UAAJ,CACF,0EACG,MAAM,CAAC,MADV,MADE,CAAN;AAGD;;AAED,YAAM,QAAQ,GAAG,MAAM,CAAC,UAAD,CAAN,IAAsB,KAAvC;AAEA,YAAM,CAAC,GAAG,MAAM,CAAC,CAAD,CAAhB,CATmB,CASU;;AAC7B,YAAM,QAAQ,GAAG,MAAM,CAAC,CAAD,CAAvB,CAVmB,CAUU;;AAC7B,YAAM,QAAQ,GAAG,MAAM,CAAC,CAAD,CAAvB,CAXmB,CAWU;;AAE7B,YAAM,YAAY,GAAG,CAArB;;AAIA,YAAI,IAAI,MAAI,CAAC,OAAT,IAAoB,MAAI,CAAC,OAAL,GAAe,CAAnC,IAAwC,MAAI,CAAC,WAAL,IAAoB,IAAhE,EAAsE;AACpE,UAAA,MAAI,CAAC,WAAL,GAAmB,mBAAmB,CAAC;AAClB,YAAA,IAAI,EAAE;AAAA,qBAAM,GAAG,CAAC,QAAJ,CAAa,CAAb,CAAN;AAAA,aADY;AAElB,YAAA,IAAI,EAAE,MAAI,CAAC,OAFO;AAGlB,YAAA,QAAQ,EAAR,QAHkB;AAIlB,YAAA,KAAK,EAAE;AAJW,WAAD,CAAtC;AAMD;;AAED,YAAM,WAAW,GAAG,MAAI,CAAC,WAAzB;;AAEA,YAAM,YAAY,GACd,SADE,YACF,CAAC,CAAD,EAAgB,IAAhB,EAAoC,KAApC,EAAqD;AACnD,cAAI,CAAC,IAAD,IAAS,CAAC,IAAI,CAAC,KAAD,CAAlB,EAA2B;AACzB,mBAAO,CAAP;AACD;;AAED,iBAAO,GAAG,CAAC,GAAJ,CAAQ,IAAI,CAAC,KAAD,CAAZ,EAAqB,CAArB,CAAP;AACD,SAPL;;AASA,YAAI,EAAE,GAAG,YAAY,CAAC,CAAD,EAAI,WAAJ,EAAiB,CAAjB,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,CAAD,EAAI,WAAJ,EAAiB,CAAjB,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,CAAD,EAAI,WAAJ,EAAiB,CAAjB,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,CAAD,EAAI,WAAJ,EAAiB,CAAjB,CAArB;;AAEA,YAAI,IAAI,MAAI,CAAC,gBAAT,IAA6B,MAAI,CAAC,gBAAL,GAAwB,CAArD,IACA,MAAI,CAAC,oBAAL,IAA6B,IADjC,EACuC;AACrC,UAAA,MAAI,CAAC,oBAAL,GAA4B,mBAAmB,CAAC;AAClB,YAAA,IAAI,EAAE;AAAA,qBAAM,GAAG,CAAC,QAAJ,CAAa,QAAb,CAAN;AAAA,aADY;AAElB,YAAA,IAAI,EAAE,MAAI,CAAC,gBAFO;AAGlB,YAAA,QAAQ,EAAR,QAHkB;AAIlB,YAAA,KAAK,EAAE;AAJW,WAAD,CAA/C;AAMD;;AAED,YAAM,cAAc,GAAG,MAAI,CAAC,oBAA5B;AAEA,YAAI,EAAE,GAAG,YAAY,CAAC,QAAD,EAAW,cAAX,EAA2B,CAA3B,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,QAAD,EAAW,cAAX,EAA2B,CAA3B,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,QAAD,EAAW,cAAX,EAA2B,CAA3B,CAArB;AACA,YAAI,EAAE,GAAG,YAAY,CAAC,QAAD,EAAW,cAAX,EAA2B,CAA3B,CAArB;AAEA,YAAM,iBAAiB,GAAG,CAA1B;;AA3DmB,yBA8Df,GAAG,CAAC,KAAJ,CAAU,MAAI,CAAC,MAAL,CAAY,IAAZ,EAAV,EAA8B,YAA9B,EAA4C,iBAA5C,CA9De;AAAA;AAAA,YA6DZ,OA7DY;AAAA,YA6DH,OA7DG;AAAA,YA6DM,OA7DN;AAAA,YA6De,OA7Df;;AAAA,mBAgEgC,MAAI,CAAC,OAAL,GAC/C,GAAG,CAAC,KAAJ,CAAU,MAAI,CAAC,IAAL,CAAU,IAAV,EAAV,EAA4B,YAA5B,CAD+C,GAE/C,CAAC,IAAD,EAAO,IAAP,EAAa,IAAb,EAAmB,IAAnB,CAlEe;AAAA;AAAA,YAgEZ,KAhEY;AAAA,YAgEL,KAhEK;AAAA,YAgEE,KAhEF;AAAA,YAgES,KAhET;;AAoEnB,QAAA,EAAE,GAAG,MAAI,CAAC,SAAL,CAAe,EAAf,EAAmB,OAAnB,EAA4B,KAA5B,EAAmC,MAAI,CAAC,OAAxC,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,SAAL,CAAe,EAAf,EAAmB,OAAnB,EAA4B,KAA5B,EAAmC,MAAI,CAAC,OAAxC,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,SAAL,CAAe,EAAf,EAAmB,OAAnB,EAA4B,KAA5B,EAAmC,MAAI,CAAC,OAAxC,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,SAAL,CAAe,EAAf,EAAmB,OAAnB,EAA4B,KAA5B,EAAmC,MAAI,CAAC,OAAxC,CAAL;;AAvEmB,0BA0Ef,GAAG,CAAC,KAAJ,CACI,MAAI,CAAC,eAAL,CAAqB,IAArB,EADJ,EACiC,YADjC,EAC+C,iBAD/C,CA1Ee;AAAA;AAAA,YAyEZ,UAzEY;AAAA,YAyEA,UAzEA;AAAA,YAyEY,UAzEZ;AAAA,YAyEwB,UAzExB;;AA6EnB,QAAA,EAAE,GAAG,MAAI,CAAC,aAAL,CAAmB,EAAnB,EAAuB,UAAvB,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,aAAL,CAAmB,EAAnB,EAAuB,UAAvB,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,aAAL,CAAmB,EAAnB,EAAuB,UAAvB,CAAL;AACA,QAAA,EAAE,GAAG,MAAI,CAAC,aAAL,CAAmB,EAAnB,EAAuB,UAAvB,CAAL;;AAEA,YAAM,CAAC,GAAG,MAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,EAAZ,CAA/B,CAAV;;AACA,YAAM,CAAC,GAAG,MAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,EAAZ,CAA/B,CAAV;;AACA,YAAM,CAAC,GAAG,GAAG,CAAC,GAAJ,CACN,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,QAAX,CADM,EAEN,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,MAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,EAAZ,CAAtB,CAAX,CAFM,CAAV;AAGA,YAAM,CAAC,GAAG,GAAG,CAAC,GAAJ,CACN,MAAI,CAAC,mBAAL,CAAyB,KAAzB,CAA+B,GAAG,CAAC,GAAJ,CAAQ,EAAR,EAAY,EAAZ,CAA/B,CADM,EAEN,MAAI,CAAC,UAAL,CAAgB,KAAhB,CAAsB,CAAtB,CAFM,CAAV;AAIA,eAAO,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,CAAP;AACD,OA5FM,CAAP;AA6FD;AAvMH;AAAA;AAAA,WAyME,qBAAS;AACD,UAAA,EAAA,gFAAA;AAAA,UAAU,CAAV,GAAW,EAAX,CAAC,OAAD;AAAA,UAAa,UAAb,GAAa,MAAA,CAAA,EAAA,EAAA,CAAA,OAAA,CAAA,CAAb;;AAEN,UAAM,MAAM,GAAiC;AAC3C,QAAA,OAAO,EAAE,KAAK,OAD6B;AAE3C,QAAA,UAAU,EAAE,KAAK,UAF0B;AAG3C,QAAA,OAAO,EAAE,KAAK,OAH6B;AAI3C,QAAA,UAAU,EAAE,KAAK,UAJ0B;AAK3C,QAAA,YAAY,EAAE,KAAK,YALwB;AAM3C,QAAA,OAAO,EAAE,KAAK;AAN6B,OAA7C;AASA,aAAA,MAAA,CAAA,MAAA,CAAA,EAAA,EAAW,UAAX,EAA0B,MAA1B,CAAA;AACD;AAtNH;AAAA;AAAA,WAwNE,mBAAU,CAAV,EAAqB,CAArB,EAAgC,CAAhC,EAA4C,OAA5C,EAAiE;AAC/D,UAAM,GAAG,GAAG,GAAG,CAAC,MAAJ,CACR,CADQ,EACW,CADX,EAC8B,KAAK,OADnC,EAEP,OAAO,IAAI,OAFJ,EAGR,KAAK,UAAL,KAAoB,eAApB,GAAsC,MAAtC,GAA+C,MAHvC,EAIR,KAAK,YAJG,CAAZ;;AAMA,UAAI,CAAJ,EAAO;AACL,eAAO,CAAC,CAAC,OAAF,CAAU,GAAV,EAAe,CAAf,EAAkB,KAAK,UAAvB,CAAP;AACD;;AAED,aAAO,GAAP;AACD;AApOH;AAAA;AAAA,WAsOE,uBAAc,CAAd,EAAyB,CAAzB,EAAkC;AAChC,UAAM,OAAO,GAAG,CAAhB;AAEA,aAAO,GAAG,CAAC,MAAJ,CACH,CADG,EACgB,CADhB,EACmC,OADnC,EAC4C,MAD5C,EAEH,KAAK,UAAL,KAAoB,eAApB,GAAsC,MAAtC,GAA+C,MAF5C,CAAP;AAGD;AA5OH;;AAAA;AAAA,EAAoC,QAApC;AACE;;AACO,cAAA,CAAA,SAAA,GAAY,gBAAZ;AA6OT,GAAG,CAAC,aAAJ,CAAkB,aAAlB,CAAgC,cAAhC;AAKA,WAAa,UAAb;AAAA;;AAAA;;AAIE,sBAAY,IAAZ,EAAgC;AAAA;;AAC9B,QAAM,IAAI,GAAG,IAAI,cAAJ,CAAmB,IAAnB,CAAb;AAD8B,8BAGxB,MAAA,CAAA,MAAA,CAAA,EAAA,EAAI,IAAJ,EAAQ;AAAE,MAAA,IAAI,EAAJ;AAAF,KAAR,CAHwB;AAI/B;AAED;;;AAVF;AAAA;AAAA,WAWE,oBACI,GADJ,EAEI,MAFJ,EAEwC;AACtC,aAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;AACD;AAfH;;AAAA;AAAA,EAAgC,SAAhC;AACE;;AACO,UAAA,CAAA,SAAA,GAAY,YAAZ;AAgBT,GAAG,CAAC,aAAJ,CAAkB,aAAlB,CAAgC,UAAhC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\nclass ConvRNN2DCell extends RNNCell {\n}\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n    constructor(args) {\n        if (args.unroll) {\n            throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n        }\n        if (Array.isArray(args.cell)) {\n            throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n        }\n        super(args);\n        this.inputSpec = [new InputSpec({ ndim: 5 })];\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            if (this.cell.dropoutMask != null) {\n                tfc.dispose(this.cell.dropoutMask);\n                this.cell.dropoutMask = null;\n            }\n            if (this.cell.recurrentDropoutMask != null) {\n                tfc.dispose(this.cell.recurrentDropoutMask);\n                this.cell.recurrentDropoutMask = null;\n            }\n            if (kwargs && kwargs['constants']) {\n                throw new ValueError('ConvRNN2D cell does not support constants');\n            }\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            const initialState = kwargs == null ? null : kwargs['initialState'];\n            return super.call(inputs, { mask, training, initialState });\n        });\n    }\n    computeOutputShape(inputShape) {\n        let outShape = this.computeSingleOutputShape(inputShape);\n        if (!this.returnSequences) {\n            outShape = [outShape[0], ...outShape.slice(2)];\n        }\n        if (this.returnState) {\n            outShape =\n                [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n        }\n        return outShape;\n    }\n    getInitialState(inputs) {\n        return tfc.tidy(() => {\n            const { stateSize } = this.cell;\n            const inputShape = inputs.shape;\n            const outputShape = this.computeSingleOutputShape(inputShape);\n            const stateShape = [outputShape[0], ...outputShape.slice(2)];\n            const initialState = tfc.zeros(stateShape);\n            if (Array.isArray(stateSize)) {\n                return Array(stateSize.length).fill(initialState);\n            }\n            return [initialState];\n        });\n    }\n    resetStates(states, training = false) {\n        tfc.tidy(() => {\n            if (!this.stateful) {\n                throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n            }\n            const inputShape = this.inputSpec[0].shape;\n            const outputShape = this.computeSingleOutputShape(inputShape);\n            const stateShape = [outputShape[0], ...outputShape.slice(2)];\n            const batchSize = inputShape[0];\n            if (batchSize == null) {\n                throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' +\n                    'the batch size of your input tensors: \\n' +\n                    '- If using a Sequential model, specify the batch size by ' +\n                    'passing a `batchInputShape` option to your first layer.\\n' +\n                    '- If using the functional API, specify the batch size by ' +\n                    'passing a `batchShape` option to your Input layer.');\n            }\n            // Initialize state if null.\n            if (this.getStates() == null) {\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n                }\n                else {\n                    this.states_ = [tfc.zeros(stateShape)];\n                }\n            }\n            else if (states == null) {\n                // Dispose old state tensors.\n                tfc.dispose(this.states_);\n                // For stateful RNNs, fully dispose kept old states.\n                if (this.keptStates != null) {\n                    tfc.dispose(this.keptStates);\n                    this.keptStates = [];\n                }\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n                }\n                else {\n                    this.states_[0] = tfc.zeros(stateShape);\n                }\n            }\n            else {\n                if (!Array.isArray(states)) {\n                    states = [states];\n                }\n                if (states.length !== this.states_.length) {\n                    throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), ` +\n                        `but it received ${states.length} state value(s). Input ` +\n                        `received: ${states}`);\n                }\n                if (training) {\n                    // Store old state tensors for complete disposal later, i.e., during\n                    // the next no-arg call to this method. We do not dispose the old\n                    // states immediately because that BPTT (among other things) require\n                    // them.\n                    this.keptStates.push(this.states_.slice());\n                }\n                else {\n                    tfc.dispose(this.states_);\n                }\n                for (let index = 0; index < this.states_.length; ++index) {\n                    const value = states[index];\n                    const expectedShape = stateShape;\n                    if (!util.arraysEqual(value.shape, expectedShape)) {\n                        throw new ValueError(`State ${index} is incompatible with layer ${this.name}: ` +\n                            `expected shape=${expectedShape}, received shape=${value.shape}`);\n                    }\n                    this.states_[index] = value;\n                }\n            }\n            this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n        });\n    }\n    computeSingleOutputShape(inputShape) {\n        const { dataFormat, filters, kernelSize, padding, strides, dilationRate } = this.cell;\n        const isChannelsFirst = dataFormat === 'channelsFirst';\n        const h = inputShape[isChannelsFirst ? 3 : 2];\n        const w = inputShape[isChannelsFirst ? 4 : 3];\n        const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n        const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n        const outShape = [\n            ...inputShape.slice(0, 2),\n            ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n        ];\n        return outShape;\n    }\n}\n/** @nocollapse */\nConvRNN2D.className = 'ConvRNN2D';\nexport class ConvLSTM2DCell extends LSTMCell {\n    constructor(args) {\n        const { filters, kernelSize, strides, padding, dataFormat, dilationRate, } = args;\n        super(Object.assign({}, args, { units: filters }));\n        this.filters = filters;\n        assertPositiveInteger(this.filters, 'filters');\n        this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n        this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n        this.strides = normalizeArray(strides || 1, 2, 'strides');\n        this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n        this.padding = padding || 'valid';\n        checkPaddingMode(this.padding);\n        this.dataFormat = dataFormat || 'channelsLast';\n        checkDataFormat(this.dataFormat);\n        this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n        this.dilationRate.forEach(rate => assertPositiveInteger(rate, 'dilationRate'));\n    }\n    build(inputShape) {\n        var _a;\n        inputShape = getExactlyOneShape(inputShape);\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new ValueError(`The channel dimension of the input should be defined. ` +\n                `Found ${inputShape[channelAxis]}`);\n        }\n        const inputDim = inputShape[channelAxis];\n        const numOfKernels = 4;\n        const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n        this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            let biasInitializer;\n            if (this.unitForgetBias) {\n                const init = this.biasInitializer;\n                const filters = this.filters;\n                biasInitializer = new (_a = class CustomInit extends Initializer {\n                        apply(shape, dtype) {\n                            const biasI = init.apply([filters]);\n                            const biasF = tfc.ones([filters]);\n                            const biasCAndO = init.apply([filters * 2]);\n                            return K.concatenate([biasI, biasF, biasCAndO]);\n                        }\n                    },\n                    /** @nocollapse */\n                    _a.className = 'CustomInit',\n                    _a)();\n            }\n            else {\n                biasInitializer = this.biasInitializer;\n            }\n            this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            if (inputs.length !== 3) {\n                throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n                    `${inputs.length}.`);\n            }\n            const training = kwargs['training'] || false;\n            const x = inputs[0]; // Current input\n            const hTMinus1 = inputs[1]; // Previous memory state.\n            const cTMinus1 = inputs[2]; // Previous carry state.\n            const numOfKernels = 4;\n            if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n                this.dropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(x),\n                    rate: this.dropout,\n                    training,\n                    count: numOfKernels\n                });\n            }\n            const dropoutMask = this.dropoutMask;\n            const applyDropout = (x, mask, index) => {\n                if (!mask || !mask[index]) {\n                    return x;\n                }\n                return tfc.mul(mask[index], x);\n            };\n            let xI = applyDropout(x, dropoutMask, 0);\n            let xF = applyDropout(x, dropoutMask, 1);\n            let xC = applyDropout(x, dropoutMask, 2);\n            let xO = applyDropout(x, dropoutMask, 3);\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n                this.recurrentDropoutMask == null) {\n                this.recurrentDropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(hTMinus1),\n                    rate: this.recurrentDropout,\n                    training,\n                    count: numOfKernels\n                });\n            }\n            const recDropoutMask = this.recurrentDropoutMask;\n            let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n            let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n            let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n            let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n            const kernelChannelAxis = 3;\n            const [kernelI, kernelF, kernelC, kernelO] = tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n            const [biasI, biasF, biasC, biasO] = this.useBias ?\n                tfc.split(this.bias.read(), numOfKernels) :\n                [null, null, null, null];\n            xI = this.inputConv(xI, kernelI, biasI, this.padding);\n            xF = this.inputConv(xF, kernelF, biasF, this.padding);\n            xC = this.inputConv(xC, kernelC, biasC, this.padding);\n            xO = this.inputConv(xO, kernelO, biasO, this.padding);\n            const [recKernelI, recKernelF, recKernelC, recKernelO] = tfc.split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n            hI = this.recurrentConv(hI, recKernelI);\n            hF = this.recurrentConv(hF, recKernelF);\n            hC = this.recurrentConv(hC, recKernelC);\n            hO = this.recurrentConv(hO, recKernelO);\n            const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n            const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n            const c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n            const h = tfc.mul(this.recurrentActivation.apply(tfc.add(xO, hO)), this.activation.apply(c));\n            return [h, h, c];\n        });\n    }\n    getConfig() {\n        const _a = super.getConfig(), { 'units': _ } = _a, baseConfig = __rest(_a, ['units']);\n        const config = {\n            filters: this.filters,\n            kernelSize: this.kernelSize,\n            padding: this.padding,\n            dataFormat: this.dataFormat,\n            dilationRate: this.dilationRate,\n            strides: this.strides,\n        };\n        return Object.assign({}, baseConfig, config);\n    }\n    inputConv(x, w, b, padding) {\n        const out = tfc.conv2d(x, w, this.strides, (padding || 'valid'), this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n        if (b) {\n            return K.biasAdd(out, b, this.dataFormat);\n        }\n        return out;\n    }\n    recurrentConv(x, w) {\n        const strides = 1;\n        return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n    }\n}\n/** @nocollapse */\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport class ConvLSTM2D extends ConvRNN2D {\n    constructor(args) {\n        const cell = new ConvLSTM2DCell(args);\n        super(Object.assign({}, args, { cell }));\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config);\n    }\n}\n/** @nocollapse */\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);\n//# sourceMappingURL=convolutional_recurrent.js.map"]},"metadata":{},"sourceType":"module"}