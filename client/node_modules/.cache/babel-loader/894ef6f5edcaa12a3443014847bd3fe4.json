{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { Im2ColPackedProgram } from '../im2col_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\nimport { batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD } from './BatchMatMul_impl';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape'; // For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\n\nexport function conv2dByMatMul(_ref) {\n  var x = _ref.x,\n      filter = _ref.filter,\n      convInfo = _ref.convInfo,\n      backend = _ref.backend,\n      _ref$bias = _ref.bias,\n      bias = _ref$bias === void 0 ? null : _ref$bias,\n      _ref$preluActivationW = _ref.preluActivationWeights,\n      preluActivationWeights = _ref$preluActivationW === void 0 ? null : _ref$preluActivationW,\n      _ref$leakyreluAlpha = _ref.leakyreluAlpha,\n      leakyreluAlpha = _ref$leakyreluAlpha === void 0 ? 0 : _ref$leakyreluAlpha,\n      _ref$activation = _ref.activation,\n      activation = _ref$activation === void 0 ? null : _ref$activation;\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  var xShape = x.shape;\n  var xTexData = backend.texData.get(x.dataId);\n  var sharedMatMulDim = convInfo.inChannels;\n  var outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  var outerShapeFilter = convInfo.outChannels;\n  var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  var transposeA = false;\n  var transposeB = false;\n  var out;\n  var intermediates = []; // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n\n  var batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n  var reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n\n  if (batchMatMulWillBeUnpacked || !env().getBool('WEBGL_LAZILY_UNPACK') || !env().getBool('WEBGL_PACK_BINARY_OPERATIONS') || !reshapeWillBeExpensive) {\n    var targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] : xShape[0] * xShape[2] * xShape[3];\n    var xReshaped = reshape({\n      inputs: {\n        x: x\n      },\n      backend: backend,\n      attrs: {\n        shape: [1, targetShape, convInfo.inChannels]\n      }\n    });\n    var filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend: backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n    var result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA: transposeA,\n      transposeB: transposeB,\n      backend: backend,\n      bias: bias,\n      activation: activation,\n      preluActivationWeights: preluActivationWeights,\n      leakyreluAlpha: leakyreluAlpha\n    });\n    out = reshape({\n      inputs: {\n        x: result\n      },\n      backend: backend,\n      attrs: {\n        shape: convInfo.outShape\n      }\n    });\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  } else {\n    // Following optimization is specific to packed |x| with odd row count\n    // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n    // we avoid expensive packed 2x2 reshape by padding row count to next,\n    // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n    // even-rows tensor before the operation and, after the batchMatMul,\n    // fix the even-rows result to have odd number of rows.\n    var _targetShape = isChannelsLast ? xShape[0] * xShape[1] * (xShape[2] + 1) : xShape[0] * xShape[2] * (xShape[3] + 1);\n\n    var _xReshaped = {\n      dataId: x.dataId,\n      shape: [1, _targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    }; // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing row count, after batchMatMul->...->compileProgram leads to\n    // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even row count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n\n    var originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(webgl_util.isReshapeFree(xTexData.shape, _xReshaped.shape), function () {\n      return \"packed reshape \".concat(xTexData.shape, \" to \").concat(_xReshaped.shape, \" isn't free\");\n    });\n\n    var _filterReshaped = reshape({\n      inputs: {\n        x: filter\n      },\n      backend: backend,\n      attrs: {\n        shape: [1, convInfo.inChannels, convInfo.outChannels]\n      }\n    });\n\n    intermediates.push(_filterReshaped);\n    var pointwiseConv = batchMatMulImpl({\n      a: _xReshaped,\n      b: _filterReshaped,\n      backend: backend,\n      transposeA: transposeA,\n      transposeB: transposeB,\n      bias: bias,\n      activation: activation,\n      preluActivationWeights: preluActivationWeights,\n      leakyreluAlpha: leakyreluAlpha\n    });\n    var pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(pointwiseConvTexData.isPacked, function () {\n      return 'batchMatMul result is expected to be packed';\n    }); // Restore the input shape to original.\n\n    xTexData.shape = originalXTexDataShape; // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n\n    pointwiseConvTexData.shape = convInfo.outShape;\n    out = identity({\n      inputs: {\n        x: pointwiseConv\n      },\n      backend: backend\n    });\n    out.shape = convInfo.outShape;\n    intermediates.push(pointwiseConv);\n  }\n\n  for (var _i = 0, _intermediates = intermediates; _i < _intermediates.length; _i++) {\n    var i = _intermediates[_i];\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n} // Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\n\nexport function conv2dWithIm2Row(_ref2) {\n  var x = _ref2.x,\n      filter = _ref2.filter,\n      convInfo = _ref2.convInfo,\n      backend = _ref2.backend,\n      _ref2$bias = _ref2.bias,\n      bias = _ref2$bias === void 0 ? null : _ref2$bias,\n      _ref2$preluActivation = _ref2.preluActivationWeights,\n      preluActivationWeights = _ref2$preluActivation === void 0 ? null : _ref2$preluActivation,\n      _ref2$leakyreluAlpha = _ref2.leakyreluAlpha,\n      leakyreluAlpha = _ref2$leakyreluAlpha === void 0 ? 0 : _ref2$leakyreluAlpha,\n      _ref2$activation = _ref2.activation,\n      activation = _ref2$activation === void 0 ? null : _ref2$activation;\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  var filterWidth = convInfo.filterWidth,\n      filterHeight = convInfo.filterHeight,\n      inChannels = convInfo.inChannels,\n      outWidth = convInfo.outWidth,\n      outHeight = convInfo.outHeight,\n      dataFormat = convInfo.dataFormat;\n  var isChannelsLast = dataFormat === 'channelsLast';\n  var sharedDim = filterWidth * filterHeight * inChannels;\n  var numCols = outHeight * outWidth;\n  var x2ColShape = [sharedDim, numCols];\n  var transposeA = true;\n  var transposeB = false;\n  var intermediates = [];\n  var xSqueezed = reshape({\n    inputs: {\n      x: x\n    },\n    backend: backend,\n    attrs: {\n      shape: x.shape.slice(1)\n    }\n  });\n  var w2Row = reshape({\n    inputs: {\n      x: filter\n    },\n    backend: backend,\n    attrs: {\n      shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]\n    }\n  });\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n  var im2ColProgram = new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n  var im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32');\n  var im2ColReshaped = reshape({\n    inputs: {\n      x: im2Col\n    },\n    backend: backend,\n    attrs: {\n      shape: [1, x2ColShape[0], x2ColShape[1]]\n    }\n  });\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n  var hasBias = bias != null;\n  var hasPreluActivationWeights = preluActivationWeights != null;\n  var hasLeakyreluAlpha = activation === 'leakyrelu';\n  var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n  var matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  var inputs = [im2ColReshaped, w2Row];\n\n  if (bias) {\n    inputs.push(bias);\n  }\n\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n\n  if (hasLeakyreluAlpha) {\n    var $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n\n  var product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n  var outShape = isChannelsLast ? [1, outHeight, outWidth, convInfo.outChannels] : [1, convInfo.outChannels, outHeight, outWidth];\n  var out = reshape({\n    inputs: {\n      x: product\n    },\n    backend: backend,\n    attrs: {\n      shape: outShape\n    }\n  });\n  intermediates.push(product);\n\n  for (var _i2 = 0, _intermediates2 = intermediates; _i2 < _intermediates2.length; _i2++) {\n    var i = _intermediates2[_i2];\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}","map":{"version":3,"sources":["../../src/kernels/Conv2D_impl.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAsB,GAAtB,EAAuC,IAAvC,QAAkD,uBAAlD;AAGA,SAAQ,mBAAR,QAAkC,sBAAlC;AACA,SAAQ,4BAAR,QAA2C,oCAA3C;AACA,SAAQ,mBAAR,QAAkC,sBAAlC;AACA,OAAO,KAAK,UAAZ,MAA4B,eAA5B;AAEA,SAAQ,eAAR,EAAyB,2BAAzB,QAA2D,oBAA3D;AACA,SAAQ,QAAR,QAAuB,YAAvB;AACA,SAAQ,OAAR,QAAsB,WAAtB,C,CAaA;AACA;AACA;;AACA,OAAM,SAAU,cAAV,OASS;AAAA,MARb,CAQa,QARb,CAQa;AAAA,MAPb,MAOa,QAPb,MAOa;AAAA,MANb,QAMa,QANb,QAMa;AAAA,MALb,OAKa,QALb,OAKa;AAAA,uBAJb,IAIa;AAAA,MAJb,IAIa,0BAJN,IAIM;AAAA,mCAHb,sBAGa;AAAA,MAHb,sBAGa,sCAHY,IAGZ;AAAA,iCAFb,cAEa;AAAA,MAFb,cAEa,oCAFI,CAEJ;AAAA,6BADb,UACa;AAAA,MADb,UACa,gCADA,IACA;AACb;AACA;AACA,MAAM,MAAM,GAAG,CAAC,CAAC,KAAjB;AACA,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,CAAC,CAAC,MAAtB,CAAjB;AACA,MAAM,eAAe,GAAG,QAAQ,CAAC,UAAjC;AACA,MAAM,WAAW,GAAG,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAD,CAAlB,GAAwB,MAAM,CAAC,CAAD,CAAlD;AACA,MAAM,gBAAgB,GAAG,QAAQ,CAAC,WAAlC;AACA,MAAM,cAAc,GAAG,QAAQ,CAAC,UAAT,KAAwB,cAA/C;AACA,MAAM,UAAU,GAAG,KAAnB;AACA,MAAM,UAAU,GAAG,KAAnB;AAEA,MAAI,GAAJ;AACA,MAAM,aAAa,GAAiB,EAApC,CAba,CAeb;AACA;;AACA,MAAM,yBAAyB,GAC3B,CAAC,WAAW,KAAK,CAAhB,IAAqB,gBAAgB,KAAK,CAA3C,KACA,eAAe,GAAG,2BAFtB;AAGA,MAAM,sBAAsB,GAAG,MAAM,CAAC,CAAD,CAAN,GAAY,CAAZ,KAAkB,CAAlB,IAAuB,CAAC,CAAC,QAAQ,CAAC,QAAjE;;AAEA,MAAI,yBAAyB,IAAI,CAAC,GAAG,GAAG,OAAN,CAAc,qBAAd,CAA9B,IACA,CAAC,GAAG,GAAG,OAAN,CAAc,8BAAd,CADD,IAEA,CAAC,sBAFL,EAE6B;AAC3B,QAAM,WAAW,GAAG,cAAc,GAAG,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAD,CAAlB,GAAwB,MAAM,CAAC,CAAD,CAAjC,GACG,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAD,CAAlB,GAAwB,MAAM,CAAC,CAAD,CADnE;AAEA,QAAM,SAAS,GAAG,OAAO,CAAC;AACxB,MAAA,MAAM,EAAE;AAAC,QAAA,CAAC,EAAD;AAAD,OADgB;AAExB,MAAA,OAAO,EAAP,OAFwB;AAGxB,MAAA,KAAK,EAAE;AAAC,QAAA,KAAK,EAAE,CAAC,CAAD,EAAI,WAAJ,EAAiB,QAAQ,CAAC,UAA1B;AAAR;AAHiB,KAAD,CAAzB;AAKA,QAAM,cAAc,GAAG,OAAO,CAAC;AAC7B,MAAA,MAAM,EAAE;AAAC,QAAA,CAAC,EAAE;AAAJ,OADqB;AAE7B,MAAA,OAAO,EAAP,OAF6B;AAG7B,MAAA,KAAK,EAAE;AAAC,QAAA,KAAK,EAAE,CAAC,CAAD,EAAI,QAAQ,CAAC,UAAb,EAAyB,QAAQ,CAAC,WAAlC;AAAR;AAHsB,KAAD,CAA9B;AAKA,QAAM,MAAM,GAAG,eAAe,CAAC;AAC7B,MAAA,CAAC,EAAE,SAD0B;AAE7B,MAAA,CAAC,EAAE,cAF0B;AAG7B,MAAA,UAAU,EAAV,UAH6B;AAI7B,MAAA,UAAU,EAAV,UAJ6B;AAK7B,MAAA,OAAO,EAAP,OAL6B;AAM7B,MAAA,IAAI,EAAJ,IAN6B;AAO7B,MAAA,UAAU,EAAV,UAP6B;AAQ7B,MAAA,sBAAsB,EAAtB,sBAR6B;AAS7B,MAAA,cAAc,EAAd;AAT6B,KAAD,CAA9B;AAYA,IAAA,GAAG,GAAG,OAAO,CACT;AAAC,MAAA,MAAM,EAAE;AAAC,QAAA,CAAC,EAAE;AAAJ,OAAT;AAAsB,MAAA,OAAO,EAAP,OAAtB;AAA+B,MAAA,KAAK,EAAE;AAAC,QAAA,KAAK,EAAE,QAAQ,CAAC;AAAjB;AAAtC,KADS,CAAb;AAGA,IAAA,aAAa,CAAC,IAAd,CAAmB,SAAnB;AACA,IAAA,aAAa,CAAC,IAAd,CAAmB,cAAnB;AACA,IAAA,aAAa,CAAC,IAAd,CAAmB,MAAnB;AACD,GAjCD,MAiCO;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAM,YAAW,GAAG,cAAc,GAC9B,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAD,CAAlB,IAAyB,MAAM,CAAC,CAAD,CAAN,GAAY,CAArC,CAD8B,GAE9B,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAD,CAAlB,IAAyB,MAAM,CAAC,CAAD,CAAN,GAAY,CAArC,CAFJ;;AAGA,QAAM,UAAS,GAAe;AAC5B,MAAA,MAAM,EAAE,CAAC,CAAC,MADkB;AAE5B,MAAA,KAAK,EAAE,CAAC,CAAD,EAAI,YAAJ,EAAiB,QAAQ,CAAC,UAA1B,CAFqB;AAG5B,MAAA,KAAK,EAAE,CAAC,CAAC;AAHmB,KAA9B,CAZK,CAiBL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,QAAM,qBAAqB,GAAG,QAAQ,CAAC,KAAvC;AACA,IAAA,QAAQ,CAAC,KAAT,GAAiB,QAAQ,CAAC,KAAT,CAAe,KAAf,EAAjB;AACA,IAAA,QAAQ,CAAC,KAAT,CAAe,QAAQ,CAAC,KAAT,CAAe,MAAf,GAAwB,CAAvC;AACA,IAAA,IAAI,CAAC,MAAL,CACI,UAAU,CAAC,aAAX,CAAyB,QAAQ,CAAC,KAAlC,EAAyC,UAAS,CAAC,KAAnD,CADJ,EAEI;AAAA,sCAAwB,QAAQ,CAAC,KAAjC,iBACI,UAAS,CAAC,KADd;AAAA,KAFJ;;AAIA,QAAM,eAAc,GAAG,OAAO,CAAC;AAC7B,MAAA,MAAM,EAAE;AAAC,QAAA,CAAC,EAAE;AAAJ,OADqB;AAE7B,MAAA,OAAO,EAAP,OAF6B;AAG7B,MAAA,KAAK,EAAE;AAAC,QAAA,KAAK,EAAE,CAAC,CAAD,EAAI,QAAQ,CAAC,UAAb,EAAyB,QAAQ,CAAC,WAAlC;AAAR;AAHsB,KAAD,CAA9B;;AAKA,IAAA,aAAa,CAAC,IAAd,CAAmB,eAAnB;AACA,QAAM,aAAa,GAAG,eAAe,CAAC;AACpC,MAAA,CAAC,EAAE,UADiC;AAEpC,MAAA,CAAC,EAAE,eAFiC;AAGpC,MAAA,OAAO,EAAP,OAHoC;AAIpC,MAAA,UAAU,EAAV,UAJoC;AAKpC,MAAA,UAAU,EAAV,UALoC;AAMpC,MAAA,IAAI,EAAJ,IANoC;AAOpC,MAAA,UAAU,EAAV,UAPoC;AAQpC,MAAA,sBAAsB,EAAtB,sBARoC;AASpC,MAAA,cAAc,EAAd;AAToC,KAAD,CAArC;AAYA,QAAM,oBAAoB,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,aAAa,CAAC,MAAlC,CAA7B;AACA,IAAA,IAAI,CAAC,MAAL,CACI,oBAAoB,CAAC,QADzB,EAEI;AAAA,aAAM,6CAAN;AAAA,KAFJ,EAnDK,CAsDL;;AACA,IAAA,QAAQ,CAAC,KAAT,GAAiB,qBAAjB,CAvDK,CAwDL;AACA;;AACA,IAAA,oBAAoB,CAAC,KAArB,GAA6B,QAAQ,CAAC,QAAtC;AAEA,IAAA,GAAG,GAAG,QAAQ,CAAC;AAAC,MAAA,MAAM,EAAE;AAAC,QAAA,CAAC,EAAE;AAAJ,OAAT;AAA6B,MAAA,OAAO,EAAP;AAA7B,KAAD,CAAd;AACA,IAAA,GAAG,CAAC,KAAJ,GAAY,QAAQ,CAAC,QAArB;AAEA,IAAA,aAAa,CAAC,IAAd,CAAmB,aAAnB;AACD;;AAED,oCAAgB,aAAhB,oCAA+B;AAA1B,QAAM,CAAC,qBAAP;AACH,IAAA,OAAO,CAAC,6BAAR,CAAsC,CAAtC;AACD;;AAED,SAAO,GAAP;AACD,C,CAED;AACA;;AACA,OAAM,SAAU,gBAAV,QASS;AAAA,MARb,CAQa,SARb,CAQa;AAAA,MAPb,MAOa,SAPb,MAOa;AAAA,MANb,QAMa,SANb,QAMa;AAAA,MALb,OAKa,SALb,OAKa;AAAA,yBAJb,IAIa;AAAA,MAJb,IAIa,2BAJN,IAIM;AAAA,oCAHb,sBAGa;AAAA,MAHb,sBAGa,sCAHY,IAGZ;AAAA,mCAFb,cAEa;AAAA,MAFb,cAEa,qCAFI,CAEJ;AAAA,+BADb,UACa;AAAA,MADb,UACa,iCADA,IACA;AACb;AACA;AACA;AACA;AACA;AACA;AANa,MAQX,WARW,GAcT,QAdS,CAQX,WARW;AAAA,MASX,YATW,GAcT,QAdS,CASX,YATW;AAAA,MAUX,UAVW,GAcT,QAdS,CAUX,UAVW;AAAA,MAWX,QAXW,GAcT,QAdS,CAWX,QAXW;AAAA,MAYX,SAZW,GAcT,QAdS,CAYX,SAZW;AAAA,MAaX,UAbW,GAcT,QAdS,CAaX,UAbW;AAgBb,MAAM,cAAc,GAAG,UAAU,KAAK,cAAtC;AAEA,MAAM,SAAS,GAAG,WAAW,GAAG,YAAd,GAA6B,UAA/C;AACA,MAAM,OAAO,GAAG,SAAS,GAAG,QAA5B;AACA,MAAM,UAAU,GAAG,CAAC,SAAD,EAAY,OAAZ,CAAnB;AACA,MAAM,UAAU,GAAG,IAAnB;AACA,MAAM,UAAU,GAAG,KAAnB;AAEA,MAAM,aAAa,GAAiB,EAApC;AAEA,MAAM,SAAS,GACX,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAD;AAAD,KAAT;AAAc,IAAA,OAAO,EAAP,OAAd;AAAuB,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd;AAAR;AAA9B,GAAD,CADX;AAEA,MAAM,KAAK,GAAG,OAAO,CAAC;AACpB,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KADY;AAEpB,IAAA,OAAO,EAAP,OAFoB;AAGpB,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE,CAAC,CAAD,EAAI,SAAJ,EAAe,IAAI,CAAC,aAAL,CAAmB,MAAM,CAAC,KAA1B,IAAmC,SAAlD;AAAR;AAHa,GAAD,CAArB;AAMA,EAAA,aAAa,CAAC,IAAd,CAAmB,SAAnB;AACA,EAAA,aAAa,CAAC,IAAd,CAAmB,KAAnB;AAEA,MAAM,aAAa,GACf,IAAI,mBAAJ,CAAwB,UAAxB,EAAoC,SAAS,CAAC,KAA9C,EAAqD,QAArD,CADJ;AAEA,MAAM,MAAM,GAAG,OAAO,CAAC,eAAR,CAAwB,aAAxB,EAAuC,CAAC,SAAD,CAAvC,EAAoD,SAApD,CAAf;AACA,MAAM,cAAc,GAAG,OAAO,CAAC;AAC7B,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KADqB;AAE7B,IAAA,OAAO,EAAP,OAF6B;AAG7B,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE,CAAC,CAAD,EAAI,UAAU,CAAC,CAAD,CAAd,EAAmB,UAAU,CAAC,CAAD,CAA7B;AAAR;AAHsB,GAAD,CAA9B;AAMA,EAAA,aAAa,CAAC,IAAd,CAAmB,MAAnB;AACA,EAAA,aAAa,CAAC,IAAd,CAAmB,cAAnB;AAEA,MAAM,OAAO,GAAG,IAAI,IAAI,IAAxB;AACA,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAA5D;AACA,MAAM,iBAAiB,GAAG,UAAU,KAAK,WAAzC;AACA,MAAM,eAAe,GACjB,UAAU,GAAG,4BAA4B,CAAC,UAAD,EAAa,IAAb,CAA/B,GAAoD,IADlE;AAEA,MAAM,aAAa,GAAG,IAAI,mBAAJ,CAClB,cAAc,CAAC,KADG,EAElB,KAAK,CAAC,KAFY,EAGlB,CAAC,CAAD,EAAI,OAAJ,EAAa,QAAQ,CAAC,WAAtB,CAHkB,EAGkB,UAHlB,EAG8B,UAH9B,EAG0C,OAH1C,EAIlB,eAJkB,EAID,yBAJC,EAI0B,iBAJ1B,CAAtB;AAKA,MAAM,MAAM,GAAiB,CAAC,cAAD,EAAiB,KAAjB,CAA7B;;AACA,MAAI,IAAJ,EAAU;AACR,IAAA,MAAM,CAAC,IAAP,CAAY,IAAZ;AACD;;AACD,MAAI,yBAAJ,EAA+B;AAC7B,IAAA,MAAM,CAAC,IAAP,CAAY,sBAAZ;AACD;;AACD,MAAI,iBAAJ,EAAuB;AACrB,QAAM,eAAe,GAAG,OAAO,CAAC,cAAR,CACpB,EADoB,EAChB,SADgB,EAEpB,IAAI,CAAC,iBAAL,CAAuB,cAAvB,EAA0D,SAA1D,CAFoB,CAAxB;AAGA,IAAA,MAAM,CAAC,IAAP,CAAY,eAAZ;AACA,IAAA,aAAa,CAAC,IAAd,CAAmB,eAAnB;AACD;;AACD,MAAM,OAAO,GAAG,OAAO,CAAC,eAAR,CAAwB,aAAxB,EAAuC,MAAvC,EAA+C,SAA/C,CAAhB;AAEA,MAAM,QAAQ,GAAG,cAAc,GAC3B,CAAC,CAAD,EAAI,SAAJ,EAAe,QAAf,EAAyB,QAAQ,CAAC,WAAlC,CAD2B,GAE3B,CAAC,CAAD,EAAI,QAAQ,CAAC,WAAb,EAA0B,SAA1B,EAAqC,QAArC,CAFJ;AAGA,MAAM,GAAG,GACL,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAuB,IAAA,OAAO,EAAP,OAAvB;AAAgC,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE;AAAR;AAAvC,GAAD,CADX;AAGA,EAAA,aAAa,CAAC,IAAd,CAAmB,OAAnB;;AACA,sCAAgB,aAAhB,uCAA+B;AAA1B,QAAM,CAAC,uBAAP;AACH,IAAA,OAAO,CAAC,6BAAR,CAAsC,CAAtC;AACD;;AAED,SAAO,GAAP;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { Im2ColPackedProgram } from '../im2col_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\nimport { batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD } from './BatchMatMul_impl';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape';\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {\n    // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n    // result from 2D to 4D.\n    const xShape = x.shape;\n    const xTexData = backend.texData.get(x.dataId);\n    const sharedMatMulDim = convInfo.inChannels;\n    const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n    const outerShapeFilter = convInfo.outChannels;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const transposeA = false;\n    const transposeB = false;\n    let out;\n    const intermediates = [];\n    // TODO: Once reduction ops are packed, batchMatMul will always be packed\n    // and we can remove this condition.\n    const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) &&\n        sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n    const reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n    if (batchMatMulWillBeUnpacked || !env().getBool('WEBGL_LAZILY_UNPACK') ||\n        !env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ||\n        !reshapeWillBeExpensive) {\n        const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] :\n            xShape[0] * xShape[2] * xShape[3];\n        const xReshaped = reshape({\n            inputs: { x },\n            backend,\n            attrs: { shape: [1, targetShape, convInfo.inChannels] }\n        });\n        const filterReshaped = reshape({\n            inputs: { x: filter },\n            backend,\n            attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }\n        });\n        const result = batchMatMulImpl({\n            a: xReshaped,\n            b: filterReshaped,\n            transposeA,\n            transposeB,\n            backend,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n        out = reshape({ inputs: { x: result }, backend, attrs: { shape: convInfo.outShape } });\n        intermediates.push(xReshaped);\n        intermediates.push(filterReshaped);\n        intermediates.push(result);\n    }\n    else {\n        // Following optimization is specific to packed |x| with odd row count\n        // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n        // we avoid expensive packed 2x2 reshape by padding row count to next,\n        // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n        // the same (has the same texture layout and and values in the texture) as\n        // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n        // even-rows tensor before the operation and, after the batchMatMul,\n        // fix the even-rows result to have odd number of rows.\n        const targetShape = isChannelsLast ?\n            xShape[0] * xShape[1] * (xShape[2] + 1) :\n            xShape[0] * xShape[2] * (xShape[3] + 1);\n        const xReshaped = {\n            dataId: x.dataId,\n            shape: [1, targetShape, convInfo.inChannels],\n            dtype: x.dtype\n        };\n        // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n        // Decrementing row count, after batchMatMul->...->compileProgram leads to\n        // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n        // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n        // in compileProgram method, but that would affect compilation of all\n        // programs - instead, provide a copy here, with even row count, before\n        // calling batchMatMul->...->compileProgram and after that, the original\n        // xTexData.shape is restored.\n        const originalXTexDataShape = xTexData.shape;\n        xTexData.shape = xTexData.shape.slice();\n        xTexData.shape[xTexData.shape.length - 2]++;\n        util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);\n        const filterReshaped = reshape({\n            inputs: { x: filter },\n            backend,\n            attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }\n        });\n        intermediates.push(filterReshaped);\n        const pointwiseConv = batchMatMulImpl({\n            a: xReshaped,\n            b: filterReshaped,\n            backend,\n            transposeA,\n            transposeB,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n        const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n        util.assert(pointwiseConvTexData.isPacked, () => 'batchMatMul result is expected to be packed');\n        // Restore the input shape to original.\n        xTexData.shape = originalXTexDataShape;\n        // Set the output shape - there is no need for expensive reshape as data\n        // layout is already correct.\n        pointwiseConvTexData.shape = convInfo.outShape;\n        out = identity({ inputs: { x: pointwiseConv }, backend });\n        out.shape = convInfo.outShape;\n        intermediates.push(pointwiseConv);\n    }\n    for (const i of intermediates) {\n        backend.disposeIntermediateTensorInfo(i);\n    }\n    return out;\n}\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {\n    // Rearranges conv2d input so each block to be convolved over forms the\n    // column of a new matrix with shape [filterWidth * filterHeight *\n    // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n    // output channel forms a row of a new matrix with shape [outChannels,\n    // filterWidth * filterHeight * inChannels]. The convolution is then\n    // computed by multiplying these matrices and reshaping the result.\n    const { filterWidth, filterHeight, inChannels, outWidth, outHeight, dataFormat } = convInfo;\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const sharedDim = filterWidth * filterHeight * inChannels;\n    const numCols = outHeight * outWidth;\n    const x2ColShape = [sharedDim, numCols];\n    const transposeA = true;\n    const transposeB = false;\n    const intermediates = [];\n    const xSqueezed = reshape({ inputs: { x }, backend, attrs: { shape: x.shape.slice(1) } });\n    const w2Row = reshape({\n        inputs: { x: filter },\n        backend,\n        attrs: { shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim] }\n    });\n    intermediates.push(xSqueezed);\n    intermediates.push(w2Row);\n    const im2ColProgram = new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n    const im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32');\n    const im2ColReshaped = reshape({\n        inputs: { x: im2Col },\n        backend,\n        attrs: { shape: [1, x2ColShape[0], x2ColShape[1]] }\n    });\n    intermediates.push(im2Col);\n    intermediates.push(im2ColReshaped);\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n    const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const inputs = [im2ColReshaped, w2Row];\n    if (bias) {\n        inputs.push(bias);\n    }\n    if (hasPreluActivationWeights) {\n        inputs.push(preluActivationWeights);\n    }\n    if (hasLeakyreluAlpha) {\n        const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n        inputs.push($leakyreluAlpha);\n        intermediates.push($leakyreluAlpha);\n    }\n    const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n    const outShape = isChannelsLast ?\n        [1, outHeight, outWidth, convInfo.outChannels] :\n        [1, convInfo.outChannels, outHeight, outWidth];\n    const out = reshape({ inputs: { x: product }, backend, attrs: { shape: outShape } });\n    intermediates.push(product);\n    for (const i of intermediates) {\n        backend.disposeIntermediateTensorInfo(i);\n    }\n    return out;\n}\n//# sourceMappingURL=Conv2D_impl.js.map"]},"metadata":{},"sourceType":"module"}