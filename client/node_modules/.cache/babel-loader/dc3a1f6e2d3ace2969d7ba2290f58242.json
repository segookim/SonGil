{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\n\nfunction broadcastTo_(x, shape) {\n  var input = convertToTensor(x, 'broadcastTo', 'x');\n  var xShape = input.shape;\n\n  if (shape.some(function (d) {\n    return !(d > 0) || d % 1 !== 0;\n  })) {\n    throw new Error(\"broadcastTo(): Invalid broadcast shape [\".concat(shape, \"].\"));\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(\"broadcastTo(): shape.length=\".concat(shape.length, \" < input.rank=\").concat(input.rank, \".\"));\n  }\n\n  if (shape.length > input.rank) {\n    var newShape = input.shape.slice();\n\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n\n    input = reshape(input, newShape);\n  }\n\n  var inputShape = input.shape;\n  var reps = Array.from(shape);\n\n  for (var i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(\"broadcastTo(): [\".concat(xShape, \"] cannot be broadcast to [\").concat(shape, \"].\"));\n    }\n  }\n\n  var axes = reps.map(function (n, i) {\n    return n > 1 ? i : -1;\n  }).filter(function (i) {\n    return i >= 0;\n  });\n\n  if (axes.length === 0) {\n    return clone(input);\n  } // TODO call broadcastTo kernel directly once backends implement broadcstTo\n\n\n  var inputs = {\n    x: input\n  };\n  var attrs = {\n    reps: reps\n  };\n  return ENGINE.runKernel(Tile, inputs, attrs);\n}\n\nexport var broadcastTo = op({\n  broadcastTo_: broadcastTo_\n});","map":{"version":3,"sources":["../../src/ops/broadcast_to.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,IAAR,QAA0C,iBAA1C;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,KAAR,QAAoB,SAApB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AAEA;;;;;;;;;;;;;AAaG;;AACH,SAAS,YAAT,CACI,CADJ,EAC0B,KAD1B,EAC4C;AAC1C,MAAI,KAAK,GAAG,eAAe,CAAC,CAAD,EAAI,aAAJ,EAAmB,GAAnB,CAA3B;AACA,MAAM,MAAM,GAAG,KAAK,CAAC,KAArB;;AAEA,MAAI,KAAK,CAAC,IAAN,CAAW,UAAA,CAAC;AAAA,WAAI,EAAE,CAAC,GAAG,CAAN,KAAY,CAAC,GAAG,CAAJ,KAAU,CAA1B;AAAA,GAAZ,CAAJ,EAA8C;AAC5C,UAAM,IAAI,KAAJ,mDAAqD,KAArD,QAAN;AACD;;AAED,MAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;AAC7B,UAAM,IAAI,KAAJ,uCAAyC,KAAK,CAAC,MAA/C,2BACF,KAAK,CAAC,IADJ,OAAN;AAED;;AAED,MAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;AAC7B,QAAM,QAAQ,GAAG,KAAK,CAAC,KAAN,CAAY,KAAZ,EAAjB;;AACA,WAAO,QAAQ,CAAC,MAAT,GAAkB,KAAK,CAAC,MAA/B,EAAuC;AACrC,MAAA,QAAQ,CAAC,OAAT,CAAiB,CAAjB;AACD;;AACD,IAAA,KAAK,GAAG,OAAO,CAAC,KAAD,EAAQ,QAAR,CAAf;AACD;;AAED,MAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;AACA,MAAM,IAAI,GAAa,KAAK,CAAC,IAAN,CAAW,KAAX,CAAvB;;AACA,OAAK,IAAI,CAAC,GAAG,KAAK,CAAC,MAAN,GAAe,CAA5B,EAA+B,CAAC,IAAI,CAApC,EAAuC,CAAC,EAAxC,EAA4C;AAC1C,QAAI,UAAU,CAAC,CAAD,CAAV,KAAkB,KAAK,CAAC,CAAD,CAA3B,EAAgC;AAC9B,MAAA,IAAI,CAAC,CAAD,CAAJ,GAAU,CAAV;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,KAAN,CAAY,CAAZ,MAAmB,CAAvB,EAA0B;AAC/B,YAAM,IAAI,KAAJ,2BACiB,MADjB,uCACoD,KADpD,QAAN;AAED;AACF;;AACD,MAAM,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,GAAG,CAAJ,GAAQ,CAAR,GAAY,CAAC,CAAvB;AAAA,GAAT,EAAmC,MAAnC,CAA0C,UAAA,CAAC;AAAA,WAAI,CAAC,IAAI,CAAT;AAAA,GAA3C,CAAb;;AAEA,MAAI,IAAI,CAAC,MAAL,KAAgB,CAApB,EAAuB;AACrB,WAAO,KAAK,CAAC,KAAD,CAAZ;AACD,GAnCyC,CAqC1C;;;AACA,MAAM,MAAM,GAAe;AAAC,IAAA,CAAC,EAAE;AAAJ,GAA3B;AACA,MAAM,KAAK,GAAc;AAAC,IAAA,IAAI,EAAJ;AAAD,GAAzB;AACA,SAAO,MAAM,CAAC,SAAP,CACH,IADG,EACG,MADH,EACmC,KADnC,CAAP;AAED;;AAED,OAAO,IAAM,WAAW,GAAG,EAAE,CAAC;AAAC,EAAA,YAAY,EAAZ;AAAD,CAAD,CAAtB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n    let input = convertToTensor(x, 'broadcastTo', 'x');\n    const xShape = input.shape;\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n    }\n    if (shape.length < input.rank) {\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n    }\n    if (shape.length > input.rank) {\n        const newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = reshape(input, newShape);\n    }\n    const inputShape = input.shape;\n    const reps = Array.from(shape);\n    for (let i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n        }\n    }\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n    if (axes.length === 0) {\n        return clone(input);\n    }\n    // TODO call broadcastTo kernel directly once backends implement broadcstTo\n    const inputs = { x: input };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const broadcastTo = op({ broadcastTo_ });\n//# sourceMappingURL=broadcast_to.js.map"]},"metadata":{},"sourceType":"module"}