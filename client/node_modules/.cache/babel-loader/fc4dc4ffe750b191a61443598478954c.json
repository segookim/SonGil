{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Optimizers.\n */\nimport { train } from '@tensorflow/tfjs-core';\nimport { epsilon } from './backend/common';\nimport { ValueError } from './errors'; // Add (de)serialize()\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\n\nexport function getOptimizer(identifier) {\n  var optimizerMap = {\n    'Adagrad': function Adagrad() {\n      return train.adagrad(0.01);\n    },\n    'Adadelta': function Adadelta() {\n      return train.adadelta(1, 0.95, epsilon());\n    },\n    'Adam': function Adam() {\n      return train.adam(0.001, 0.9, 0.999, epsilon());\n    },\n    'Adamax': function Adamax() {\n      return train.adamax(0.002, 0.9, 0.999, epsilon(), 0);\n    },\n    'RMSProp': function RMSProp() {\n      return train.rmsprop(0.001, 0.9, 0, epsilon());\n    },\n    'SGD': function SGD() {\n      return train.sgd(0.01);\n    }\n  };\n  optimizerMap['adagrad'] = optimizerMap['Adagrad'];\n  optimizerMap['adadelta'] = optimizerMap['Adadelta'];\n  optimizerMap['adam'] = optimizerMap['Adam'];\n  optimizerMap['adamax'] = optimizerMap['Adamax'];\n  optimizerMap['rmsprop'] = optimizerMap['RMSProp'];\n  optimizerMap['sgd'] = optimizerMap['SGD'];\n\n  if (identifier in optimizerMap) {\n    return optimizerMap[identifier]();\n  }\n\n  throw new ValueError(\"Unknown Optimizer \".concat(identifier));\n}","map":{"version":3,"sources":["../src/optimizers.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;AAEH;;AAEG;AAEH,SAAmB,KAAnB,QAA+B,uBAA/B;AAEA,SAAQ,OAAR,QAAsB,kBAAtB;AAEA,SAAQ,UAAR,QAAyB,UAAzB,C,CAEA;AAEA;AACA;;AACA,OAAM,SAAU,YAAV,CAAuB,UAAvB,EAAyC;AAC7C,MAAM,YAAY,GAA+C;AAC/D,eAAW;AAAA,aAAM,KAAK,CAAC,OAAN,CAAc,IAAd,CAAN;AAAA,KADoD;AAE/D,gBAAY;AAAA,aAAM,KAAK,CAAC,QAAN,CAAe,CAAf,EAAkB,IAAlB,EAAwB,OAAO,EAA/B,CAAN;AAAA,KAFmD;AAG/D,YAAQ;AAAA,aAAM,KAAK,CAAC,IAAN,CAAW,KAAX,EAAkB,GAAlB,EAAuB,KAAvB,EAA8B,OAAO,EAArC,CAAN;AAAA,KAHuD;AAI/D,cAAU;AAAA,aAAM,KAAK,CAAC,MAAN,CAAa,KAAb,EAAoB,GAApB,EAAyB,KAAzB,EAAgC,OAAO,EAAvC,EAA2C,CAA3C,CAAN;AAAA,KAJqD;AAK/D,eAAW;AAAA,aAAM,KAAK,CAAC,OAAN,CAAc,KAAd,EAAqB,GAArB,EAA0B,CAA1B,EAA6B,OAAO,EAApC,CAAN;AAAA,KALoD;AAM/D,WAAO;AAAA,aAAM,KAAK,CAAC,GAAN,CAAU,IAAV,CAAN;AAAA;AANwD,GAAjE;AAQA,EAAA,YAAY,CAAC,SAAD,CAAZ,GAA0B,YAAY,CAAC,SAAD,CAAtC;AACA,EAAA,YAAY,CAAC,UAAD,CAAZ,GAA2B,YAAY,CAAC,UAAD,CAAvC;AACA,EAAA,YAAY,CAAC,MAAD,CAAZ,GAAuB,YAAY,CAAC,MAAD,CAAnC;AACA,EAAA,YAAY,CAAC,QAAD,CAAZ,GAAyB,YAAY,CAAC,QAAD,CAArC;AACA,EAAA,YAAY,CAAC,SAAD,CAAZ,GAA0B,YAAY,CAAC,SAAD,CAAtC;AACA,EAAA,YAAY,CAAC,KAAD,CAAZ,GAAsB,YAAY,CAAC,KAAD,CAAlC;;AAEA,MAAI,UAAU,IAAI,YAAlB,EAAgC;AAC9B,WAAO,YAAY,CAAC,UAAD,CAAZ,EAAP;AACD;;AACD,QAAM,IAAI,UAAJ,6BAAoC,UAApC,EAAN;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Optimizers.\n */\nimport { train } from '@tensorflow/tfjs-core';\nimport { epsilon } from './backend/common';\nimport { ValueError } from './errors';\n// Add (de)serialize()\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\nexport function getOptimizer(identifier) {\n    const optimizerMap = {\n        'Adagrad': () => train.adagrad(0.01),\n        'Adadelta': () => train.adadelta(1, 0.95, epsilon()),\n        'Adam': () => train.adam(0.001, 0.9, 0.999, epsilon()),\n        'Adamax': () => train.adamax(0.002, 0.9, 0.999, epsilon(), 0),\n        'RMSProp': () => train.rmsprop(0.001, 0.9, 0, epsilon()),\n        'SGD': () => train.sgd(0.01)\n    };\n    optimizerMap['adagrad'] = optimizerMap['Adagrad'];\n    optimizerMap['adadelta'] = optimizerMap['Adadelta'];\n    optimizerMap['adam'] = optimizerMap['Adam'];\n    optimizerMap['adamax'] = optimizerMap['Adamax'];\n    optimizerMap['rmsprop'] = optimizerMap['RMSProp'];\n    optimizerMap['sgd'] = optimizerMap['SGD'];\n    if (identifier in optimizerMap) {\n        return optimizerMap[identifier]();\n    }\n    throw new ValueError(`Unknown Optimizer ${identifier}`);\n}\n//# sourceMappingURL=optimizers.js.map"]},"metadata":{},"sourceType":"module"}