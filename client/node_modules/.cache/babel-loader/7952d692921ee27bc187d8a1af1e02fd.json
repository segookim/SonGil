{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n// tslint:disable-next-line:max-line-length\nimport { Constant, GlorotNormal, GlorotUniform, HeNormal, HeUniform, Identity, LeCunNormal, LeCunUniform, Ones, Orthogonal, RandomNormal, RandomUniform, TruncatedNormal, VarianceScaling, Zeros } from './initializers';\n/**\n * Initializer that generates tensors initialized to 0.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function zeros() {\n  return new Zeros();\n}\n/**\n * Initializer that generates tensors initialized to 1.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function ones() {\n  return new Ones();\n}\n/**\n * Initializer that generates values initialized to some constant.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function constant(args) {\n  return new Constant(args);\n}\n/**\n * Initializer that generates random values initialized to a uniform\n * distribution.\n *\n * Values will be distributed uniformly between the configured minval and\n * maxval.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function randomUniform(args) {\n  return new RandomUniform(args);\n}\n/**\n * Initializer that generates random values initialized to a normal\n * distribution.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function randomNormal(args) {\n  return new RandomNormal(args);\n}\n/**\n * Initializer that generates random values initialized to a truncated normal.\n * distribution.\n *\n * These values are similar to values from a `RandomNormal` except that values\n * more than two standard deviations from the mean are discarded and re-drawn.\n * This is the recommended initializer for neural network weights and filters.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function truncatedNormal(args) {\n  return new TruncatedNormal(args);\n}\n/**\n * Initializer that generates the identity matrix.\n * Only use for square 2D matrices.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function identity(args) {\n  return new Identity(args);\n}\n/**\n * Initializer capable of adapting its scale to the shape of weights.\n * With distribution=NORMAL, samples are drawn from a truncated normal\n * distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n *   - number of input units in the weight tensor, if mode = FAN_IN.\n *   - number of output units, if mode = FAN_OUT.\n *   - average of the numbers of input and output units, if mode = FAN_AVG.\n * With distribution=UNIFORM,\n * samples are drawn from a uniform distribution\n * within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\n\nexport function varianceScaling(config) {\n  return new VarianceScaling(config);\n}\n/**\n * Glorot uniform initializer, also called Xavier uniform initializer.\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function glorotUniform(args) {\n  return new GlorotUniform(args);\n}\n/**\n * Glorot normal initializer, also called Xavier normal initializer.\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor.\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function glorotNormal(args) {\n  return new GlorotNormal(args);\n}\n/**\n * He normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function heNormal(args) {\n  return new HeNormal(args);\n}\n/**\n * He uniform initializer.\n *\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / fan_in)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\n\nexport function heUniform(args) {\n  return new HeUniform(args);\n}\n/**\n * LeCun normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(1 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * References:\n *   [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n *   [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function leCunNormal(args) {\n  return new LeCunNormal(args);\n}\n/**\n * LeCun uniform initializer.\n *\n * It draws samples from a uniform distribution in the interval\n * `[-limit, limit]` with `limit = sqrt(3 / fanIn)`,\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function leCunUniform(args) {\n  return new LeCunUniform(args);\n}\n/**\n * Initializer that generates a random orthogonal matrix.\n *\n * Reference:\n * [Saxe et al., http://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function orthogonal(args) {\n  return new Orthogonal(args);\n}","map":{"version":3,"sources":["../src/exports_initializers.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;AACH;AACA,SAAQ,QAAR,EAAgC,YAAhC,EAA8C,aAA9C,EAA6D,QAA7D,EAAuE,SAAvE,EAAkF,QAAlF,EAAuH,WAAvH,EAAoI,YAApI,EAAkJ,IAAlJ,EAAwJ,UAAxJ,EAAoL,YAApL,EAAoN,aAApN,EAA+Q,eAA/Q,EAAqT,eAArT,EAA2V,KAA3V,QAAuW,gBAAvW;AAEA;;;;AAIG;;AACH,OAAM,SAAU,KAAV,GAAe;AACnB,SAAO,IAAI,KAAJ,EAAP;AACD;AAED;;;;AAIG;;AACH,OAAM,SAAU,IAAV,GAAc;AAClB,SAAO,IAAI,IAAJ,EAAP;AACD;AAED;;;;AAIG;;AACH,OAAM,SAAU,QAAV,CAAmB,IAAnB,EAAqC;AACzC,SAAO,IAAI,QAAJ,CAAa,IAAb,CAAP;AACD;AAED;;;;;;;;AAQG;;AACH,OAAM,SAAU,aAAV,CAAwB,IAAxB,EAA+C;AACnD,SAAO,IAAI,aAAJ,CAAkB,IAAlB,CAAP;AACD;AAED;;;;;AAKG;;AACH,OAAM,SAAU,YAAV,CAAuB,IAAvB,EAA6C;AACjD,SAAO,IAAI,YAAJ,CAAiB,IAAjB,CAAP;AACD;AAED;;;;;;;;;AASG;;AACH,OAAM,SAAU,eAAV,CAA0B,IAA1B,EAAmD;AACvD,SAAO,IAAI,eAAJ,CAAoB,IAApB,CAAP;AACD;AAED;;;;;AAKG;;AACH,OAAM,SAAU,QAAV,CAAmB,IAAnB,EAAqC;AACzC,SAAO,IAAI,QAAJ,CAAa,IAAb,CAAP;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,eAAV,CAA0B,MAA1B,EAAqD;AACzD,SAAO,IAAI,eAAJ,CAAoB,MAApB,CAAP;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,aAAV,CAAwB,IAAxB,EAAqD;AACzD,SAAO,IAAI,aAAJ,CAAkB,IAAlB,CAAP;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,YAAV,CAAuB,IAAvB,EAAoD;AACxD,SAAO,IAAI,YAAJ,CAAiB,IAAjB,CAAP;AACD;AAED;;;;;;;;;;;AAWG;;AACH,OAAM,SAAU,QAAV,CAAmB,IAAnB,EAAgD;AACpD,SAAO,IAAI,QAAJ,CAAa,IAAb,CAAP;AACD;AAED;;;;;;;;;;;AAWG;;AACH,OAAM,SAAU,SAAV,CAAoB,IAApB,EAAiD;AACrD,SAAO,IAAI,SAAJ,CAAc,IAAd,CAAP;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,WAAV,CAAsB,IAAtB,EAAmD;AACvD,SAAO,IAAI,WAAJ,CAAgB,IAAhB,CAAP;AACD;AAED;;;;;;;;AAQG;;AACH,OAAM,SAAU,YAAV,CAAuB,IAAvB,EAAoD;AACxD,SAAO,IAAI,YAAJ,CAAiB,IAAjB,CAAP;AACD;AAED;;;;;;;AAOG;;AACH,OAAM,SAAU,UAAV,CAAqB,IAArB,EAAyC;AAC7C,SAAO,IAAI,UAAJ,CAAe,IAAf,CAAP;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n// tslint:disable-next-line:max-line-length\nimport { Constant, GlorotNormal, GlorotUniform, HeNormal, HeUniform, Identity, LeCunNormal, LeCunUniform, Ones, Orthogonal, RandomNormal, RandomUniform, TruncatedNormal, VarianceScaling, Zeros } from './initializers';\n/**\n * Initializer that generates tensors initialized to 0.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function zeros() {\n    return new Zeros();\n}\n/**\n * Initializer that generates tensors initialized to 1.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function ones() {\n    return new Ones();\n}\n/**\n * Initializer that generates values initialized to some constant.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function constant(args) {\n    return new Constant(args);\n}\n/**\n * Initializer that generates random values initialized to a uniform\n * distribution.\n *\n * Values will be distributed uniformly between the configured minval and\n * maxval.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function randomUniform(args) {\n    return new RandomUniform(args);\n}\n/**\n * Initializer that generates random values initialized to a normal\n * distribution.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function randomNormal(args) {\n    return new RandomNormal(args);\n}\n/**\n * Initializer that generates random values initialized to a truncated normal.\n * distribution.\n *\n * These values are similar to values from a `RandomNormal` except that values\n * more than two standard deviations from the mean are discarded and re-drawn.\n * This is the recommended initializer for neural network weights and filters.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function truncatedNormal(args) {\n    return new TruncatedNormal(args);\n}\n/**\n * Initializer that generates the identity matrix.\n * Only use for square 2D matrices.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function identity(args) {\n    return new Identity(args);\n}\n/**\n * Initializer capable of adapting its scale to the shape of weights.\n * With distribution=NORMAL, samples are drawn from a truncated normal\n * distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n *   - number of input units in the weight tensor, if mode = FAN_IN.\n *   - number of output units, if mode = FAN_OUT.\n *   - average of the numbers of input and output units, if mode = FAN_AVG.\n * With distribution=UNIFORM,\n * samples are drawn from a uniform distribution\n * within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\nexport function varianceScaling(config) {\n    return new VarianceScaling(config);\n}\n/**\n * Glorot uniform initializer, also called Xavier uniform initializer.\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function glorotUniform(args) {\n    return new GlorotUniform(args);\n}\n/**\n * Glorot normal initializer, also called Xavier normal initializer.\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor.\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function glorotNormal(args) {\n    return new GlorotNormal(args);\n}\n/**\n * He normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function heNormal(args) {\n    return new HeNormal(args);\n}\n/**\n * He uniform initializer.\n *\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / fan_in)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\nexport function heUniform(args) {\n    return new HeUniform(args);\n}\n/**\n * LeCun normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(1 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * References:\n *   [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n *   [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function leCunNormal(args) {\n    return new LeCunNormal(args);\n}\n/**\n * LeCun uniform initializer.\n *\n * It draws samples from a uniform distribution in the interval\n * `[-limit, limit]` with `limit = sqrt(3 / fanIn)`,\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function leCunUniform(args) {\n    return new LeCunUniform(args);\n}\n/**\n * Initializer that generates a random orthogonal matrix.\n *\n * Reference:\n * [Saxe et al., http://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function orthogonal(args) {\n    return new Orthogonal(args);\n}\n//# sourceMappingURL=exports_initializers.js.map"]},"metadata":{},"sourceType":"module"}