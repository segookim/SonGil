{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Dilation2DBackpropInput, util } from '@tensorflow/tfjs-core';\nexport var dilation2dBackpropInputConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: function kernelFunc(_ref) {\n    var inputs = _ref.inputs,\n        backend = _ref.backend,\n        attrs = _ref.attrs;\n    var x = inputs.x,\n        filter = inputs.filter,\n        dy = inputs.dy;\n    var strides = attrs.strides,\n        pad = attrs.pad,\n        dilations = attrs.dilations;\n    var cpuBackend = backend;\n    var $x = util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n    var $filter = util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n\n    var _backend_util$compute = backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC'\n    /* dataFormat */\n    , dilations),\n        batchSize = _backend_util$compute.batchSize,\n        inHeight = _backend_util$compute.inHeight,\n        inWidth = _backend_util$compute.inWidth,\n        inChannels = _backend_util$compute.inChannels,\n        outHeight = _backend_util$compute.outHeight,\n        outWidth = _backend_util$compute.outWidth,\n        padInfo = _backend_util$compute.padInfo,\n        strideHeight = _backend_util$compute.strideHeight,\n        strideWidth = _backend_util$compute.strideWidth,\n        filterHeight = _backend_util$compute.filterHeight,\n        filterWidth = _backend_util$compute.filterWidth,\n        dilationHeight = _backend_util$compute.dilationHeight,\n        dilationWidth = _backend_util$compute.dilationWidth,\n        outShape = _backend_util$compute.outShape;\n\n    util.assert(dy.rank === outShape.length, function () {\n      return \"Error in \".concat(Dilation2DBackpropInput, \", dy \") + \"must have the same rank as output \".concat(outShape.length, \", but got \") + \"\".concat(dy.rank);\n    });\n    var $dy = util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values); // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n\n    var gradients = util.makeZerosNestedTypedArray(x.shape, x.dtype); // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n\n    for (var b = 0; b < batchSize; ++b) {\n      for (var hOut = 0; hOut < outHeight; ++hOut) {\n        var hBeg = hOut * strideHeight - padInfo.top;\n\n        for (var wOut = 0; wOut < outWidth; ++wOut) {\n          var wBeg = wOut * strideWidth - padInfo.left;\n\n          for (var d = 0; d < inChannels; ++d) {\n            var curVal = Number.MIN_SAFE_INTEGER;\n            var hInMax = hBeg < 0 ? 0 : hBeg;\n            var wInMax = wBeg < 0 ? 0 : wBeg;\n\n            for (var h = 0; h < filterHeight; ++h) {\n              var hIn = hBeg + h * dilationHeight;\n\n              if (hIn >= 0 && hIn < inHeight) {\n                for (var w = 0; w < filterWidth; ++w) {\n                  var wIn = wBeg + w * dilationWidth;\n\n                  if (wIn >= 0 && wIn < inWidth) {\n                    var val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    var dataId = cpuBackend.write(util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n    return {\n      dataId: dataId,\n      shape: x.shape,\n      dtype: x.dtype\n    };\n  }\n};","map":{"version":3,"sources":["../../src/kernels/Dilation2DBackpropInput.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,EAAuC,uBAAvC,EAAgG,IAAhG,QAA2G,uBAA3G;AAKA,OAAO,IAAM,6BAA6B,GAAiB;AACzD,EAAA,UAAU,EAAE,uBAD6C;AAEzD,EAAA,WAAW,EAAE,KAF4C;AAGzD,EAAA,UAAU,EAAE,0BAA6B;AAAA,QAA3B,MAA2B,QAA3B,MAA2B;AAAA,QAAnB,OAAmB,QAAnB,OAAmB;AAAA,QAAV,KAAU,QAAV,KAAU;AAAA,QAChC,CADgC,GAEnC,MAFmC,CAChC,CADgC;AAAA,QAC7B,MAD6B,GAEnC,MAFmC,CAC7B,MAD6B;AAAA,QACrB,EADqB,GAEnC,MAFmC,CACrB,EADqB;AAAA,QAGhC,OAHgC,GAGL,KAHK,CAGhC,OAHgC;AAAA,QAGvB,GAHuB,GAGL,KAHK,CAGvB,GAHuB;AAAA,QAGlB,SAHkB,GAGL,KAHK,CAGlB,SAHkB;AAIvC,QAAM,UAAU,GAAG,OAAnB;AAEA,QAAM,EAAE,GACJ,IAAI,CAAC,aAAL,CACI,CAAC,CAAC,KADN,EACa,UAAU,CAAC,IAAX,CAAgB,GAAhB,CAAoB,CAAC,CAAC,MAAtB,EAA8B,MAD3C,CADJ;AAKA,QAAM,OAAO,GAAG,IAAI,CAAC,aAAL,CACI,MAAM,CAAC,KADX,EAEI,UAAU,CAAC,IAAX,CAAgB,GAAhB,CAAoB,MAAM,CAAC,MAA3B,EAAmC,MAFvC,CAAhB;;AAXuC,gCAgCnC,YAAY,CAAC,qBAAb,CACI,CAAC,CAAC,KADN,EAEI,MAAM,CAAC,KAFX,EAE8C,OAF9C,EAEuD,GAFvD,EAGI;AAAO;AAHX,MAG6B,SAH7B,CAhCmC;AAAA,QAiBrC,SAjBqC,yBAiBrC,SAjBqC;AAAA,QAkBrC,QAlBqC,yBAkBrC,QAlBqC;AAAA,QAmBrC,OAnBqC,yBAmBrC,OAnBqC;AAAA,QAoBrC,UApBqC,yBAoBrC,UApBqC;AAAA,QAqBrC,SArBqC,yBAqBrC,SArBqC;AAAA,QAsBrC,QAtBqC,yBAsBrC,QAtBqC;AAAA,QAuBrC,OAvBqC,yBAuBrC,OAvBqC;AAAA,QAwBrC,YAxBqC,yBAwBrC,YAxBqC;AAAA,QAyBrC,WAzBqC,yBAyBrC,WAzBqC;AAAA,QA0BrC,YA1BqC,yBA0BrC,YA1BqC;AAAA,QA2BrC,WA3BqC,yBA2BrC,WA3BqC;AAAA,QA4BrC,cA5BqC,yBA4BrC,cA5BqC;AAAA,QA6BrC,aA7BqC,yBA6BrC,aA7BqC;AAAA,QA8BrC,QA9BqC,yBA8BrC,QA9BqC;;AAqCvC,IAAA,IAAI,CAAC,MAAL,CACI,EAAE,CAAC,IAAH,KAAY,QAAQ,CAAC,MADzB,EAEI;AAAA,aAAM,mBAAY,uBAAZ,yDACmC,QAAQ,CAAC,MAD5C,4BAEC,EAAE,CAAC,IAFJ,CAAN;AAAA,KAFJ;AAMA,QAAM,GAAG,GACL,IAAI,CAAC,aAAL,CACI,QADJ,EACc,UAAU,CAAC,IAAX,CAAgB,GAAhB,CAAoB,EAAE,CAAC,MAAvB,EAA+B,MAD7C,CADJ,CA3CuC,CAgDvC;AACA;;AACA,QAAM,SAAS,GACX,IAAI,CAAC,yBAAL,CAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CADJ,CAlDuC,CAqDvC;AACA;AACA;AACA;AACA;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAApB,EAA+B,EAAE,CAAjC,EAAoC;AAClC,WAAK,IAAI,IAAI,GAAG,CAAhB,EAAmB,IAAI,GAAG,SAA1B,EAAqC,EAAE,IAAvC,EAA6C;AAC3C,YAAM,IAAI,GAAG,IAAI,GAAG,YAAP,GAAsB,OAAO,CAAC,GAA3C;;AACA,aAAK,IAAI,IAAI,GAAG,CAAhB,EAAmB,IAAI,GAAG,QAA1B,EAAoC,EAAE,IAAtC,EAA4C;AAC1C,cAAM,IAAI,GAAG,IAAI,GAAG,WAAP,GAAqB,OAAO,CAAC,IAA1C;;AACA,eAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAApB,EAAgC,EAAE,CAAlC,EAAqC;AACnC,gBAAI,MAAM,GAAG,MAAM,CAAC,gBAApB;AACA,gBAAI,MAAM,GAAI,IAAI,GAAG,CAAR,GAAa,CAAb,GAAiB,IAA9B;AACA,gBAAI,MAAM,GAAI,IAAI,GAAG,CAAR,GAAa,CAAb,GAAiB,IAA9B;;AACA,iBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAApB,EAAkC,EAAE,CAApC,EAAuC;AACrC,kBAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,cAAvB;;AACA,kBAAI,GAAG,IAAI,CAAP,IAAY,GAAG,GAAG,QAAtB,EAAgC;AAC9B,qBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,WAApB,EAAiC,EAAE,CAAnC,EAAsC;AACpC,sBAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,aAAvB;;AACA,sBAAI,GAAG,IAAI,CAAP,IAAY,GAAG,GAAG,OAAtB,EAA+B;AAC7B,wBAAM,GAAG,GAAG,EAAE,CAAC,CAAD,CAAF,CAAM,GAAN,EAAW,GAAX,EAAgB,CAAhB,IAAqB,OAAO,CAAC,CAAD,CAAP,CAAW,CAAX,EAAc,CAAd,CAAjC;;AACA,wBAAI,GAAG,GAAG,MAAV,EAAkB;AAChB,sBAAA,MAAM,GAAG,GAAT;AACA,sBAAA,MAAM,GAAG,GAAT;AACA,sBAAA,MAAM,GAAG,GAAT;AACD;AACF;AACF;AACF;AACF;;AACD,YAAA,SAAS,CAAC,CAAD,CAAT,CAAa,MAAb,EAAqB,MAArB,EAA6B,CAA7B,KAAmC,GAAG,CAAC,CAAD,CAAH,CAAO,IAAP,EAAa,IAAb,EAAmB,CAAnB,CAAnC;AACD;AACF;AACF;AACF;;AAED,QAAM,MAAM,GAAG,UAAU,CAAC,KAAX,CACX,IAAI,CAAC,YAAL,CAAkB,SAAlB,EAA6B,CAAC,CAAC,KAA/B,CADW,EAC4B,CAAC,CAAC,KAD9B,EACqC,CAAC,CAAC,KADvC,CAAf;AAGA,WAAO;AAAC,MAAA,MAAM,EAAN,MAAD;AAAS,MAAA,KAAK,EAAE,CAAC,CAAC,KAAlB;AAAyB,MAAA,KAAK,EAAE,CAAC,CAAC;AAAlC,KAAP;AACD;AAhGwD,CAApD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Dilation2DBackpropInput, util } from '@tensorflow/tfjs-core';\nexport const dilation2dBackpropInputConfig = {\n    kernelName: Dilation2DBackpropInput,\n    backendName: 'cpu',\n    kernelFunc: ({ inputs, backend, attrs }) => {\n        const { x, filter, dy } = inputs;\n        const { strides, pad, dilations } = attrs;\n        const cpuBackend = backend;\n        const $x = util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n        const $filter = util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n        const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations);\n        util.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n        const $dy = util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);\n        // The computed gradients has the same dimensions as the input:\n        // [batch, inputHeight, inputCols, inChannel]\n        const gradients = util.makeZerosNestedTypedArray(x.shape, x.dtype);\n        // In the case of multiple argmax branches, we only back-propagate along the\n        // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n        // similarly to the max-pooling backward routines.\n        // This implementation follows the TF c++ implementation:\n        // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n        for (let b = 0; b < batchSize; ++b) {\n            for (let hOut = 0; hOut < outHeight; ++hOut) {\n                const hBeg = hOut * strideHeight - padInfo.top;\n                for (let wOut = 0; wOut < outWidth; ++wOut) {\n                    const wBeg = wOut * strideWidth - padInfo.left;\n                    for (let d = 0; d < inChannels; ++d) {\n                        let curVal = Number.MIN_SAFE_INTEGER;\n                        let hInMax = (hBeg < 0) ? 0 : hBeg;\n                        let wInMax = (wBeg < 0) ? 0 : wBeg;\n                        for (let h = 0; h < filterHeight; ++h) {\n                            const hIn = hBeg + h * dilationHeight;\n                            if (hIn >= 0 && hIn < inHeight) {\n                                for (let w = 0; w < filterWidth; ++w) {\n                                    const wIn = wBeg + w * dilationWidth;\n                                    if (wIn >= 0 && wIn < inWidth) {\n                                        const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                                        if (val > curVal) {\n                                            curVal = val;\n                                            hInMax = hIn;\n                                            wInMax = wIn;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                        gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n                    }\n                }\n            }\n        }\n        const dataId = cpuBackend.write(util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n        return { dataId, shape: x.shape, dtype: x.dtype };\n    }\n};\n//# sourceMappingURL=Dilation2DBackpropInput.js.map"]},"metadata":{},"sourceType":"module"}