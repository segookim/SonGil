{"ast":null,"code":"import _toConsumableArray from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _classCallCheck from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _get from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport { notEqual, serialization, tidy, zerosLike } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport var Embedding = /*#__PURE__*/function (_Layer) {\n  _inherits(Embedding, _Layer);\n\n  var _super = _createSuper(Embedding);\n\n  function Embedding(args) {\n    var _this;\n\n    _classCallCheck(this, Embedding);\n\n    _this = _super.call(this, args);\n    _this.embeddings = null;\n    _this.DEFAULT_EMBEDDINGS_INITIALIZER = 'randomUniform';\n\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      var batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        _this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        _this.batchInputShape = [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n\n    _this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(_this.inputDim, 'inputDim');\n    _this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(_this.outputDim, 'outputDim');\n    _this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || _this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    _this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    _this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    _this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    _this.maskZero = args.maskZero;\n    _this.supportsMasking = args.maskZero;\n    _this.inputLength = args.inputLength;\n    return _this;\n  }\n\n  _createClass(Embedding, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      this.embeddings = this.addWeight('embeddings', [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);\n      this.built = true;\n    } // Override warnOnIncompatibleInputShape because an embedding layer allows\n    // the input to have varying ranks.\n\n  }, {\n    key: \"warnOnIncompatibleInputShape\",\n    value: function warnOnIncompatibleInputShape(inputShape) {}\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      var _this2 = this;\n\n      return tidy(function () {\n        if (!_this2.maskZero) {\n          return null;\n        } else {\n          inputs = getExactlyOneTensor(inputs);\n          return notEqual(inputs, zerosLike(inputs));\n        }\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n\n      if (this.inputLength == null) {\n        return [].concat(_toConsumableArray(inputShape), [this.outputDim]);\n      } // inputLength can be an array if input is 3D or higher.\n\n\n      var inLens = generic_utils.toList(this.inputLength);\n\n      if (inLens.length !== inputShape.length - 1) {\n        throw new ValueError(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received \") + \"input shape has shape \".concat(inputShape));\n      } else {\n        var i = 0;\n\n        for (var k = 0; k < inLens.length; ++k) {\n          var s1 = inLens[k];\n          var s2 = inputShape[k + 1];\n\n          if (s1 != null && s2 != null && s1 !== s2) {\n            throw new ValueError(\"\\\"inputLength\\\" is \".concat(this.inputLength, \", but received \") + \"input shape has shape \".concat(inputShape));\n          } else if (s1 == null) {\n            inLens[i] = s2;\n          }\n\n          i++;\n        }\n      }\n\n      return [inputShape[0]].concat(_toConsumableArray(inLens), [this.outputDim]);\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this3 = this;\n\n      return tidy(function () {\n        _this3.invokeCallHook(inputs, kwargs); // Embedding layer accepts only a single input.\n\n\n        var input = getExactlyOneTensor(inputs);\n\n        if (input.dtype !== 'int32') {\n          input = K.cast(input, 'int32');\n        }\n\n        var output = K.gather(_this3.embeddings.read(), input.as1D());\n        return output.reshape(getExactlyOneShape(_this3.computeOutputShape(input.shape)));\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        inputDim: this.inputDim,\n        outputDim: this.outputDim,\n        embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n        embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n        maskZero: this.maskZero,\n        inputLength: this.inputLength\n      };\n\n      var baseConfig = _get(_getPrototypeOf(Embedding.prototype), \"getConfig\", this).call(this);\n\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n\n  return Embedding;\n}(Layer);\n/** @nocollapse */\n\nEmbedding.className = 'Embedding';\nserialization.registerClass(Embedding);","map":{"version":3,"sources":["../../src/layers/embeddings.ts"],"names":[],"mappings":";;;;;;;;AAAA;;;;;;;;AAQG;;AAEH;;;;AAIG;AACH,SAAQ,QAAR,EAAkB,aAAlB,EAAyC,IAAzC,EAA+C,SAA/C,QAA+D,uBAA/D;AAEA,OAAO,KAAK,CAAZ,MAAmB,yBAAnB;AACA,SAA0C,aAA1C,EAAyD,mBAAzD,QAAmF,gBAAnF;AACA,SAAQ,KAAR,QAA+B,oBAA/B;AACA,SAAQ,UAAR,QAAyB,WAAzB;AACA,SAAQ,cAAR,EAA4D,oBAA5D,QAAuF,iBAAvF;AAEA,SAAQ,cAAR,EAA4D,oBAA5D,QAAuF,iBAAvF;AAEA,OAAO,KAAK,aAAZ,MAA+B,wBAA/B;AACA,SAAQ,kBAAR,EAA4B,mBAA5B,QAAsD,sBAAtD;AAiDA,WAAa,SAAb;AAAA;;AAAA;;AAgBE,qBAAY,IAAZ,EAAoC;AAAA;;AAAA;;AAClC,8BAAM,IAAN;AARM,UAAA,UAAA,GAA4B,IAA5B;AAEC,UAAA,8BAAA,GACL,eADK;;AAOP,QAAI,IAAI,CAAC,eAAL,IAAwB,IAAxB,IAAgC,IAAI,CAAC,UAAL,IAAmB,IAAvD,EAA6D;AAC3D;AACA;AACA;AACA;AACA,UAAI,SAAS,GAAW,IAAxB;;AACA,UAAI,IAAI,CAAC,SAAL,IAAkB,IAAtB,EAA4B;AAC1B,QAAA,SAAS,GAAG,IAAI,CAAC,SAAjB;AACD;;AACD,UAAI,IAAI,CAAC,WAAL,IAAoB,IAAxB,EAA8B;AAC5B;AACA;AACA,cAAK,eAAL,GAAuB,CAAC,SAAD,EAAY,IAAZ,CAAvB;AACD,OAJD,MAIO;AACL;AACA;AACA,cAAK,eAAL,GACI,CAAC,SAAD,EAAY,MAAZ,CAAmB,aAAa,CAAC,MAAd,CAAqB,IAAI,CAAC,WAA1B,CAAnB,CADJ;AAED;AACF;;AACD,UAAK,QAAL,GAAgB,IAAI,CAAC,QAArB;AACA,IAAA,aAAa,CAAC,qBAAd,CAAoC,MAAK,QAAzC,EAAmD,UAAnD;AACA,UAAK,SAAL,GAAiB,IAAI,CAAC,SAAtB;AACA,IAAA,aAAa,CAAC,qBAAd,CAAoC,MAAK,SAAzC,EAAoD,WAApD;AACA,UAAK,qBAAL,GAA6B,cAAc,CACvC,IAAI,CAAC,qBAAL,IAA8B,MAAK,8BADI,CAA3C;AAEA,UAAK,qBAAL,GAA6B,cAAc,CAAC,IAAI,CAAC,qBAAN,CAA3C;AACA,UAAK,mBAAL,GAA2B,cAAc,CAAC,IAAI,CAAC,mBAAN,CAAzC;AACA,UAAK,oBAAL,GAA4B,aAAa,CAAC,IAAI,CAAC,oBAAN,CAAzC;AACA,UAAK,QAAL,GAAgB,IAAI,CAAC,QAArB;AACA,UAAK,eAAL,GAAuB,IAAI,CAAC,QAA5B;AACA,UAAK,WAAL,GAAmB,IAAI,CAAC,WAAxB;AAjCkC;AAkCnC;;AAlDH;AAAA;AAAA,WAoDS,eAAM,UAAN,EAA+B;AACpC,WAAK,UAAL,GAAkB,KAAK,SAAL,CACd,YADc,EACA,CAAC,KAAK,QAAN,EAAgB,KAAK,SAArB,CADA,EACiC,KAAK,KADtC,EAEd,KAAK,qBAFS,EAEc,KAAK,qBAFnB,EAE0C,IAF1C,EAGd,KAAK,oBAHS,CAAlB;AAIA,WAAK,KAAL,GAAa,IAAb;AACD,KA1DH,CA4DE;AACA;;AA7DF;AAAA;AAAA,WA8DY,sCAA6B,UAA7B,EAA8C,CAAI;AA9D9D;AAAA;AAAA,WAgEE,qBAAY,MAAZ,EAAqC,IAArC,EAA2D;AAAA;;AACzD,aAAO,IAAI,CAAC,YAAK;AACf,YAAI,CAAC,MAAI,CAAC,QAAV,EAAoB;AAClB,iBAAO,IAAP;AACD,SAFD,MAEO;AACL,UAAA,MAAM,GAAG,mBAAmB,CAAC,MAAD,CAA5B;AACA,iBAAO,QAAQ,CAAC,MAAD,EAAS,SAAS,CAAC,MAAD,CAAlB,CAAf;AACD;AACF,OAPU,CAAX;AAQD;AAzEH;AAAA;AAAA,WA2EE,4BAAmB,UAAnB,EAA4C;AAC1C,MAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;;AACA,UAAI,KAAK,WAAL,IAAoB,IAAxB,EAA8B;AAC5B,4CAAW,UAAX,IAAuB,KAAK,SAA5B;AACD,OAJyC,CAK1C;;;AACA,UAAM,MAAM,GAAa,aAAa,CAAC,MAAd,CAAqB,KAAK,WAA1B,CAAzB;;AACA,UAAI,MAAM,CAAC,MAAP,KAAkB,UAAU,CAAC,MAAX,GAAoB,CAA1C,EAA6C;AAC3C,cAAM,IAAI,UAAJ,CACF,6BAAoB,KAAK,WAAzB,uDACyB,UADzB,CADE,CAAN;AAGD,OAJD,MAIO;AACL,YAAI,CAAC,GAAG,CAAR;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;AACtC,cAAM,EAAE,GAAG,MAAM,CAAC,CAAD,CAAjB;AACA,cAAM,EAAE,GAAG,UAAU,CAAC,CAAC,GAAG,CAAL,CAArB;;AACA,cAAK,EAAE,IAAI,IAAP,IAAiB,EAAE,IAAI,IAAvB,IAAiC,EAAE,KAAK,EAA5C,EAAiD;AAC/C,kBAAM,IAAI,UAAJ,CACF,6BAAoB,KAAK,WAAzB,uDACyB,UADzB,CADE,CAAN;AAGD,WAJD,MAIO,IAAI,EAAE,IAAI,IAAV,EAAgB;AACrB,YAAA,MAAM,CAAC,CAAD,CAAN,GAAY,EAAZ;AACD;;AACD,UAAA,CAAC;AACF;AACF;;AACD,cAAQ,UAAU,CAAC,CAAD,CAAlB,4BAA0B,MAA1B,IAAkC,KAAK,SAAvC;AACD;AAtGH;AAAA;AAAA,WAwGE,cAAK,MAAL,EAA8B,MAA9B,EAA4C;AAAA;;AAC1C,aAAO,IAAI,CAAC,YAAK;AACf,QAAA,MAAI,CAAC,cAAL,CAAoB,MAApB,EAA4B,MAA5B,EADe,CAEf;;;AACA,YAAI,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAA/B;;AACA,YAAI,KAAK,CAAC,KAAN,KAAgB,OAApB,EAA6B;AAC3B,UAAA,KAAK,GAAG,CAAC,CAAC,IAAF,CAAO,KAAP,EAAc,OAAd,CAAR;AACD;;AACD,YAAM,MAAM,GAAG,CAAC,CAAC,MAAF,CAAS,MAAI,CAAC,UAAL,CAAgB,IAAhB,EAAT,EAAiC,KAAK,CAAC,IAAN,EAAjC,CAAf;AACA,eAAO,MAAM,CAAC,OAAP,CACH,kBAAkB,CAAC,MAAI,CAAC,kBAAL,CAAwB,KAAK,CAAC,KAA9B,CAAD,CADf,CAAP;AAED,OAVU,CAAX;AAWD;AApHH;AAAA;AAAA,WAsHE,qBAAS;AACP,UAAM,MAAM,GAAG;AACb,QAAA,QAAQ,EAAE,KAAK,QADF;AAEb,QAAA,SAAS,EAAE,KAAK,SAFH;AAGb,QAAA,qBAAqB,EAAE,oBAAoB,CAAC,KAAK,qBAAN,CAH9B;AAIb,QAAA,qBAAqB,EAAE,oBAAoB,CAAC,KAAK,qBAAN,CAJ9B;AAKb,QAAA,mBAAmB,EAAE,oBAAoB,CAAC,KAAK,mBAAN,CAL5B;AAMb,QAAA,oBAAoB,EAAE,mBAAmB,CAAC,KAAK,oBAAN,CAN5B;AAOb,QAAA,QAAQ,EAAE,KAAK,QAPF;AAQb,QAAA,WAAW,EAAE,KAAK;AARL,OAAf;;AAUA,UAAM,UAAU,2EAAhB;;AACA,MAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,aAAO,MAAP;AACD;AApIH;;AAAA;AAAA,EAA+B,KAA/B;AACE;;AACO,SAAA,CAAA,SAAA,GAAY,WAAZ;AAoIT,aAAa,CAAC,aAAd,CAA4B,SAA5B","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport { notEqual, serialization, tidy, zerosLike } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Embedding extends Layer {\n    constructor(args) {\n        super(args);\n        this.embeddings = null;\n        this.DEFAULT_EMBEDDINGS_INITIALIZER = 'randomUniform';\n        if (args.batchInputShape == null && args.inputShape == null) {\n            // Porting Note: This logic is copied from Layer's constructor, since we\n            // can't do exactly what the Python constructor does for Embedding().\n            // Specifically, the super constructor can not be called after the\n            // mutation of the `config` argument.\n            let batchSize = null;\n            if (args.batchSize != null) {\n                batchSize = args.batchSize;\n            }\n            if (args.inputLength == null) {\n                // Fix super-constructor to what it would have done if\n                // 'config.inputShape' were (None, )\n                this.batchInputShape = [batchSize, null];\n            }\n            else {\n                // Fix super-constructor to what it would have done if\n                // 'config.inputShape' were (config.inputLength, )\n                this.batchInputShape =\n                    [batchSize].concat(generic_utils.toList(args.inputLength));\n            }\n        }\n        this.inputDim = args.inputDim;\n        generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n        this.outputDim = args.outputDim;\n        generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n        this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n        this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n        this.activityRegularizer = getRegularizer(args.activityRegularizer);\n        this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n        this.maskZero = args.maskZero;\n        this.supportsMasking = args.maskZero;\n        this.inputLength = args.inputLength;\n    }\n    build(inputShape) {\n        this.embeddings = this.addWeight('embeddings', [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);\n        this.built = true;\n    }\n    // Override warnOnIncompatibleInputShape because an embedding layer allows\n    // the input to have varying ranks.\n    warnOnIncompatibleInputShape(inputShape) { }\n    computeMask(inputs, mask) {\n        return tidy(() => {\n            if (!this.maskZero) {\n                return null;\n            }\n            else {\n                inputs = getExactlyOneTensor(inputs);\n                return notEqual(inputs, zerosLike(inputs));\n            }\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        if (this.inputLength == null) {\n            return [...inputShape, this.outputDim];\n        }\n        // inputLength can be an array if input is 3D or higher.\n        const inLens = generic_utils.toList(this.inputLength);\n        if (inLens.length !== inputShape.length - 1) {\n            throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` +\n                `input shape has shape ${inputShape}`);\n        }\n        else {\n            let i = 0;\n            for (let k = 0; k < inLens.length; ++k) {\n                const s1 = inLens[k];\n                const s2 = inputShape[k + 1];\n                if ((s1 != null) && (s2 != null) && (s1 !== s2)) {\n                    throw new ValueError(`\"inputLength\" is ${this.inputLength}, but received ` +\n                        `input shape has shape ${inputShape}`);\n                }\n                else if (s1 == null) {\n                    inLens[i] = s2;\n                }\n                i++;\n            }\n        }\n        return [inputShape[0], ...inLens, this.outputDim];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            // Embedding layer accepts only a single input.\n            let input = getExactlyOneTensor(inputs);\n            if (input.dtype !== 'int32') {\n                input = K.cast(input, 'int32');\n            }\n            const output = K.gather(this.embeddings.read(), input.as1D());\n            return output.reshape(getExactlyOneShape(this.computeOutputShape(input.shape)));\n        });\n    }\n    getConfig() {\n        const config = {\n            inputDim: this.inputDim,\n            outputDim: this.outputDim,\n            embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n            embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n            maskZero: this.maskZero,\n            inputLength: this.inputLength\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nEmbedding.className = 'Embedding';\nserialization.registerClass(Embedding);\n//# sourceMappingURL=embeddings.js.map"]},"metadata":{},"sourceType":"module"}