{"ast":null,"code":"import _regeneratorRuntime from \"/Users/kimkiwoong/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/kimkiwoong/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), function () {\n    return \"batchSize is required to be a positive integer, but got \".concat(batchSize);\n  });\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\n\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(function (array) {\n      return sliceAlongFirstAxis(array, start, stop - start);\n    });\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\n\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(function () {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(function (array) {\n        return sliceArraysByIndices(array, indices);\n      });\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\n\nexport function makeBatches(size, batchSize) {\n  var output = [];\n  var batchStart = 0;\n  var batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\n\nfunction fitLoop(_x, _x2, _x3, _x4, _x5, _x6, _x7, _x8, _x9, _x10, _x11, _x12, _x13, _x14, _x15) {\n  return _fitLoop.apply(this, arguments);\n}\n\nfunction _fitLoop() {\n  _fitLoop = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    var doValidation, numTrainSamples, indexArray, _configureCallbacks, callbackList, history, _loop, epoch, _ret;\n\n    return _regeneratorRuntime.wrap(function _callee2$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            if (batchSize == null) {\n              batchSize = 32;\n            }\n\n            if (epochs == null) {\n              epochs = 1;\n            }\n\n            if (shuffle == null) {\n              shuffle = true;\n            }\n\n            if (initialEpoch == null) {\n              initialEpoch = 0;\n            } // TODO(cais): Change const to let below when implementing validation.\n\n\n            doValidation = false;\n\n            if (valF != null && valIns != null) {\n              doValidation = true; // TODO(cais): verbose message.\n            }\n\n            if (!(validationSteps != null)) {\n              _context4.next = 10;\n              break;\n            }\n\n            doValidation = true;\n\n            if (!(stepsPerEpoch == null)) {\n              _context4.next = 10;\n              break;\n            }\n\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n\n          case 10:\n            numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n\n            if (numTrainSamples != null) {\n              indexArray = range(0, numTrainSamples);\n            }\n\n            if (verbose == null) {\n              verbose = 1;\n            }\n\n            _configureCallbacks = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics), callbackList = _configureCallbacks.callbackList, history = _configureCallbacks.history;\n            callbackList.setModel(model);\n            model.history = history;\n            _context4.next = 18;\n            return callbackList.onTrainBegin();\n\n          case 18:\n            model.stopTraining_ = false; // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n            // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n            _loop = /*#__PURE__*/_regeneratorRuntime.mark(function _loop(epoch) {\n              var epochLogs;\n              return _regeneratorRuntime.wrap(function _loop$(_context3) {\n                while (1) {\n                  switch (_context3.prev = _context3.next) {\n                    case 0:\n                      _context3.next = 2;\n                      return callbackList.onEpochBegin(epoch);\n\n                    case 2:\n                      epochLogs = {};\n\n                      if (!(stepsPerEpoch != null)) {\n                        _context3.next = 7;\n                        break;\n                      }\n\n                      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n\n                    case 7:\n                      return _context3.delegateYield( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                        var epochIndexArray1D, batches, _loop2, batchIndex, _ret2;\n\n                        return _regeneratorRuntime.wrap(function _callee$(_context2) {\n                          while (1) {\n                            switch (_context2.prev = _context2.next) {\n                              case 0:\n                                if (!(shuffle === 'batch')) {\n                                  _context2.next = 4;\n                                  break;\n                                }\n\n                                throw new NotImplementedError('batch shuffling is not implemneted yet');\n\n                              case 4:\n                                if (shuffle) {\n                                  util.shuffle(indexArray);\n                                }\n\n                              case 5:\n                                // Convert the potentially shuffled indices to Tensor1D, to avoid the\n                                // cost of repeated creation of Array1Ds later on.\n                                epochIndexArray1D = tensor1d(indexArray);\n                                batches = makeBatches(numTrainSamples, batchSize);\n                                _loop2 = /*#__PURE__*/_regeneratorRuntime.mark(function _loop2(batchIndex) {\n                                  var batchLogs;\n                                  return _regeneratorRuntime.wrap(function _loop2$(_context) {\n                                    while (1) {\n                                      switch (_context.prev = _context.next) {\n                                        case 0:\n                                          batchLogs = {};\n                                          _context.next = 3;\n                                          return callbackList.onBatchBegin(batchIndex, batchLogs);\n\n                                        case 3:\n                                          tfc.tidy(function () {\n                                            var batchStart = batches[batchIndex][0];\n                                            var batchEnd = batches[batchIndex][1];\n                                            var batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                                            batchLogs['batch'] = batchIndex;\n                                            batchLogs['size'] = batchEnd - batchStart; // TODO(cais): In ins, train flag can be a number, instead of an\n                                            //   Tensor? Do we need to handle this in tfjs-layers?\n\n                                            var insBatch = sliceArraysByIndices(ins, batchIds);\n                                            var outs = f(insBatch);\n\n                                            for (var i = 0; i < outLabels.length; ++i) {\n                                              var label = outLabels[i];\n                                              var out = outs[i];\n                                              batchLogs[label] = out;\n                                              tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n                                            }\n\n                                            if (batchIndex === batches.length - 1) {\n                                              // Last batch.\n                                              if (doValidation) {\n                                                var valOuts = model.testLoop(valF, valIns, batchSize); // Porting Notes: In tfjs-layers, valOuts is always an Array.\n\n                                                for (var _i = 0; _i < outLabels.length; ++_i) {\n                                                  var _label = outLabels[_i];\n                                                  var _out = valOuts[_i];\n                                                  tfc.keep(_out); // TODO(cais): Use scope() to avoid ownership.\n\n                                                  epochLogs['val_' + _label] = _out;\n                                                }\n                                              }\n                                            }\n                                          });\n                                          _context.next = 6;\n                                          return callbackList.onBatchEnd(batchIndex, batchLogs);\n\n                                        case 6:\n                                          disposeTensorsInLogs(batchLogs);\n\n                                          if (!model.stopTraining_) {\n                                            _context.next = 9;\n                                            break;\n                                          }\n\n                                          return _context.abrupt(\"return\", \"break\");\n\n                                        case 9:\n                                        case \"end\":\n                                          return _context.stop();\n                                      }\n                                    }\n                                  }, _loop2);\n                                });\n                                batchIndex = 0;\n\n                              case 9:\n                                if (!(batchIndex < batches.length)) {\n                                  _context2.next = 17;\n                                  break;\n                                }\n\n                                return _context2.delegateYield(_loop2(batchIndex), \"t0\", 11);\n\n                              case 11:\n                                _ret2 = _context2.t0;\n\n                                if (!(_ret2 === \"break\")) {\n                                  _context2.next = 14;\n                                  break;\n                                }\n\n                                return _context2.abrupt(\"break\", 17);\n\n                              case 14:\n                                ++batchIndex;\n                                _context2.next = 9;\n                                break;\n\n                              case 17:\n                                epochIndexArray1D.dispose();\n\n                              case 18:\n                              case \"end\":\n                                return _context2.stop();\n                            }\n                          }\n                        }, _callee);\n                      })(), \"t0\", 8);\n\n                    case 8:\n                      _context3.next = 10;\n                      return callbackList.onEpochEnd(epoch, epochLogs);\n\n                    case 10:\n                      if (!model.stopTraining_) {\n                        _context3.next = 12;\n                        break;\n                      }\n\n                      return _context3.abrupt(\"return\", \"break\");\n\n                    case 12:\n                    case \"end\":\n                      return _context3.stop();\n                  }\n                }\n              }, _loop);\n            });\n            epoch = initialEpoch;\n\n          case 21:\n            if (!(epoch < epochs)) {\n              _context4.next = 29;\n              break;\n            }\n\n            return _context4.delegateYield(_loop(epoch), \"t0\", 23);\n\n          case 23:\n            _ret = _context4.t0;\n\n            if (!(_ret === \"break\")) {\n              _context4.next = 26;\n              break;\n            }\n\n            return _context4.abrupt(\"break\", 29);\n\n          case 26:\n            ++epoch;\n            _context4.next = 21;\n            break;\n\n          case 29:\n            _context4.next = 31;\n            return callbackList.onTrainEnd();\n\n          case 31:\n            _context4.next = 33;\n            return model.history.syncData();\n\n          case 33:\n            return _context4.abrupt(\"return\", model.history);\n\n          case 34:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _fitLoop.apply(this, arguments);\n}\n\nexport function fitTensors(_x16, _x17, _x18) {\n  return _fitTensors.apply(this, arguments);\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\n\nfunction _fitTensors() {\n  _fitTensors = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, x, y) {\n    var args,\n        inputs,\n        targets,\n        inputValX,\n        inputValY,\n        valX,\n        valY,\n        sampleWeights,\n        batchSize,\n        checkBatchAxis,\n        standardizedOuts,\n        doValidation,\n        valIns,\n        _checkBatchAxis,\n        valStandardized,\n        splitAt,\n        originalBatchSize,\n        ins,\n        trainFunction,\n        outLabels,\n        valFunction,\n        callbackMetrics,\n        callbacks,\n        out,\n        _args5 = arguments;\n\n    return _regeneratorRuntime.wrap(function _callee3$(_context5) {\n      while (1) {\n        switch (_context5.prev = _context5.next) {\n          case 0:\n            args = _args5.length > 3 && _args5[3] !== undefined ? _args5[3] : {};\n\n            if (!model.isTraining) {\n              _context5.next = 3;\n              break;\n            }\n\n            throw new Error('Cannot start training because another fit() call is ongoing.');\n\n          case 3:\n            model.isTraining = true;\n            _context5.prev = 4;\n            batchSize = args.batchSize == null ? 32 : args.batchSize;\n            checkBatchSize(batchSize); // Validate user data.\n            // TODO(cais): Support sampleWeight.\n\n            checkBatchAxis = false;\n            _context5.next = 10;\n            return model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n\n          case 10:\n            standardizedOuts = _context5.sent;\n            inputs = standardizedOuts[0];\n            targets = standardizedOuts[1];\n            sampleWeights = standardizedOuts[2]; // Prepare validation data.\n\n            doValidation = false;\n\n            if (!(args.validationData != null && args.validationData.length > 0)) {\n              _context5.next = 36;\n              break;\n            }\n\n            doValidation = true;\n\n            if (!(args.validationData.length === 2)) {\n              _context5.next = 22;\n              break;\n            }\n\n            // config.validationData consists of valX and valY.\n            inputValX = args.validationData[0];\n            inputValY = args.validationData[1];\n            _context5.next = 27;\n            break;\n\n          case 22:\n            if (!(args.validationData.length === 3)) {\n              _context5.next = 26;\n              break;\n            }\n\n            throw new NotImplementedError('validationData including sample weights is not supported yet.');\n\n          case 26:\n            throw new ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" + \"or 3 (valX, valY, valSampleWeight) items; \" + \"\".concat(args.validationData, \" is invalid.\"));\n\n          case 27:\n            _checkBatchAxis = true;\n            _context5.next = 30;\n            return model.standardizeUserData(inputValX, inputValY, null,\n            /** Unused sample weights. */\n            null,\n            /** Unused class weights. */\n            _checkBatchAxis, batchSize);\n\n          case 30:\n            valStandardized = _context5.sent;\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n\n            _context5.next = 37;\n            break;\n\n          case 36:\n            if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n              doValidation = true; // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n\n              splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n              originalBatchSize = inputs[0].shape[0];\n              valX = sliceArrays(inputs, splitAt, originalBatchSize);\n              inputs = sliceArrays(inputs, 0, splitAt);\n              valY = sliceArrays(targets, splitAt, originalBatchSize);\n              targets = sliceArrays(targets, 0, splitAt); // TODO(cais): Once sampleWeights becomes available, slice it to get\n              //   valSampleWeights.\n\n              valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n            } else if (args.validationSteps != null) {\n              doValidation = true; // TODO(cais): Add useLearningPhase.\n            }\n\n          case 37:\n            ins = inputs.concat(targets).concat(sampleWeights);\n            model.checkTrainableWeightsConsistency(); // TODO(cais): Handle use_learning_phase and learning_phase?\n            // Porting Note: Here we see a key deviation of tfjs-layers from\n            // Keras.\n            //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n            //  we do not construct symbolic computation graphs to embody the\n            //  training process. Instead, we define a function that performs the\n            //  training action. In PyKeras, the data (inputs and targets) are fed\n            //  through graph placeholders. In tfjs-layers, the data are fed as\n            //  function arguments. Since the function are defined below in the\n            //  scope, we don't have equivalents of PyKeras's\n            //  `_make_train_funciton`.\n\n            trainFunction = model.makeTrainFunction();\n            outLabels = model.getDedupedMetricsNames();\n\n            if (doValidation) {\n              model.makeTestFunction();\n              valFunction = model.testFunction;\n              callbackMetrics = outLabels.slice().concat(outLabels.map(function (n) {\n                return 'val_' + n;\n              }));\n            } else {\n              valFunction = null;\n              valIns = [];\n              callbackMetrics = outLabels.slice();\n            }\n\n            callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n            _context5.next = 45;\n            return fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n\n          case 45:\n            out = _context5.sent;\n            return _context5.abrupt(\"return\", out);\n\n          case 47:\n            _context5.prev = 47;\n            model.isTraining = false; // Memory clean up.\n\n            disposeNewTensors(inputs, x);\n            disposeNewTensors(targets, y);\n            disposeNewTensors(valX, inputValX);\n            disposeNewTensors(valY, inputValY);\n\n            if (sampleWeights != null) {\n              tfc.dispose(sampleWeights);\n            }\n\n            return _context5.finish(47);\n\n          case 55:\n          case \"end\":\n            return _context5.stop();\n        }\n      }\n    }, _callee3, null, [[4,, 47, 55]]);\n  }));\n  return _fitTensors.apply(this, arguments);\n}\n\nexport function ensureTensorsRank2OrHigher(tensors) {\n  var outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  } // Make Tensors at least 2D.\n\n\n  for (var i = 0; i < tensors.length; ++i) {\n    var tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\n\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  var oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(function (t) {\n      return oldTensorIds.push(t.id);\n    });\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (var name in refTensors) {\n      var oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  var tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(function (t) {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (var _name in tensors) {\n      var tensor = tensors[_name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(function (t) {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"sources":["../../src/engine/training_tensors.ts"],"names":[],"mappings":";;;AAAA;;;;;;;;AAQG;;AAEH;;AAEG;AAEH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAgB,MAAhB,EAAkC,QAAlC,EAA4C,IAA5C,QAAuD,uBAAvD;AAEA,SAAQ,UAAR,EAAoB,MAApB,EAA4B,mBAA5B,QAAsD,yBAAtD;AACA,SAAsB,kBAAtB,EAA8F,oBAA9F,QAA4I,mBAA5I;AACA,SAAQ,mBAAR,EAA6B,UAA7B,QAA8C,WAA9C;AACA,SAAQ,oBAAR,QAAmD,SAAnD;AACA,SAAQ,KAAR,QAAoB,qBAApB;AA4IA,OAAM,SAAU,cAAV,CAAyB,SAAzB,EAA0C;AAC9C,EAAA,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,SAAS,GAAG,CAAZ,IAAiB,MAAM,CAAC,SAAP,CAAiB,SAAjB,CADrB,EAEI;AAAA,6EACI,SADJ;AAAA,GAFJ;AAID;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,WAAV,CACF,MADE,EACuB,KADvB,EACsC,IADtC,EACkD;AACtD,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,WAAO,CAAC,IAAD,CAAP;AACD,GAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;AAChC,WAAO,MAAM,CAAC,GAAP,CAAW,UAAA,KAAK;AAAA,aAAI,mBAAmB,CAAC,KAAD,EAAQ,KAAR,EAAe,IAAI,GAAG,KAAtB,CAAvB;AAAA,KAAhB,CAAP;AACD,GAFM,MAEA;AAAG;AACR,WAAO,mBAAmB,CAAC,MAAD,EAAS,KAAT,EAAgB,IAAI,GAAG,KAAvB,CAA1B;AACD;AACF;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,oBAAV,CACF,MADE,EACuB,OADvB,EACwC;AAC5C,SAAO,GAAG,CAAC,IAAJ,CAAS,YAAK;AACnB,QAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,aAAO,IAAP;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;AAChC,aAAO,MAAM,CAAC,GAAP,CACH,UAAA,KAAK;AAAA,eAAK,oBAAoB,CAAC,KAAD,EAAQ,OAAR,CAAzB;AAAA,OADF,CAAP;AAED,KAHM,MAGA;AACL;AACA;AACA,aAAO,MAAM,CACT,MADS,EACD,OAAO,CAAC,KAAR,KAAkB,OAAlB,GAA4B,OAA5B,GAAsC,OAAO,CAAC,KAAR,EADrC,CAAb;AAED;AACF,GAZM,CAAP;AAaD;AAED;;;;;;;AAOG;;AACH,OAAM,SAAU,WAAV,CACF,IADE,EACY,SADZ,EAC6B;AACjC,MAAM,MAAM,GAA4B,EAAxC;AACA,MAAI,UAAU,GAAG,CAAjB;AACA,MAAI,QAAQ,GAAW,IAAvB;;AACA,SAAO,UAAU,GAAG,IAApB,EAA0B;AACxB,IAAA,QAAQ,GAAG,UAAU,GAAG,SAAxB;;AACA,QAAI,QAAQ,IAAI,IAAhB,EAAsB;AACpB,MAAA,QAAQ,GAAG,IAAX;AACD;;AACD,IAAA,MAAM,CAAC,IAAP,CAAY,CAAC,UAAD,EAAa,QAAb,CAAZ;AACA,IAAA,UAAU,GAAG,QAAb;AACD;;AACD,SAAO,MAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BG;;SACY,O;;;;;sEAAf,mBACI;AACA;AACA,EAAA,KAHJ,EAGgB,CAHhB,EAGiD,GAHjD,EAII,SAJJ,EAI0B,SAJ1B,EAI8C,MAJ9C,EAI+D,OAJ/D,EAKI,SALJ,EAKgC,IALhC,EAMI,MANJ,EAMuB,OANvB,EAMiD,eANjD,EAOI,YAPJ,EAO2B,aAP3B,EAQI,eARJ;AAAA;;AAAA;AAAA;AAAA;AAAA;AASE,gBAAI,SAAS,IAAI,IAAjB,EAAuB;AACrB,cAAA,SAAS,GAAG,EAAZ;AACD;;AACD,gBAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,cAAA,MAAM,GAAG,CAAT;AACD;;AACD,gBAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,cAAA,OAAO,GAAG,IAAV;AACD;;AACD,gBAAI,YAAY,IAAI,IAApB,EAA0B;AACxB,cAAA,YAAY,GAAG,CAAf;AACD,aApBH,CAsBE;;;AACI,YAAA,YAvBN,GAuBqB,KAvBrB;;AAwBE,gBAAI,IAAI,IAAI,IAAR,IAAgB,MAAM,IAAI,IAA9B,EAAoC;AAClC,cAAA,YAAY,GAAG,IAAf,CADkC,CAElC;AACD;;AA3BH,kBA4BM,eAAe,IAAI,IA5BzB;AAAA;AAAA;AAAA;;AA6BI,YAAA,YAAY,GAAG,IAAf;;AA7BJ,kBA8BQ,aAAa,IAAI,IA9BzB;AAAA;AAAA;AAAA;;AAAA,kBA+BY,IAAI,UAAJ,CACF,mEACA,oCAFE,CA/BZ;;AAAA;AAqCQ,YAAA,eArCR,GAsCM,KAAK,CAAC,eAAN,CAAsB,GAAtB,EAA2B,SAA3B,EAAsC,aAAtC,EAAqD,iBAArD,CAtCN;;AAwCE,gBAAI,eAAe,IAAI,IAAvB,EAA6B;AAC3B,cAAA,UAAU,GAAG,KAAK,CAAC,CAAD,EAAI,eAAJ,CAAlB;AACD;;AAED,gBAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,cAAA,OAAO,GAAG,CAAV;AACD;;AA9CH,kCAgDkC,kBAAkB,CAC9C,SAD8C,EACnC,OADmC,EAC1B,MAD0B,EAClB,YADkB,EACJ,eADI,EACa,aADb,EAE9C,SAF8C,EAEnC,YAFmC,EAErB,eAFqB,CAhDpD,EAgDS,YAhDT,uBAgDS,YAhDT,EAgDuB,OAhDvB,uBAgDuB,OAhDvB;AAmDE,YAAA,YAAY,CAAC,QAAb,CAAsB,KAAtB;AACA,YAAA,KAAK,CAAC,OAAN,GAAgB,OAAhB;AApDF;AAAA,mBAqDQ,YAAY,CAAC,YAAb,EArDR;;AAAA;AAsDE,YAAA,KAAK,CAAC,aAAN,GAAsB,KAAtB,CAtDF,CAuDE;AACA;;AAxDF,yEA0DW,KA1DX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BA2DU,YAAY,CAAC,YAAb,CAA0B,KAA1B,CA3DV;;AAAA;AA4DU,sBAAA,SA5DV,GA4DsC,EA5DtC;;AAAA,4BA6DQ,aAAa,IAAI,IA7DzB;AAAA;AAAA;AAAA;;AAAA,4BA8DY,IAAI,mBAAJ,CACF,4CADE,CA9DZ;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,sCAiEU,OAAO,KAAK,OAjEtB;AAAA;AAAA;AAAA;;AAAA,sCAkEc,IAAI,mBAAJ,CAAwB,wCAAxB,CAlEd;;AAAA;AAmEa,oCAAI,OAAJ,EAAa;AAClB,kCAAA,IAAI,CAAC,OAAL,CAAa,UAAb;AACD;;AArEP;AAsEM;AACA;AACM,gCAAA,iBAxEZ,GAwEgC,QAAQ,CAAC,UAAD,CAxExC;AA0EY,gCAAA,OA1EZ,GA0EsB,WAAW,CAAC,eAAD,EAAkB,SAAlB,CA1EjC;AAAA,+FA2Ee,UA3Ef;AAAA;AAAA;AAAA;AAAA;AAAA;AA4Ec,0CAAA,SA5Ed,GA4E0C,EA5E1C;AAAA;AAAA,iDA6Ec,YAAY,CAAC,YAAb,CAA0B,UAA1B,EAAsC,SAAtC,CA7Ed;;AAAA;AA+EQ,0CAAA,GAAG,CAAC,IAAJ,CAAS,YAAK;AACZ,gDAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gDAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;AACA,gDAAM,QAAQ,GAAG,mBAAmB,CACf,iBADe,EACI,UADJ,EAEf,QAAQ,GAAG,UAFI,CAApC;AAGA,4CAAA,SAAS,CAAC,OAAD,CAAT,GAAqB,UAArB;AACA,4CAAA,SAAS,CAAC,MAAD,CAAT,GAAoB,QAAQ,GAAG,UAA/B,CAPY,CASZ;AACA;;AACA,gDAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAD,EAAM,QAAN,CAArC;AACA,gDAAM,IAAI,GAAG,CAAC,CAAC,QAAD,CAAd;;AACA,iDAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,kDAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;AACA,kDAAM,GAAG,GAAG,IAAI,CAAC,CAAD,CAAhB;AACA,8CAAA,SAAS,CAAC,KAAD,CAAT,GAAmB,GAAnB;AACA,8CAAA,GAAG,CAAC,IAAJ,CAAS,GAAT,EAJyC,CAKzC;AACD;;AAED,gDAAI,UAAU,KAAK,OAAO,CAAC,MAAR,GAAiB,CAApC,EAAuC;AAAG;AACxC,kDAAI,YAAJ,EAAkB;AAChB,oDAAM,OAAO,GAAG,KAAK,CAAC,QAAN,CAAe,IAAf,EAAqB,MAArB,EAA6B,SAA7B,CAAhB,CADgB,CAEhB;;AACA,qDAAK,IAAI,EAAC,GAAG,CAAb,EAAgB,EAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,EAAxC,EAA2C;AACzC,sDAAM,MAAK,GAAG,SAAS,CAAC,EAAD,CAAvB;AACA,sDAAM,IAAG,GAAG,OAAO,CAAC,EAAD,CAAnB;AACA,kDAAA,GAAG,CAAC,IAAJ,CAAS,IAAT,EAHyC,CAIzC;;AACA,kDAAA,SAAS,CAAC,SAAS,MAAV,CAAT,GAA4B,IAA5B;AACD;AACF;AACF;AACF,2CAlCD;AA/ER;AAAA,iDAmHc,YAAY,CAAC,UAAb,CAAwB,UAAxB,EAAoC,SAApC,CAnHd;;AAAA;AAoHQ,0CAAA,oBAAoB,CAAC,SAAD,CAApB;;AApHR,+CAsHY,KAAK,CAAC,aAtHlB;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA2Ee,gCAAA,UA3Ef,GA2E4B,CA3E5B;;AAAA;AAAA,sCA2E+B,UAAU,GAAG,OAAO,CAAC,MA3EpD;AAAA;AAAA;AAAA;;AAAA,sEA2Ee,UA3Ef;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AA2E4D,kCAAE,UA3E9D;AAAA;AAAA;;AAAA;AA4HM,gCAAA,iBAAiB,CAAC,OAAlB;;AA5HN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,6BA+HU,YAAY,CAAC,UAAb,CAAwB,KAAxB,EAA+B,SAA/B,CA/HV;;AAAA;AAAA,2BAgIQ,KAAK,CAAC,aAhId;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA0DW,YAAA,KA1DX,GA0DmB,YA1DnB;;AAAA;AAAA,kBA0DiC,KAAK,GAAG,MA1DzC;AAAA;AAAA;AAAA;;AAAA,iDA0DW,KA1DX;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AA0DiD,cAAE,KA1DnD;AAAA;AAAA;;AAAA;AAAA;AAAA,mBAoIQ,YAAY,CAAC,UAAb,EApIR;;AAAA;AAAA;AAAA,mBAsIQ,KAAK,CAAC,OAAN,CAAc,QAAd,EAtIR;;AAAA;AAAA,8CAuIS,KAAK,CAAC,OAvIf;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA0IA,gBAAsB,UAAtB;AAAA;AAAA;AAwIA;;;;;AAKG;;;yEA7II,mBACH;AACA;AACA,EAAA,KAHG,EAGS,CAHT,EAIH,CAJG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAKH,YAAA,IALG,8DAKkB,EALlB;;AAAA,iBAMD,KAAK,CAAC,UANL;AAAA;AAAA;AAAA;;AAAA,kBAOG,IAAI,KAAJ,CACF,8DADE,CAPH;;AAAA;AAUL,YAAA,KAAK,CAAC,UAAN,GAAmB,IAAnB;AAVK;AAmBG,YAAA,SAnBH,GAmBe,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAnBlD;AAoBH,YAAA,cAAc,CAAC,SAAD,CAAd,CApBG,CAsBH;AACA;;AACM,YAAA,cAxBH,GAwBoB,KAxBpB;AAAA;AAAA,mBA0BO,KAAK,CAAC,mBAAN,CACF,CADE,EACC,CADD,EACI,IAAI,CAAC,YADT,EACuB,IAAI,CAAC,WAD5B,EACyC,cADzC,EAEF,SAFE,CA1BP;;AAAA;AAyBG,YAAA,gBAzBH;AA6BH,YAAA,MAAM,GAAG,gBAAgB,CAAC,CAAD,CAAzB;AACA,YAAA,OAAO,GAAG,gBAAgB,CAAC,CAAD,CAA1B;AACA,YAAA,aAAa,GAAG,gBAAgB,CAAC,CAAD,CAAhC,CA/BG,CAiCH;;AACI,YAAA,YAlCD,GAkCgB,KAlChB;;AAAA,kBAoCC,IAAI,CAAC,cAAL,IAAuB,IAAvB,IAA+B,IAAI,CAAC,cAAL,CAAoB,MAApB,GAA6B,CApC7D;AAAA;AAAA;AAAA;;AAqCD,YAAA,YAAY,GAAG,IAAf;;AArCC,kBAsCG,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CAtClC;AAAA;AAAA;AAAA;;AAuCC;AACA,YAAA,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;AACA,YAAA,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;AAzCD;AAAA;;AAAA;AAAA,kBA0CU,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CA1CzC;AAAA;AAAA;AAAA;;AAAA,kBA2CO,IAAI,mBAAJ,CACF,+DADE,CA3CP;;AAAA;AAAA,kBA8CO,IAAI,UAAJ,CACF,2HAEG,IAAI,CAAC,cAFR,iBADE,CA9CP;;AAAA;AAoDK,YAAA,eApDL,GAoDsB,IApDtB;AAAA;AAAA,mBAsDS,KAAK,CAAC,mBAAN,CACF,SADE,EACS,SADT,EACoB,IADpB;AAC0B;AAC5B,gBAFE;AAE0B;AAC5B,YAAA,eAHE,EAGc,SAHd,CAtDT;;AAAA;AAqDK,YAAA,eArDL;AA0DD,YAAA,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;AACA,YAAA,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;AACA,YAAA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT,CA5DC,CA6DD;;AA7DC;AAAA;;AAAA;AA8DI,gBACH,IAAI,CAAC,eAAL,IAAwB,IAAxB,IAAgC,IAAI,CAAC,eAAL,GAAuB,CAAvD,IACA,IAAI,CAAC,eAAL,GAAuB,CAFpB,EAEuB;AAC5B,cAAA,YAAY,GAAG,IAAf,CAD4B,CAE5B;;AACM,cAAA,OAHsB,GAIxB,IAAI,CAAC,KAAL,CAAW,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,KAAsB,IAAI,IAAI,CAAC,eAA/B,CAAX,CAJwB;AAKtB,cAAA,iBALsB,GAKF,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,CALE;AAM5B,cAAA,IAAI,GAAG,WAAW,CAAC,MAAD,EAAS,OAAT,EAAkB,iBAAlB,CAAlB;AACA,cAAA,MAAM,GAAG,WAAW,CAAC,MAAD,EAAS,CAAT,EAAY,OAAZ,CAApB;AACA,cAAA,IAAI,GAAG,WAAW,CAAC,OAAD,EAAU,OAAV,EAAmB,iBAAnB,CAAlB;AACA,cAAA,OAAO,GAAG,WAAW,CAAC,OAAD,EAAU,CAAV,EAAa,OAAb,CAArB,CAT4B,CAU5B;AACA;;AACA,cAAA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT,CAZ4B,CAc5B;AACD,aAjBM,MAiBA,IAAI,IAAI,CAAC,eAAL,IAAwB,IAA5B,EAAkC;AACvC,cAAA,YAAY,GAAG,IAAf,CADuC,CAEvC;AACD;;AAlFE;AAoFG,YAAA,GApFH,GAoFS,MAAM,CAAC,MAAP,CAAc,OAAd,EAAuB,MAAvB,CAA8B,aAA9B,CApFT;AAsFH,YAAA,KAAK,CAAC,gCAAN,GAtFG,CAwFH;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACM,YAAA,aApGH,GAoGmB,KAAK,CAAC,iBAAN,EApGnB;AAqGG,YAAA,SArGH,GAqGe,KAAK,CAAC,sBAAN,EArGf;;AAyGH,gBAAI,YAAJ,EAAkB;AAChB,cAAA,KAAK,CAAC,gBAAN;AACA,cAAA,WAAW,GAAG,KAAK,CAAC,YAApB;AACA,cAAA,eAAe,GACX,SAAS,CAAC,KAAV,GAAkB,MAAlB,CAAyB,SAAS,CAAC,GAAV,CAAc,UAAA,CAAC;AAAA,uBAAI,SAAS,CAAb;AAAA,eAAf,CAAzB,CADJ;AAED,aALD,MAKO;AACL,cAAA,WAAW,GAAG,IAAd;AACA,cAAA,MAAM,GAAG,EAAT;AACA,cAAA,eAAe,GAAG,SAAS,CAAC,KAAV,EAAlB;AACD;;AAEK,YAAA,SApHH,GAoHe,oBAAoB,CAAC,IAAI,CAAC,SAAN,EAAiB,IAAI,CAAC,UAAtB,CApHnC;AAAA;AAAA,mBAqHe,OAAO,CACrB,KADqB,EACd,aADc,EACC,GADD,EACM,SADN,EACiB,SADjB,EAC4B,IAAI,CAAC,MADjC,EAErB,IAAI,CAAC,OAFgB,EAEP,SAFO,EAEI,WAFJ,EAEiB,MAFjB,EAEyB,IAAI,CAAC,OAF9B,EAGrB,eAHqB,EAGJ,IAAI,CAAC,YAHD,EAGe,IAHf,EAGqB,IAHrB,CArHtB;;AAAA;AAqHG,YAAA,GArHH;AAAA,8CAyHI,GAzHJ;;AAAA;AAAA;AA2HH,YAAA,KAAK,CAAC,UAAN,GAAmB,KAAnB,CA3HG,CA4HH;;AACA,YAAA,iBAAiB,CAAC,MAAD,EAAS,CAAT,CAAjB;AACA,YAAA,iBAAiB,CAAC,OAAD,EAAU,CAAV,CAAjB;AACA,YAAA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;AACA,YAAA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;;AACA,gBAAI,aAAa,IAAI,IAArB,EAA2B;AACzB,cAAA,GAAG,CAAC,OAAJ,CAAY,aAAZ;AACD;;AAnIE;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA8IP,OAAM,SAAU,0BAAV,CAAqC,OAArC,EAA6D;AACjE,MAAM,IAAI,GAAa,EAAvB;;AACA,MAAI,OAAO,YAAY,MAAvB,EAA+B;AAC7B,IAAA,OAAO,GAAG,CAAC,OAAD,CAAV;AACD,GAJgE,CAMjE;;;AACA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;AACvC,QAAM,MAAM,GAAG,OAAO,CAAC,CAAD,CAAtB;;AACA,QAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;AACrB,MAAA,IAAI,CAAC,IAAL,CAAU,UAAU,CAAC,MAAD,EAAS,CAAT,CAApB;AACD,KAFD,MAEO,IAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;AAC5B,YAAM,IAAI,KAAJ,CACF,iEACA,WAFE,CAAN;AAGD,KAJM,MAIA;AACL,MAAA,IAAI,CAAC,IAAL,CAAU,MAAV;AACD;AACF;;AACD,SAAO,IAAP;AACD;AAED;;;;;;;;;;AAUG;AACH;;AACA,OAAM,SAAU,iBAAV,CACF,OADE,EAEF,UAFE,EAEuD;AAC3D,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB;AACD;;AACD,MAAM,YAAY,GAAa,EAA/B;;AACA,MAAI,UAAU,YAAY,MAA1B,EAAkC;AAChC,IAAA,YAAY,CAAC,IAAb,CAAkB,UAAU,CAAC,EAA7B;AACD,GAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,UAAd,CAAJ,EAA+B;AACpC,IAAA,UAAU,CAAC,OAAX,CAAmB,UAAA,CAAC;AAAA,aAAI,YAAY,CAAC,IAAb,CAAkB,CAAC,CAAC,EAApB,CAAJ;AAAA,KAApB;AACD,GAFM,MAEA,IAAI,UAAU,IAAI,IAAlB,EAAwB;AAC7B;AACA,SAAK,IAAM,IAAX,IAAmB,UAAnB,EAA+B;AAC7B,UAAM,SAAS,GAAG,UAAU,CAAC,IAAD,CAA5B;AACA,MAAA,YAAY,CAAC,IAAb,CAAkB,SAAS,CAAC,EAA5B;AACD;AACF;;AAED,MAAM,gBAAgB,GAAa,EAAnC;;AACA,MAAI,OAAO,YAAY,MAAvB,EAA+B;AAC7B,QAAI,YAAY,CAAC,OAAb,CAAqB,OAAO,CAAC,EAA7B,MAAqC,CAAC,CAA1C,EAA6C;AAC3C,MAAA,gBAAgB,CAAC,IAAjB,CAAsB,OAAtB;AACD;AACF,GAJD,MAIO,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,CAAJ,EAA4B;AACjC,IAAA,OAAO,CAAC,OAAR,CAAgB,UAAA,CAAC,EAAG;AAClB,UAAI,YAAY,CAAC,OAAb,CAAqB,CAAC,CAAC,EAAvB,MAA+B,CAAC,CAApC,EAAuC;AACrC,QAAA,gBAAgB,CAAC,IAAjB,CAAsB,CAAtB;AACD;AACF,KAJD;AAKD,GANM,MAMA,IAAI,OAAO,IAAI,IAAf,EAAqB;AAC1B;AACA,SAAK,IAAM,KAAX,IAAmB,OAAnB,EAA4B;AAC1B,UAAM,MAAM,GAAG,OAAO,CAAC,KAAD,CAAtB;;AACA,UAAI,YAAY,CAAC,OAAb,CAAqB,MAAM,CAAC,EAA5B,MAAoC,CAAC,CAAzC,EAA4C;AAC1C,QAAA,gBAAgB,CAAC,IAAjB,CAAsB,MAAtB;AACD;AACF;AACF;;AAED,EAAA,gBAAgB,CAAC,OAAjB,CAAyB,UAAA,CAAC,EAAG;AAC3B,QAAI,CAAC,CAAC,CAAC,UAAP,EAAmB;AACjB,MAAA,CAAC,CAAC,OAAF;AACD;AACF,GAJD;AAKD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n    }\n    else { // Tensor.\n        return sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(() => {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(array => sliceArraysByIndices(array, indices));\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n    const output = [];\n    let batchStart = 0;\n    let batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n        batchSize = 32;\n    }\n    if (epochs == null) {\n        epochs = 1;\n    }\n    if (shuffle == null) {\n        shuffle = true;\n    }\n    if (initialEpoch == null) {\n        initialEpoch = 0;\n    }\n    // TODO(cais): Change const to let below when implementing validation.\n    let doValidation = false;\n    if (valF != null && valIns != null) {\n        doValidation = true;\n        // TODO(cais): verbose message.\n    }\n    if (validationSteps != null) {\n        doValidation = true;\n        if (stepsPerEpoch == null) {\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                'i.e., `stepsPerEpoch` must be set.');\n        }\n    }\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n    if (numTrainSamples != null) {\n        indexArray = range(0, numTrainSamples);\n    }\n    if (verbose == null) {\n        verbose = 1;\n    }\n    const { callbackList, history } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n        await callbackList.onEpochBegin(epoch);\n        const epochLogs = {};\n        if (stepsPerEpoch != null) {\n            throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n        }\n        else {\n            if (shuffle === 'batch') {\n                throw new NotImplementedError('batch shuffling is not implemneted yet');\n            }\n            else if (shuffle) {\n                util.shuffle(indexArray);\n            }\n            // Convert the potentially shuffled indices to Tensor1D, to avoid the\n            // cost of repeated creation of Array1Ds later on.\n            const epochIndexArray1D = tensor1d(indexArray);\n            const batches = makeBatches(numTrainSamples, batchSize);\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchLogs = {};\n                await callbackList.onBatchBegin(batchIndex, batchLogs);\n                tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = batchEnd - batchStart;\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const outs = f(insBatch);\n                    for (let i = 0; i < outLabels.length; ++i) {\n                        const label = outLabels[i];\n                        const out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                        // TODO(cais): Use scope() to avoid ownership.\n                    }\n                    if (batchIndex === batches.length - 1) { // Last batch.\n                        if (doValidation) {\n                            const valOuts = model.testLoop(valF, valIns, batchSize);\n                            // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                            for (let i = 0; i < outLabels.length; ++i) {\n                                const label = outLabels[i];\n                                const out = valOuts[i];\n                                tfc.keep(out);\n                                // TODO(cais): Use scope() to avoid ownership.\n                                epochLogs['val_' + label] = out;\n                            }\n                        }\n                    }\n                });\n                await callbackList.onBatchEnd(batchIndex, batchLogs);\n                disposeTensorsInLogs(batchLogs);\n                if (model.stopTraining_) {\n                    break;\n                }\n                // TODO(cais): return outs as list of Tensor.\n            }\n            epochIndexArray1D.dispose();\n        }\n        // TODO(cais): Run validation at the end of the epoch.\n        await callbackList.onEpochEnd(epoch, epochLogs);\n        if (model.stopTraining_) {\n            break;\n        }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n    if (model.isTraining) {\n        throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n    try {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // Validate user data.\n        // TODO(cais): Support sampleWeight.\n        const checkBatchAxis = false;\n        const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        sampleWeights = standardizedOuts[2];\n        // Prepare validation data.\n        let doValidation = false;\n        let valIns;\n        if (args.validationData != null && args.validationData.length > 0) {\n            doValidation = true;\n            if (args.validationData.length === 2) {\n                // config.validationData consists of valX and valY.\n                inputValX = args.validationData[0];\n                inputValY = args.validationData[1];\n            }\n            else if (args.validationData.length === 3) {\n                throw new NotImplementedError('validationData including sample weights is not supported yet.');\n            }\n            else {\n                throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` +\n                    `or 3 (valX, valY, valSampleWeight) items; ` +\n                    `${args.validationData} is invalid.`);\n            }\n            const checkBatchAxis = true;\n            const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis, batchSize);\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSplit != null && args.validationSplit > 0 &&\n            args.validationSplit < 1) {\n            doValidation = true;\n            // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            const originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            // TODO(cais): Once sampleWeights becomes available, slice it to get\n            //   valSampleWeights.\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSteps != null) {\n            doValidation = true;\n            // TODO(cais): Add useLearningPhase.\n        }\n        const ins = inputs.concat(targets).concat(sampleWeights);\n        model.checkTrainableWeightsConsistency();\n        // TODO(cais): Handle use_learning_phase and learning_phase?\n        // Porting Note: Here we see a key deviation of tfjs-layers from\n        // Keras.\n        //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n        //  we do not construct symbolic computation graphs to embody the\n        //  training process. Instead, we define a function that performs the\n        //  training action. In PyKeras, the data (inputs and targets) are fed\n        //  through graph placeholders. In tfjs-layers, the data are fed as\n        //  function arguments. Since the function are defined below in the\n        //  scope, we don't have equivalents of PyKeras's\n        //  `_make_train_funciton`.\n        const trainFunction = model.makeTrainFunction();\n        const outLabels = model.getDedupedMetricsNames();\n        let valFunction;\n        let callbackMetrics;\n        if (doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics =\n                outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n        }\n        else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n        }\n        const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n        const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n        return out;\n    }\n    finally {\n        model.isTraining = false;\n        // Memory clean up.\n        disposeNewTensors(inputs, x);\n        disposeNewTensors(targets, y);\n        disposeNewTensors(valX, inputValX);\n        disposeNewTensors(valY, inputValY);\n        if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n        }\n    }\n    // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n    const outs = [];\n    if (tensors instanceof Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (let i = 0; i < tensors.length; ++i) {\n        const tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    const oldTensorIds = [];\n    if (refTensors instanceof Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(t => oldTensorIds.push(t.id));\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in refTensors) {\n            const oldTensor = refTensors[name];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    const tensorsToDispose = [];\n    if (tensors instanceof Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(t => {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in tensors) {\n            const tensor = tensors[name];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(t => {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\n//# sourceMappingURL=training_tensors.js.map"]},"metadata":{},"sourceType":"module"}