{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, notEqual, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n  constructor(args) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0); // So that the scalar doesn't get tidied up between executions.\n\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  getNoiseShape(input) {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n\n    const inputShape = input.shape;\n    const noiseShape = [];\n\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n\n    return noiseShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n\n      if (0 < this.rate && this.rate < 1) {\n        const training = kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n        return output;\n      }\n\n      return inputs;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  dispose() {\n    return super.dispose();\n  }\n\n}\n/** @nocollapse */\n\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n  constructor(args) {\n    super(args);\n    this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getNoiseShape(input) {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n\n}\n/** @nocollapse */\n\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n  constructor(args) {\n    super(args); // Default activation: Linear (none).\n\n    this.activation = null;\n    this.useBias = true;\n    this.kernel = null;\n    this.bias = null;\n    this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n\n    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n\n    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n    this.inputSpec = [{\n      minNDim: 2\n    }];\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n\n    if (this.kernel == null) {\n      this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{\n      minNDim: 2,\n      axes: {\n        [-1]: inputLastDim\n      }\n    }];\n    this.built = true;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs); // Dense layer accepts only a single input.\n\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n      let output;\n\n      if (fusedActivationName != null) {\n        output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n  constructor(args) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{\n      minNDim: 3\n    }];\n    this.dataFormat = args.dataFormat;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` + `(got ${inputShape.slice(1)}). Make sure to pass a complete ` + `\"input_shape\" or \"batch_input_shape\" argument to the first ` + `layer in your model.`);\n      }\n    }\n\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      let input = getExactlyOneTensor(inputs);\n\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation = [0];\n\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n\n        permutation.push(1);\n        input = input.transpose(permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  getConfig() {\n    const config = {};\n\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n  constructor(args) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      activation: serializeActivation(this.activation)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n  constructor(args) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{\n      ndim: 2\n    }];\n  }\n\n  computeOutputShape(inputShape) {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      n: this.n\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n  constructor(args) {\n    super(args);\n    this.targetShape = args.targetShape; // Make sure that all unknown dimensions are represented as `null`.\n\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  isUnknown(dim) {\n    return dim < 0 || dim == null;\n  }\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n\n\n  fixUnknownDimension(inputShape, outputShape) {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  computeOutputShape(inputShape) {\n    let anyUnknownDims = false;\n\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return input.reshape(outputShape);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      targetShape: this.targetShape\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n  constructor(args) {\n    super(args);\n\n    if (args.dims == null) {\n      throw new Error('Required configuration field `dims` is missing during Permute ' + 'constructor call.');\n    }\n\n    if (!Array.isArray(args.dims)) {\n      throw new Error('Permute constructor requires `dims` to be an Array, but received ' + `${args.dims} instead.`);\n    } // Check the validity of the permutation indices.\n\n\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) + ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({\n      ndim: this.dims.length + 1\n    })];\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim, i) => {\n      outputShape[i + 1] = inputShape[dim];\n    });\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  getConfig() {\n    const config = {\n      dims: this.dims\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n  constructor(args) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  computeOutputShape(inputShape) {\n    return inputShape;\n  }\n\n  getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {\n      maskValue: this.maskValue\n    };\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  computeMask(inputs, mask) {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = input.mul(booleanMask.asType(input.dtype));\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMasking.className = 'Masking';\nserialization.registerClass(Masking);","map":{"version":3,"sources":["../../src/layers/core.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;AAEH;;AAEG;AAEH,SAAQ,GAAR,EAAa,QAAb,EAAuB,aAAvB,EAA8C,IAA9C,EAAoD,SAApD,EAA+D,IAA/D,QAA0E,uBAA1E;AAEA,SAAoC,aAApC,EAAmD,mBAAnD,QAA6E,gBAA7E;AACA,OAAO,KAAK,CAAZ,MAAmB,yBAAnB;AACA,SAA0C,aAA1C,EAAyD,mBAAzD,QAAmF,gBAAnF;AACA,SAAuB,SAAvB,EAAkC,KAAlC,QAAyD,oBAAzD;AACA,SAAQ,UAAR,QAAyB,WAAzB;AACA,SAAQ,cAAR,EAA4D,oBAA5D,QAAuF,iBAAvF;AAIA,SAAQ,cAAR,EAA4D,oBAA5D,QAAuF,iBAAvF;AAEA,SAAQ,qBAAR,EAA+B,0BAA/B,QAAgE,wBAAhE;AACA,SAAQ,SAAR,EAAmB,KAAnB,QAA+B,qBAA/B;AACA,SAAQ,kBAAR,EAA4B,mBAA5B,QAAsD,sBAAtD;AAqBA,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;AAOhC,EAAA,WAAA,CAAY,IAAZ,EAAkC;AAChC,UAAM,IAAN;AACA,SAAK,IAAL,GAAY,IAAI,CAAC,GAAL,CAAS,IAAI,CAAC,GAAL,CAAS,IAAI,CAAC,IAAd,EAAoB,CAApB,CAAT,EAAiC,CAAjC,CAAZ,CAFgC,CAGhC;;AACA,SAAK,UAAL,GAAkB,IAAI,CAAC,UAAvB;AACA,SAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;AACA,SAAK,eAAL,GAAuB,IAAvB;AACD;;AAES,EAAA,aAAa,CAAC,KAAD,EAAc;AACnC,QAAI,KAAK,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,aAAO,KAAK,UAAZ;AACD;;AACD,UAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;AACA,UAAM,UAAU,GAAU,EAA1B;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,UAAL,CAAgB,MAApC,EAA4C,EAAE,CAA9C,EAAiD;AAC/C,MAAA,UAAU,CAAC,IAAX,CACI,KAAK,UAAL,CAAgB,CAAhB,KAAsB,IAAtB,GAA6B,UAAU,CAAC,CAAD,CAAvC,GAA6C,KAAK,UAAL,CAAgB,CAAhB,CADjD;AAED;;AACD,WAAO,UAAP;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B;AACA,YAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;;AACA,UAAI,IAAI,KAAK,IAAT,IAAiB,KAAK,IAAL,GAAY,CAAjC,EAAoC;AAClC,cAAM,QAAQ,GACV,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqC,MAAM,CAAC,UAAD,CAD/C;AAEA,cAAM,UAAU,GAAG,KAAK,aAAL,CAAmB,KAAnB,CAAnB;AACA,cAAM,MAAM,GAAG,CAAC,CAAC,YAAF,CACX,MAAM,CAAC,CAAC,OAAF,CAAU,KAAV,EAAiB,KAAK,IAAtB,EAA4B,UAA5B,EAAwC,KAAK,IAA7C,CADK,EAEX,MAAM,KAFK,EAEE,QAFF,CAAf;AAGA,eAAO,MAAP;AACD;;AACD,aAAO,MAAP;AACD,KAbU,CAAX;AAcD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAAG;AACb,MAAA,IAAI,EAAE,KAAK,IADE;AAEb,MAAA,UAAU,EAAE,KAAK,UAFJ;AAGb,MAAA,IAAI,EAAE,KAAK;AAHE,KAAf;AAKA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,MAAM,OAAN,EAAP;AACD;;AA3D+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AA2DT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AA4DA,OAAM,MAAO,gBAAP,SAAgC,OAAhC,CAAuC;AAI3C,EAAA,WAAA,CAAY,IAAZ,EAA6C;AAC3C,UAAM,IAAN;AACA,SAAK,SAAL,GAAiB,CAAC;AAAC,MAAA,IAAI,EAAE;AAAP,KAAD,CAAjB;AACD;;AAES,EAAA,aAAa,CAAC,KAAD,EAAc;AACnC,UAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;AACA,WAAO,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,CAAhB,EAAmB,UAAU,CAAC,CAAD,CAA7B,CAAP;AACD;;AAZ0C;AAC3C;;AACO,gBAAA,CAAA,SAAA,GAAY,kBAAZ;AAYT,aAAa,CAAC,aAAd,CAA4B,gBAA5B;AAEA,OAAM,MAAO,KAAP,SAAqB,KAArB,CAA0B;AAmB9B,EAAA,WAAA,CAAY,IAAZ,EAAgC;AAC9B,UAAM,IAAN,EAD8B,CAfhC;;AACQ,SAAA,UAAA,GAA2B,IAA3B;AACA,SAAA,OAAA,GAAU,IAAV;AAGA,SAAA,MAAA,GAAwB,IAAxB;AACA,SAAA,IAAA,GAAsB,IAAtB;AAEC,SAAA,0BAAA,GAAoD,cAApD;AACA,SAAA,wBAAA,GAAkD,OAAlD;;AAQP,QAAI,IAAI,CAAC,eAAL,IAAwB,IAAxB,IAAgC,IAAI,CAAC,UAAL,IAAmB,IAAnD,IACA,IAAI,CAAC,QAAL,IAAiB,IADrB,EAC2B;AACzB;AACA;AACA,UAAI,SAAS,GAAW,IAAxB;;AACA,UAAI,IAAI,CAAC,SAAL,IAAkB,IAAtB,EAA4B;AAC1B,QAAA,SAAS,GAAG,IAAI,CAAC,SAAjB;AACD;;AACD,WAAK,eAAL,GAAuB,CAAC,SAAD,EAAY,IAAI,CAAC,QAAjB,CAAvB;AACD;;AAED,SAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;AACA,IAAA,qBAAqB,CAAC,KAAK,KAAN,EAAa,OAAb,CAArB;AACA,SAAK,UAAL,GAAkB,aAAa,CAAC,IAAI,CAAC,UAAN,CAA/B;;AACA,QAAI,IAAI,CAAC,OAAL,IAAgB,IAApB,EAA0B;AACxB,WAAK,OAAL,GAAe,IAAI,CAAC,OAApB;AACD;;AACD,SAAK,iBAAL,GAAyB,cAAc,CACnC,IAAI,CAAC,iBAAL,IAA0B,KAAK,0BADI,CAAvC;AAEA,SAAK,eAAL,GACI,cAAc,CAAC,IAAI,CAAC,eAAL,IAAwB,KAAK,wBAA9B,CADlB;AAEA,SAAK,gBAAL,GAAwB,aAAa,CAAC,IAAI,CAAC,gBAAN,CAArC;AACA,SAAK,cAAL,GAAsB,aAAa,CAAC,IAAI,CAAC,cAAN,CAAnC;AACA,SAAK,iBAAL,GAAyB,cAAc,CAAC,IAAI,CAAC,iBAAN,CAAvC;AACA,SAAK,eAAL,GAAuB,cAAc,CAAC,IAAI,CAAC,eAAN,CAArC;AACA,SAAK,mBAAL,GAA2B,cAAc,CAAC,IAAI,CAAC,mBAAN,CAAzC;AACA,SAAK,eAAL,GAAuB,IAAvB;AAEA,SAAK,SAAL,GAAiB,CAAC;AAAC,MAAA,OAAO,EAAE;AAAV,KAAD,CAAjB;AACD;;AAEM,EAAA,KAAK,CAAC,UAAD,EAA0B;AACpC,IAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;AACA,UAAM,YAAY,GAAG,UAAU,CAAC,UAAU,CAAC,MAAX,GAAoB,CAArB,CAA/B;;AACA,QAAI,KAAK,MAAL,IAAe,IAAnB,EAAyB;AACvB,WAAK,MAAL,GAAc,KAAK,SAAL,CACV,QADU,EACA,CAAC,YAAD,EAAe,KAAK,KAApB,CADA,EAC4B,IAD5B,EACkC,KAAK,iBADvC,EAEV,KAAK,iBAFK,EAEc,IAFd,EAEoB,KAAK,gBAFzB,CAAd;;AAGA,UAAI,KAAK,OAAT,EAAkB;AAChB,aAAK,IAAL,GAAY,KAAK,SAAL,CACR,MADQ,EACA,CAAC,KAAK,KAAN,CADA,EACc,IADd,EACoB,KAAK,eADzB,EAER,KAAK,eAFG,EAEc,IAFd,EAEoB,KAAK,cAFzB,CAAZ;AAGD;AACF;;AAED,SAAK,SAAL,GAAiB,CAAC;AAAC,MAAA,OAAO,EAAE,CAAV;AAAa,MAAA,IAAI,EAAE;AAAC,SAAC,CAAC,CAAF,GAAM;AAAP;AAAnB,KAAD,CAAjB;AACA,SAAK,KAAL,GAAa,IAAb;AACD;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAA0B;AAC1C,IAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;AACA,UAAM,WAAW,GAAG,UAAU,CAAC,KAAX,EAApB;AACA,IAAA,WAAW,CAAC,WAAW,CAAC,MAAZ,GAAqB,CAAtB,CAAX,GAAsC,KAAK,KAA3C;AACA,WAAO,WAAP;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B,EADe,CAEf;;AACA,YAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;AACA,YAAM,mBAAmB,GACrB,0BAA0B,CAAC,KAAK,UAAL,CAAgB,YAAhB,EAAD,CAD9B;AAEA,UAAI,MAAJ;;AAEA,UAAI,mBAAmB,IAAI,IAA3B,EAAiC;AAC/B,QAAA,MAAM,GAAG,CAAC,CAAC,GAAF,CACL,KADK,EACE,KAAK,MAAL,CAAY,IAAZ,EADF,EACsB,mBADtB,EAEL,KAAK,IAAL,GAAY,KAAK,IAAL,CAAU,IAAV,EAAZ,GAA+B,IAF1B,CAAT;AAGD,OAJD,MAIO;AACL,QAAA,MAAM,GAAG,CAAC,CAAC,GAAF,CAAM,KAAN,EAAa,KAAK,MAAL,CAAY,IAAZ,EAAb,CAAT;;AACA,YAAI,KAAK,IAAL,IAAa,IAAjB,EAAuB;AACrB,UAAA,MAAM,GAAG,CAAC,CAAC,OAAF,CAAU,MAAV,EAAkB,KAAK,IAAL,CAAU,IAAV,EAAlB,CAAT;AACD;;AACD,YAAI,KAAK,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,UAAA,MAAM,GAAG,KAAK,UAAL,CAAgB,KAAhB,CAAsB,MAAtB,CAAT;AACD;AACF;;AAED,aAAO,MAAP;AACD,KAvBU,CAAX;AAwBD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAA6B;AACvC,MAAA,KAAK,EAAE,KAAK,KAD2B;AAEvC,MAAA,UAAU,EAAE,mBAAmB,CAAC,KAAK,UAAN,CAFQ;AAGvC,MAAA,OAAO,EAAE,KAAK,OAHyB;AAIvC,MAAA,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CAJA;AAKvC,MAAA,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CALE;AAMvC,MAAA,iBAAiB,EAAE,oBAAoB,CAAC,KAAK,iBAAN,CANA;AAOvC,MAAA,eAAe,EAAE,oBAAoB,CAAC,KAAK,eAAN,CAPE;AAQvC,MAAA,mBAAmB,EAAE,oBAAoB,CAAC,KAAK,mBAAN,CARF;AASvC,MAAA,gBAAgB,EAAE,mBAAmB,CAAC,KAAK,gBAAN,CATE;AAUvC,MAAA,cAAc,EAAE,mBAAmB,CAAC,KAAK,cAAN;AAVI,KAAzC;AAYA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AAxH6B;AAC9B;;AACO,KAAA,CAAA,SAAA,GAAY,OAAZ;AAwHT,aAAa,CAAC,aAAd,CAA4B,KAA5B;AAOA,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;AAKhC,EAAA,WAAA,CAAY,IAAZ,EAAmC;AACjC,IAAA,IAAI,GAAG,IAAI,IAAI,EAAf;AACA,UAAM,IAAN;AACA,SAAK,SAAL,GAAiB,CAAC;AAAC,MAAA,OAAO,EAAE;AAAV,KAAD,CAAjB;AACA,SAAK,UAAL,GAAkB,IAAI,CAAC,UAAvB;AACD;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAA0B;AAC1C,IAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;;AACA,SAAK,MAAM,GAAX,IAAkB,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAlB,EAAuC;AACrC,UAAI,GAAG,IAAI,IAAX,EAAiB;AACf,cAAM,IAAI,UAAJ,CACF,2DAAA,GACA,QAAQ,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAmB,kCAD3B,GAEA,6DAFA,GAGA,sBAJE,CAAN;AAKD;AACF;;AACD,WAAO,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,SAAS,CAAC,UAAD,EAAa,CAAb,CAAzB,CAAP;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B;AAEA,UAAI,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAA/B;;AACA,UAAI,KAAK,UAAL,KAAoB,eAApB,IAAuC,KAAK,CAAC,IAAN,GAAa,CAAxD,EAA2D;AACzD,cAAM,WAAW,GAAa,CAAC,CAAD,CAA9B;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,IAA1B,EAAgC,EAAE,CAAlC,EAAqC;AACnC,UAAA,WAAW,CAAC,IAAZ,CAAiB,CAAjB;AACD;;AACD,QAAA,WAAW,CAAC,IAAZ,CAAiB,CAAjB;AACA,QAAA,KAAK,GAAG,KAAK,CAAC,SAAN,CAAgB,WAAhB,CAAR;AACD;;AAED,aAAO,CAAC,CAAC,YAAF,CAAe,KAAf,CAAP;AACD,KAdU,CAAX;AAeD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAA6B,EAAzC;;AACA,QAAI,KAAK,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,MAAA,MAAM,CAAC,YAAD,CAAN,GAAuB,KAAK,UAA5B;AACD;;AACD,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AApD+B;AAGhC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAkDT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AASA,OAAM,MAAO,UAAP,SAA0B,KAA1B,CAA+B;AAKnC,EAAA,WAAA,CAAY,IAAZ,EAAqC;AACnC,UAAM,IAAN;AACA,SAAK,eAAL,GAAuB,IAAvB;AACA,SAAK,UAAL,GAAkB,aAAa,CAAC,IAAI,CAAC,UAAN,CAA/B;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B;AACA,YAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;AACA,aAAO,KAAK,UAAL,CAAgB,KAAhB,CAAsB,KAAtB,CAAP;AACD,KAJU,CAAX;AAKD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAAG;AAAC,MAAA,UAAU,EAAE,mBAAmB,CAAC,KAAK,UAAN;AAAhC,KAAf;AACA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AAxBkC;AACnC;;AACO,UAAA,CAAA,SAAA,GAAY,YAAZ;AAwBT,aAAa,CAAC,aAAd,CAA4B,UAA5B;AAcA,OAAM,MAAO,YAAP,SAA4B,KAA5B,CAAiC;AAKrC,EAAA,WAAA,CAAY,IAAZ,EAAuC;AACrC,UAAM,IAAN;AACA,SAAK,CAAL,GAAS,IAAI,CAAC,CAAd;AACA,SAAK,SAAL,GAAiB,CAAC;AAAC,MAAA,IAAI,EAAE;AAAP,KAAD,CAAjB;AACD;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAAkB;AAClC,WAAO,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,KAAK,CAArB,EAAwB,UAAU,CAAC,CAAD,CAAlC,CAAP;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,MAAA,MAAM,GAAG,mBAAmB,CAAC,MAAD,CAA5B;AACA,aAAO,CAAC,CAAC,MAAF,CAAS,MAAT,EAAiB,KAAK,CAAtB,CAAP;AACD,KAHU,CAAX;AAID;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAAG;AACb,MAAA,CAAC,EAAE,KAAK;AADK,KAAf;AAGA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AA7BoC;AACrC;;AACO,YAAA,CAAA,SAAA,GAAY,cAAZ;AA6BT,aAAa,CAAC,aAAd,CAA4B,YAA5B;AAEA,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;AAKhC,EAAA,WAAA,CAAY,IAAZ,EAAkC;AAChC,UAAM,IAAN;AACA,SAAK,WAAL,GAAmB,IAAI,CAAC,WAAxB,CAFgC,CAIhC;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,WAAL,CAAiB,MAArC,EAA6C,EAAE,CAA/C,EAAkD;AAChD,UAAI,KAAK,SAAL,CAAe,KAAK,WAAL,CAAiB,CAAjB,CAAf,CAAJ,EAAyC;AACvC,aAAK,WAAL,CAAiB,CAAjB,IAAsB,IAAtB;AACD;AACF;AACF;;AAEO,EAAA,SAAS,CAAC,GAAD,EAAY;AAC3B,WAAO,GAAG,GAAG,CAAN,IAAW,GAAG,IAAI,IAAzB;AACD;AAED;;;;;;;;;;;;;AAaG;;;AACK,EAAA,mBAAmB,CAAC,UAAD,EAAoB,WAApB,EAAsC;AAC/D,UAAM,QAAQ,GAAG,4CAAjB;AACA,UAAM,UAAU,GAAG,WAAW,CAAC,KAAZ,EAAnB;AACA,QAAI,KAAK,GAAG,CAAZ;AACA,QAAI,OAAO,GAAG,IAAd;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;AAC1C,YAAM,GAAG,GAAG,UAAU,CAAC,CAAD,CAAtB;;AACA,UAAI,KAAK,SAAL,CAAe,GAAf,CAAJ,EAAyB;AACvB,YAAI,OAAO,KAAK,IAAhB,EAAsB;AACpB,UAAA,OAAO,GAAG,CAAV;AACD,SAFD,MAEO;AACL,gBAAM,IAAI,UAAJ,CAAe,0CAAf,CAAN;AACD;AACF,OAND,MAMO;AACL,QAAA,KAAK,IAAI,GAAT;AACD;AACF;;AAED,UAAM,YAAY,GAAG,SAAS,CAAC,UAAD,CAA9B;;AACA,QAAI,OAAO,KAAK,IAAhB,EAAsB;AACpB,UAAI,KAAK,KAAK,CAAV,IAAe,YAAY,GAAG,KAAf,KAAyB,CAA5C,EAA+C;AAC7C,cAAM,IAAI,UAAJ,CAAe,QAAf,CAAN;AACD;;AACD,MAAA,UAAU,CAAC,OAAD,CAAV,GAAsB,YAAY,GAAG,KAArC;AACD,KALD,MAKO,IAAI,YAAY,KAAK,KAArB,EAA4B;AACjC,YAAM,IAAI,UAAJ,CAAe,QAAf,CAAN;AACD;;AAED,WAAO,UAAP;AACD;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAAkB;AAClC,QAAI,cAAc,GAAG,KAArB;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;AAC1C,UAAI,KAAK,SAAL,CAAe,UAAU,CAAC,CAAD,CAAzB,CAAJ,EAAmC;AACjC,QAAA,cAAc,GAAG,IAAjB;AACA;AACD;AACF;;AAED,QAAI,cAAJ,EAAoB;AAClB,aAAO,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB,MAAvB,CAA8B,KAAK,WAAnC,CAAP;AACD,KAFD,MAEO;AACL,aAAO,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB,MAAvB,CACH,KAAK,mBAAL,CAAyB,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAK,WAAnD,CADG,CAAP;AAED;AACF;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B;AACA,YAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;AACA,YAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;AACA,YAAM,WAAW,GAAG,UAAU,CAAC,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB,MAAvB,CAChB,KAAK,mBAAL,CAAyB,UAAU,CAAC,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAK,WAAnD,CADgB,CAApB;AAEA,aAAO,KAAK,CAAC,OAAN,CAAc,WAAd,CAAP;AACD,KAPU,CAAX;AAQD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAAG;AACb,MAAA,WAAW,EAAE,KAAK;AADL,KAAf;AAGA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AArG+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAqGT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAYA,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;AAMhC,EAAA,WAAA,CAAY,IAAZ,EAAkC;AAChC,UAAM,IAAN;;AACA,QAAI,IAAI,CAAC,IAAL,IAAa,IAAjB,EAAuB;AACrB,YAAM,IAAI,KAAJ,CACF,mEACA,mBAFE,CAAN;AAGD;;AACD,QAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAL,EAA+B;AAC7B,YAAM,IAAI,KAAJ,CACF,sEACA,GAAG,IAAI,CAAC,IAAI,WAFV,CAAN;AAGD,KAX+B,CAahC;;;AACA,UAAM,qBAAqB,GAAG,KAAK,CAAC,CAAD,EAAI,IAAI,CAAC,IAAL,CAAU,MAAV,GAAmB,CAAvB,CAAnC;;AACA,QAAI,CAAC,IAAI,CAAC,WAAL,CAAiB,IAAI,CAAC,IAAL,CAAU,KAAV,GAAkB,IAAlB,EAAjB,EAA2C,qBAA3C,CAAL,EAAwE;AACtE,YAAM,IAAI,KAAJ,CACF,iCAAiC,IAAI,CAAC,SAAL,CAAe,IAAI,CAAC,IAApB,CAAjC,GACA,4DAFE,CAAN;AAGD;;AAED,SAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;AACA,SAAK,kBAAL,GAA0B,CAAC,CAAD,EAAI,MAAJ,CAAW,KAAK,IAAhB,CAA1B;AACA,SAAK,SAAL,GAAiB,CAAC,IAAI,SAAJ,CAAc;AAAC,MAAA,IAAI,EAAE,KAAK,IAAL,CAAU,MAAV,GAAmB;AAA1B,KAAd,CAAD,CAAjB;AACD;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAA0B;AAC1C,IAAA,UAAU,GAAG,kBAAkB,CAAC,UAAD,CAA/B;AACA,UAAM,WAAW,GAAG,UAAU,CAAC,KAAX,EAApB;AACA,SAAK,IAAL,CAAU,OAAV,CAAkB,CAAC,GAAD,EAAc,CAAd,KAA2B;AAC3C,MAAA,WAAW,CAAC,CAAC,GAAG,CAAL,CAAX,GAAsB,UAAoB,CAAC,GAAD,CAA1C;AACD,KAFD;AAGA,WAAO,WAAP;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,SAAS,CAAC,mBAAmB,CAAC,MAAD,CAApB,EAA8B,KAAK,kBAAnC,CAAhB;AACD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,MAAM,GAAG;AACb,MAAA,IAAI,EAAE,KAAK;AADE,KAAf;AAGA,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AApD+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAoDT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AASA,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;AAKhC,EAAA,WAAA,CAAY,IAAZ,EAA8B;AAC5B,UAAM,IAAI,IAAI,IAAR,GAAe,EAAf,GAAoB,IAA1B;AACA,SAAK,eAAL,GAAuB,IAAvB;;AACA,QAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB,WAAK,SAAL,GAAiB,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,CAAzB,GAA6B,IAAI,CAAC,SAAnD;AACD,KAFD,MAEO;AACL,WAAK,SAAL,GAAiB,CAAjB;AACD;AACF;;AAED,EAAA,kBAAkB,CAAC,UAAD,EAA0B;AAC1C,WAAO,UAAP;AACD;;AAED,EAAA,SAAS,GAAA;AACP,UAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;AACA,UAAM,MAAM,GAAG;AAAC,MAAA,SAAS,EAAE,KAAK;AAAjB,KAAf;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;AACA,WAAO,MAAP;AACD;;AAED,EAAA,WAAW,CAAC,MAAD,EAA0B,IAA1B,EAAgD;AACzD,UAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;AACA,UAAM,IAAI,GAAG,CAAC,CAAd;AACA,WAAO,GAAG,CAAC,QAAQ,CAAC,KAAD,EAAQ,KAAK,SAAb,CAAT,EAAkC,IAAlC,CAAV;AACD;;AAED,EAAA,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;AAC1C,WAAO,IAAI,CAAC,MAAK;AACf,WAAK,cAAL,CAAoB,MAApB,EAA4B,MAA5B;AACA,YAAM,KAAK,GAAG,mBAAmB,CAAC,MAAD,CAAjC;AACA,YAAM,IAAI,GAAG,CAAC,CAAd;AACA,YAAM,QAAQ,GAAG,IAAjB;AACA,YAAM,WAAW,GAAG,GAAG,CAAC,QAAQ,CAAC,KAAD,EAAQ,KAAK,SAAb,CAAT,EAAkC,IAAlC,EAAwC,QAAxC,CAAvB;AACA,YAAM,MAAM,GAAG,KAAK,CAAC,GAAN,CAAU,WAAW,CAAC,MAAZ,CAAmB,KAAK,CAAC,KAAzB,CAAV,CAAf;AACA,aAAO,MAAP;AACD,KARU,CAAX;AASD;;AA1C+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AA0CT,aAAa,CAAC,aAAd,CAA4B,OAA5B","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, notEqual, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n    constructor(args) {\n        super(args);\n        this.rate = Math.max(Math.min(args.rate, 1), 0);\n        // So that the scalar doesn't get tidied up between executions.\n        this.noiseShape = args.noiseShape;\n        this.seed = args.seed;\n        this.supportsMasking = true;\n    }\n    getNoiseShape(input) {\n        if (this.noiseShape == null) {\n            return this.noiseShape;\n        }\n        const inputShape = input.shape;\n        const noiseShape = [];\n        for (let i = 0; i < this.noiseShape.length; ++i) {\n            noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n        }\n        return noiseShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            if (0 < this.rate && this.rate < 1) {\n                const training = kwargs['training'] == null ? false : kwargs['training'];\n                const noiseShape = this.getNoiseShape(input);\n                const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n                return output;\n            }\n            return inputs;\n        });\n    }\n    getConfig() {\n        const config = {\n            rate: this.rate,\n            noiseShape: this.noiseShape,\n            seed: this.seed,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    dispose() {\n        return super.dispose();\n    }\n}\n/** @nocollapse */\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n    constructor(args) {\n        super(args);\n        this.inputSpec = [{ ndim: 3 }];\n    }\n    getNoiseShape(input) {\n        const inputShape = input.shape;\n        return [inputShape[0], 1, inputShape[2]];\n    }\n}\n/** @nocollapse */\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n    constructor(args) {\n        super(args);\n        // Default activation: Linear (none).\n        this.activation = null;\n        this.useBias = true;\n        this.kernel = null;\n        this.bias = null;\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        if (args.batchInputShape == null && args.inputShape == null &&\n            args.inputDim != null) {\n            // This logic is copied from Layer's constructor, since we can't\n            // do exactly what the Python constructor does for Dense().\n            let batchSize = null;\n            if (args.batchSize != null) {\n                batchSize = args.batchSize;\n            }\n            this.batchInputShape = [batchSize, args.inputDim];\n        }\n        this.units = args.units;\n        assertPositiveInteger(this.units, 'units');\n        this.activation = getActivation(args.activation);\n        if (args.useBias != null) {\n            this.useBias = args.useBias;\n        }\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.activityRegularizer = getRegularizer(args.activityRegularizer);\n        this.supportsMasking = true;\n        this.inputSpec = [{ minNDim: 2 }];\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const inputLastDim = inputShape[inputShape.length - 1];\n        if (this.kernel == null) {\n            this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n            if (this.useBias) {\n                this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n            }\n        }\n        this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];\n        this.built = true;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        outputShape[outputShape.length - 1] = this.units;\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            // Dense layer accepts only a single input.\n            const input = getExactlyOneTensor(inputs);\n            const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n            let output;\n            if (fusedActivationName != null) {\n                output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n            }\n            else {\n                output = K.dot(input, this.kernel.read());\n                if (this.bias != null) {\n                    output = K.biasAdd(output, this.bias.read());\n                }\n                if (this.activation != null) {\n                    output = this.activation.apply(output);\n                }\n            }\n            return output;\n        });\n    }\n    getConfig() {\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint)\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n    constructor(args) {\n        args = args || {};\n        super(args);\n        this.inputSpec = [{ minNDim: 3 }];\n        this.dataFormat = args.dataFormat;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        for (const dim of inputShape.slice(1)) {\n            if (dim == null) {\n                throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` +\n                    `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n                    `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n                    `layer in your model.`);\n            }\n        }\n        return [inputShape[0], arrayProd(inputShape, 1)];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            let input = getExactlyOneTensor(inputs);\n            if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n                const permutation = [0];\n                for (let i = 2; i < input.rank; ++i) {\n                    permutation.push(i);\n                }\n                permutation.push(1);\n                input = input.transpose(permutation);\n            }\n            return K.batchFlatten(input);\n        });\n    }\n    getConfig() {\n        const config = {};\n        if (this.dataFormat != null) {\n            config['dataFormat'] = this.dataFormat;\n        }\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n    constructor(args) {\n        super(args);\n        this.supportsMasking = true;\n        this.activation = getActivation(args.activation);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            return this.activation.apply(input);\n        });\n    }\n    getConfig() {\n        const config = { activation: serializeActivation(this.activation) };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n    constructor(args) {\n        super(args);\n        this.n = args.n;\n        this.inputSpec = [{ ndim: 2 }];\n    }\n    computeOutputShape(inputShape) {\n        return [inputShape[0], this.n, inputShape[1]];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            return K.repeat(inputs, this.n);\n        });\n    }\n    getConfig() {\n        const config = {\n            n: this.n,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n    constructor(args) {\n        super(args);\n        this.targetShape = args.targetShape;\n        // Make sure that all unknown dimensions are represented as `null`.\n        for (let i = 0; i < this.targetShape.length; ++i) {\n            if (this.isUnknown(this.targetShape[i])) {\n                this.targetShape[i] = null;\n            }\n        }\n    }\n    isUnknown(dim) {\n        return dim < 0 || dim == null;\n    }\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n    fixUnknownDimension(inputShape, outputShape) {\n        const errorMsg = 'Total size of new array must be unchanged.';\n        const finalShape = outputShape.slice();\n        let known = 1;\n        let unknown = null;\n        for (let i = 0; i < finalShape.length; ++i) {\n            const dim = finalShape[i];\n            if (this.isUnknown(dim)) {\n                if (unknown === null) {\n                    unknown = i;\n                }\n                else {\n                    throw new ValueError('Can only specifiy one unknown dimension.');\n                }\n            }\n            else {\n                known *= dim;\n            }\n        }\n        const originalSize = arrayProd(inputShape);\n        if (unknown !== null) {\n            if (known === 0 || originalSize % known !== 0) {\n                throw new ValueError(errorMsg);\n            }\n            finalShape[unknown] = originalSize / known;\n        }\n        else if (originalSize !== known) {\n            throw new ValueError(errorMsg);\n        }\n        return finalShape;\n    }\n    computeOutputShape(inputShape) {\n        let anyUnknownDims = false;\n        for (let i = 0; i < inputShape.length; ++i) {\n            if (this.isUnknown(inputShape[i])) {\n                anyUnknownDims = true;\n                break;\n            }\n        }\n        if (anyUnknownDims) {\n            return inputShape.slice(0, 1).concat(this.targetShape);\n        }\n        else {\n            return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const inputShape = input.shape;\n            const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n            return input.reshape(outputShape);\n        });\n    }\n    getConfig() {\n        const config = {\n            targetShape: this.targetShape,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n    constructor(args) {\n        super(args);\n        if (args.dims == null) {\n            throw new Error('Required configuration field `dims` is missing during Permute ' +\n                'constructor call.');\n        }\n        if (!Array.isArray(args.dims)) {\n            throw new Error('Permute constructor requires `dims` to be an Array, but received ' +\n                `${args.dims} instead.`);\n        }\n        // Check the validity of the permutation indices.\n        const expectedSortedIndices = range(1, args.dims.length + 1);\n        if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n            throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n                ' `dims` must contain consecutive integers starting from 1.');\n        }\n        this.dims = args.dims;\n        this.dimsIncludingBatch = [0].concat(this.dims);\n        this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        this.dims.forEach((dim, i) => {\n            outputShape[i + 1] = inputShape[dim];\n        });\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    }\n    getConfig() {\n        const config = {\n            dims: this.dims,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.supportsMasking = true;\n        if (args != null) {\n            this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n        }\n        else {\n            this.maskValue = 0;\n        }\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = { maskValue: this.maskValue };\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    computeMask(inputs, mask) {\n        const input = getExactlyOneTensor(inputs);\n        const axis = -1;\n        return any(notEqual(input, this.maskValue), axis);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const axis = -1;\n            const keepDims = true;\n            const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n            const output = input.mul(booleanMask.asType(input.dtype));\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMasking.className = 'Masking';\nserialization.registerClass(Masking);\n//# sourceMappingURL=core.js.map"]},"metadata":{},"sourceType":"module"}