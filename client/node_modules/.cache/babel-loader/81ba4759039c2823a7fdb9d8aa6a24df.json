{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n  let maxInput = x;\n\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values;\n      const newShape = new Array(xRank);\n\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n\n      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n  let outShape = maxOutShape;\n\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values;\n    const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max\n};","map":{"version":3,"sources":["../../src/kernels/Max.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAoB,GAApB,QAA+D,uBAA/D;AACA,SAAQ,YAAR,EAAgD,IAAhD,QAA2D,uBAA3D;AAGA,SAAQ,UAAR,QAAyB,wBAAzB;AAEA,SAAQ,OAAR,QAAsB,YAAtB;AACA,SAAQ,aAAR,EAAuB,gBAAvB,QAA8C,kBAA9C;AAEA,OAAM,SAAU,GAAV,CACF,IADE,EACmE;AAEvE,QAAM;AAAC,IAAA,MAAD;AAAS,IAAA,OAAT;AAAkB,IAAA;AAAlB,MAA2B,IAAjC;AACA,QAAM;AAAC,IAAA;AAAD,MAAM,MAAZ;AACA,QAAM;AAAC,IAAA,gBAAD;AAAmB,IAAA;AAAnB,MAA+B,KAArC;AAEA,QAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;AAEA,QAAM,QAAQ,GAAG,IAAI,CAAC,cAAL,CAAoB,gBAApB,EAAsC,CAAC,CAAC,KAAxC,CAAjB;AACA,MAAI,IAAI,GAAG,QAAX;AACA,QAAM,YAAY,GAAG,YAAY,CAAC,kBAAb,CAAgC,IAAhC,EAAsC,KAAtC,CAArB;AACA,QAAM,oBAAoB,GAAG,YAAY,IAAI,IAA7C;AACA,QAAM,kBAAkB,GAAG,OAAO,CAAC,kBAAR,CAA2B,CAAC,CAAD,CAA3B,CAA3B;AAEA,MAAI,QAAQ,GAAG,CAAf;;AACA,MAAI,oBAAJ,EAA0B;AACxB,QAAI,kBAAJ,EAAwB;AACtB,YAAM,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAAjB;AACA,YAAM,MAAM,GAAG,QAAQ,CAAC,MAAxB;AAEA,YAAM,QAAQ,GAAa,IAAI,KAAJ,CAAU,KAAV,CAA3B;;AACA,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAAQ,CAAC,MAA7B,EAAqC,CAAC,EAAtC,EAA0C;AACxC,QAAA,QAAQ,CAAC,CAAD,CAAR,GAAc,CAAC,CAAC,KAAF,CAAQ,YAAY,CAAC,CAAD,CAApB,CAAd;AACD;;AACD,YAAM,cAAc,GAChB,gBAAgB,CAAC,MAAD,EAAS,CAAC,CAAC,KAAX,EAAkB,CAAC,CAAC,KAApB,EAA2B,YAA3B,EAAyC,QAAzC,CADpB;AAGA,MAAA,QAAQ,GAAG,OAAO,CAAC,cAAR,CAAuB,QAAvB,EAAiC,CAAC,CAAC,KAAnC,CAAX;AACA,YAAM,YAAY,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAArB;AACA,MAAA,YAAY,CAAC,MAAb,GAAsB,cAAtB;AACD,KAdD,MAcO;AACL,MAAA,QAAQ,GAAG,aAAa,CAAC,CAAD,EAAI,YAAJ,EAAkB,OAAlB,CAAxB;AACD;;AAED,IAAA,IAAI,GAAG,YAAY,CAAC,gBAAb,CAA8B,IAAI,CAAC,MAAnC,EAA2C,KAA3C,CAAP;AACD;;AAED,EAAA,YAAY,CAAC,0BAAb,CAAwC,KAAxC,EAA+C,IAA/C,EAAqD,KAArD;AACA,QAAM,CAAC,WAAD,EAAc,WAAd,IACF,YAAY,CAAC,yBAAb,CAAuC,QAAQ,CAAC,KAAhD,EAAuD,IAAvD,CADJ;AAGA,MAAI,QAAQ,GAAG,WAAf;;AACA,MAAI,QAAJ,EAAc;AACZ;AACA,IAAA,QAAQ,GAAG,YAAY,CAAC,oBAAb,CAAkC,WAAlC,EAA+C,QAA/C,CAAX;AACD;;AAED,MAAI,GAAJ;;AACA,MAAI,kBAAJ,EAAwB;AACtB,UAAM,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAAjB;AACA,UAAM,MAAM,GAAG,QAAQ,CAAC,MAAxB;AAEA,UAAM,SAAS,GACX,UAAU,CAAC,MAAD,EAAS,IAAI,CAAC,aAAL,CAAmB,WAAnB,CAAT,EAA0C,QAA1C,EAAoD,CAAC,CAAC,KAAtD,CADd;AAGA,IAAA,GAAG,GAAG,OAAO,CAAC,cAAR,CAAuB,QAAvB,EAAiC,CAAC,CAAC,KAAnC,CAAN;AACA,UAAM,OAAO,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,GAAG,CAAC,MAAxB,CAAhB;AACA,IAAA,OAAO,CAAC,MAAR,GAAiB,SAAjB;AACD,GAVD,MAUO;AACL,IAAA,GAAG,GAAG,OAAO,CAAC,QAAD,EAAW,WAAX,EAAwB,QAAxB,EAAkC,OAAlC,CAAb;AACD;;AAED,MAAI,oBAAJ,EAA0B;AACxB,IAAA,OAAO,CAAC,6BAAR,CAAsC,QAAtC;AACD;;AAED,SAAO,GAAP;AACD;AAED,OAAO,MAAM,SAAS,GAAiB;AACrC,EAAA,UAAU,EAAE,GADyB;AAErC,EAAA,WAAW,EAAE,OAFwB;AAGrC,EAAA,UAAU,EAAE;AAHyB,CAAhC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { reductionIndices, keepDims } = attrs;\n    const xRank = x.shape.length;\n    const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    const maxInputIsTransposed = permutedAxes != null;\n    const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n    let maxInput = x;\n    if (maxInputIsTransposed) {\n        if (shouldExecuteOnCPU) {\n            const xTexData = backend.texData.get(maxInput.dataId);\n            const values = xTexData.values;\n            const newShape = new Array(xRank);\n            for (let i = 0; i < newShape.length; i++) {\n                newShape[i] = x.shape[permutedAxes[i]];\n            }\n            const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n            maxInput = backend.makeTensorInfo(newShape, x.dtype);\n            const maxInputData = backend.texData.get(maxInput.dataId);\n            maxInputData.values = maxInputValues;\n        }\n        else {\n            maxInput = transposeImpl(x, permutedAxes, backend);\n        }\n        axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    }\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n    let outShape = maxOutShape;\n    if (keepDims) {\n        // rather than reshape at the end, set the target shape here.\n        outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    }\n    let out;\n    if (shouldExecuteOnCPU) {\n        const xTexData = backend.texData.get(maxInput.dataId);\n        const values = xTexData.values;\n        const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n        out = backend.makeTensorInfo(outShape, x.dtype);\n        const outData = backend.texData.get(out.dataId);\n        outData.values = outValues;\n    }\n    else {\n        out = maxImpl(maxInput, reduceShape, outShape, backend);\n    }\n    if (maxInputIsTransposed) {\n        backend.disposeIntermediateTensorInfo(maxInput);\n    }\n    return out;\n}\nexport const maxConfig = {\n    kernelName: Max,\n    backendName: 'webgl',\n    kernelFunc: max\n};\n//# sourceMappingURL=Max.js.map"]},"metadata":{},"sourceType":"module"}