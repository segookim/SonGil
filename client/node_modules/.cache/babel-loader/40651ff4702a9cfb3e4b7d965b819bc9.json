{"ast":null,"code":"import _regeneratorRuntime from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original source: keras/callbacks.py */\nimport { BaseCallback } from './base_callbacks';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nexport var Callback = /*#__PURE__*/function (_BaseCallback) {\n  _inherits(Callback, _BaseCallback);\n\n  var _super = _createSuper(Callback);\n\n  function Callback() {\n    var _this;\n\n    _classCallCheck(this, Callback);\n\n    _this = _super.apply(this, arguments);\n    /** Instance of `keras.models.Model`. Reference of the model being trained. */\n\n    _this.model = null;\n    return _this;\n  }\n\n  _createClass(Callback, [{\n    key: \"setModel\",\n    value: function setModel(model) {\n      if (!(model instanceof LayersModel)) {\n        throw new Error('model must be a LayersModel, not some other Container');\n      }\n\n      this.model = model;\n    }\n  }]);\n\n  return Callback;\n}(BaseCallback);\n\nfunction less(currVal, prevVal) {\n  return currVal < prevVal;\n}\n\nfunction greater(currVal, prevVal) {\n  return currVal > prevVal;\n}\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\n\n\nexport var EarlyStopping = /*#__PURE__*/function (_Callback) {\n  _inherits(EarlyStopping, _Callback);\n\n  var _super2 = _createSuper(EarlyStopping);\n\n  function EarlyStopping(args) {\n    var _this2;\n\n    _classCallCheck(this, EarlyStopping);\n\n    _this2 = _super2.call(this);\n\n    if (args == null) {\n      args = {};\n    }\n\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError('restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n\n    _this2.monitor = args.monitor || 'val_loss';\n    _this2.minDelta = Math.abs(args.minDelta || 0);\n    _this2.patience = args.patience || 0;\n    _this2.verbose = args.verbose || 0;\n    _this2.mode = args.mode || 'auto';\n    _this2.baseline = args.baseline;\n\n    if (['auto', 'min', 'max'].indexOf(_this2.mode) === -1) {\n      console.warn(\"EarlyStopping mode '\".concat(_this2.mode, \"' is invalid. \") + \"Falling back to mode 'auto'.\");\n      _this2.mode = 'auto';\n    }\n\n    if (_this2.mode === 'min') {\n      _this2.monitorFunc = less;\n    } else if (_this2.mode === 'max') {\n      _this2.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (_this2.monitor.indexOf('acc') !== -1) {\n        _this2.monitorFunc = greater;\n      } else {\n        _this2.monitorFunc = less;\n      }\n    }\n\n    if (_this2.monitorFunc === less) {\n      _this2.minDelta *= -1;\n    }\n\n    return _this2;\n  }\n\n  _createClass(EarlyStopping, [{\n    key: \"onTrainBegin\",\n    value: function () {\n      var _onTrainBegin = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(logs) {\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                this.wait = 0;\n                this.stoppedEpoch = 0;\n\n                if (this.baseline != null) {\n                  this.best = this.baseline;\n                } else {\n                  this.best = this.monitorFunc === less ? Infinity : -Infinity;\n                }\n\n              case 3:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function onTrainBegin(_x) {\n        return _onTrainBegin.apply(this, arguments);\n      }\n\n      return onTrainBegin;\n    }()\n  }, {\n    key: \"onEpochEnd\",\n    value: function () {\n      var _onEpochEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(epoch, logs) {\n        var current;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return resolveScalarsInLogs(logs);\n\n              case 2:\n                current = this.getMonitorValue(logs);\n\n                if (!(current == null)) {\n                  _context2.next = 5;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 5:\n                if (this.monitorFunc(current - this.minDelta, this.best)) {\n                  this.best = current;\n                  this.wait = 0; // TODO(cais): Logic for restoreBestWeights.\n                } else {\n                  this.wait++;\n\n                  if (this.wait >= this.patience) {\n                    this.stoppedEpoch = epoch;\n                    this.model.stopTraining = true;\n                  } // TODO(cais): Logic for restoreBestWeights.\n\n                }\n\n              case 6:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function onEpochEnd(_x2, _x3) {\n        return _onEpochEnd.apply(this, arguments);\n      }\n\n      return onEpochEnd;\n    }()\n  }, {\n    key: \"onTrainEnd\",\n    value: function () {\n      var _onTrainEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(logs) {\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                if (this.stoppedEpoch > 0 && this.verbose) {\n                  console.log(\"Epoch \".concat(this.stoppedEpoch, \": early stopping.\"));\n                }\n\n              case 1:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function onTrainEnd(_x4) {\n        return _onTrainEnd.apply(this, arguments);\n      }\n\n      return onTrainEnd;\n    }()\n  }, {\n    key: \"getMonitorValue\",\n    value: function getMonitorValue(logs) {\n      if (logs == null) {\n        logs = {};\n      }\n\n      var monitorValue = logs[this.monitor];\n\n      if (monitorValue == null) {\n        console.warn(\"Metric for EarlyStopping \".concat(this.monitor, \" is not available. \") + \"Available metrics are: \".concat(Object.keys(logs)));\n      }\n\n      return monitorValue;\n    }\n  }]);\n\n  return EarlyStopping;\n}(Callback);\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\n\nexport function earlyStopping(args) {\n  return new EarlyStopping(args);\n}\nexport var callbacks = {\n  earlyStopping: earlyStopping\n};","map":{"version":3,"sources":["../src/callbacks.ts"],"names":[],"mappings":";;;;;;;AAAA;;;;;;;;AAQG;;AAEH;AAEA,SAAQ,YAAR,QAA2B,kBAA3B;AAEA,SAAQ,WAAR,QAA0B,mBAA1B;AACA,SAAQ,mBAAR,QAAkC,UAAlC;AACA,SAAc,oBAAd,QAAyC,QAAzC;AAEA,WAAsB,QAAtB;AAAA;;AAAA;;AAAA,sBAAA;AAAA;;AAAA;;;AACE;;AACA,UAAA,KAAA,GAAqB,IAArB;AAFF;AAUC;;AAVD;AAAA;AAAA,WAIE,kBAAS,KAAT,EAAyB;AACvB,UAAI,EAAE,KAAK,YAAY,WAAnB,CAAJ,EAAqC;AACnC,cAAM,IAAI,KAAJ,CAAU,uDAAV,CAAN;AACD;;AACD,WAAK,KAAL,GAAa,KAAb;AACD;AATH;;AAAA;AAAA,EAAuC,YAAvC;;AAsEA,SAAS,IAAT,CAAc,OAAd,EAA+B,OAA/B,EAA8C;AAC5C,SAAO,OAAO,GAAG,OAAjB;AACD;;AAED,SAAS,OAAT,CAAiB,OAAjB,EAAkC,OAAlC,EAAiD;AAC/C,SAAO,OAAO,GAAG,OAAjB;AACD;AAED;;;AAGG;;;AACH,WAAa,aAAb;AAAA;;AAAA;;AAcE,yBAAY,IAAZ,EAA4C;AAAA;;AAAA;;AAC1C;;AACA,QAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB,MAAA,IAAI,GAAG,EAAP;AACD;;AACD,QAAI,IAAI,CAAC,kBAAT,EAA6B;AAC3B,YAAM,IAAI,mBAAJ,CACF,oEADE,CAAN;AAED;;AAED,WAAK,OAAL,GAAe,IAAI,CAAC,OAAL,IAAgB,UAA/B;AACA,WAAK,QAAL,GAAgB,IAAI,CAAC,GAAL,CAAS,IAAI,CAAC,QAAL,IAAiB,CAA1B,CAAhB;AACA,WAAK,QAAL,GAAgB,IAAI,CAAC,QAAL,IAAiB,CAAjC;AACA,WAAK,OAAL,GAAe,IAAI,CAAC,OAAL,IAAgB,CAA/B;AACA,WAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,MAAzB;AACA,WAAK,QAAL,GAAgB,IAAI,CAAC,QAArB;;AAEA,QAAI,CAAC,MAAD,EAAS,KAAT,EAAgB,KAAhB,EAAuB,OAAvB,CAA+B,OAAK,IAApC,MAA8C,CAAC,CAAnD,EAAsD;AACpD,MAAA,OAAO,CAAC,IAAR,CACI,8BAAuB,OAAK,IAA5B,oDADJ;AAGA,aAAK,IAAL,GAAY,MAAZ;AACD;;AAED,QAAI,OAAK,IAAL,KAAc,KAAlB,EAAyB;AACvB,aAAK,WAAL,GAAmB,IAAnB;AACD,KAFD,MAEO,IAAI,OAAK,IAAL,KAAc,KAAlB,EAAyB;AAC9B,aAAK,WAAL,GAAmB,OAAnB;AACD,KAFM,MAEA;AACL;AACA,UAAI,OAAK,OAAL,CAAa,OAAb,CAAqB,KAArB,MAAgC,CAAC,CAArC,EAAwC;AACtC,eAAK,WAAL,GAAmB,OAAnB;AACD,OAFD,MAEO;AACL,eAAK,WAAL,GAAmB,IAAnB;AACD;AACF;;AAED,QAAI,OAAK,WAAL,KAAqB,IAAzB,EAA+B;AAC7B,aAAK,QAAL,IAAiB,CAAC,CAAlB;AACD;;AAvCyC;AAwC3C;;AAtDH;AAAA;AAAA;AAAA,mFAwDE,iBAAmB,IAAnB;AAAA;AAAA;AAAA;AAAA;AACE,qBAAK,IAAL,GAAY,CAAZ;AACA,qBAAK,YAAL,GAAoB,CAApB;;AACA,oBAAI,KAAK,QAAL,IAAiB,IAArB,EAA2B;AACzB,uBAAK,IAAL,GAAY,KAAK,QAAjB;AACD,iBAFD,MAEO;AACL,uBAAK,IAAL,GAAY,KAAK,WAAL,KAAqB,IAArB,GAA4B,QAA5B,GAAuC,CAAC,QAApD;AACD;;AAPH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAxDF;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iFAkEE,kBAAiB,KAAjB,EAAgC,IAAhC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBACQ,oBAAoB,CAAC,IAAD,CAD5B;;AAAA;AAEQ,gBAAA,OAFR,GAEkB,KAAK,eAAL,CAAqB,IAArB,CAFlB;;AAAA,sBAGM,OAAO,IAAI,IAHjB;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAOE,oBAAI,KAAK,WAAL,CAAiB,OAAO,GAAG,KAAK,QAAhC,EAA0C,KAAK,IAA/C,CAAJ,EAA0D;AACxD,uBAAK,IAAL,GAAY,OAAZ;AACA,uBAAK,IAAL,GAAY,CAAZ,CAFwD,CAGxD;AACD,iBAJD,MAIO;AACL,uBAAK,IAAL;;AACA,sBAAI,KAAK,IAAL,IAAa,KAAK,QAAtB,EAAgC;AAC9B,yBAAK,YAAL,GAAoB,KAApB;AACA,yBAAK,KAAL,CAAW,YAAX,GAA0B,IAA1B;AACD,mBALI,CAML;;AACD;;AAlBH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAlEF;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iFAuFE,kBAAiB,IAAjB;AAAA;AAAA;AAAA;AAAA;AACE,oBAAI,KAAK,YAAL,GAAoB,CAApB,IAAyB,KAAK,OAAlC,EAA2C;AACzC,kBAAA,OAAO,CAAC,GAAR,iBAAqB,KAAK,YAA1B;AACD;;AAHH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAvFF;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,WA6FU,yBAAgB,IAAhB,EAA0B;AAChC,UAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB,QAAA,IAAI,GAAG,EAAP;AACD;;AACD,UAAM,YAAY,GAAG,IAAI,CAAC,KAAK,OAAN,CAAzB;;AACA,UAAI,YAAY,IAAI,IAApB,EAA0B;AACxB,QAAA,OAAO,CAAC,IAAR,CACI,mCAA4B,KAAK,OAAjC,4DAC0B,MAAM,CAAC,IAAP,CAAY,IAAZ,CAD1B,CADJ;AAGD;;AACD,aAAO,YAAP;AACD;AAxGH;;AAAA;AAAA,EAAmC,QAAnC;AA2GA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CG;;AACH,OAAM,SAAU,aAAV,CAAwB,IAAxB,EAAwD;AAC5D,SAAO,IAAI,aAAJ,CAAkB,IAAlB,CAAP;AACD;AAED,OAAO,IAAM,SAAS,GAAG;AAAC,EAAA,aAAa,EAAb;AAAD,CAAlB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original source: keras/callbacks.py */\nimport { BaseCallback } from './base_callbacks';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nexport class Callback extends BaseCallback {\n    constructor() {\n        super(...arguments);\n        /** Instance of `keras.models.Model`. Reference of the model being trained. */\n        this.model = null;\n    }\n    setModel(model) {\n        if (!(model instanceof LayersModel)) {\n            throw new Error('model must be a LayersModel, not some other Container');\n        }\n        this.model = model;\n    }\n}\nfunction less(currVal, prevVal) {\n    return currVal < prevVal;\n}\nfunction greater(currVal, prevVal) {\n    return currVal > prevVal;\n}\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\nexport class EarlyStopping extends Callback {\n    constructor(args) {\n        super();\n        if (args == null) {\n            args = {};\n        }\n        if (args.restoreBestWeights) {\n            throw new NotImplementedError('restoreBestWeights = True is not implemented in EarlyStopping yet.');\n        }\n        this.monitor = args.monitor || 'val_loss';\n        this.minDelta = Math.abs(args.minDelta || 0);\n        this.patience = args.patience || 0;\n        this.verbose = args.verbose || 0;\n        this.mode = args.mode || 'auto';\n        this.baseline = args.baseline;\n        if (['auto', 'min', 'max'].indexOf(this.mode) === -1) {\n            console.warn(`EarlyStopping mode '${this.mode}' is invalid. ` +\n                `Falling back to mode 'auto'.`);\n            this.mode = 'auto';\n        }\n        if (this.mode === 'min') {\n            this.monitorFunc = less;\n        }\n        else if (this.mode === 'max') {\n            this.monitorFunc = greater;\n        }\n        else {\n            // For mode === 'auto'.\n            if (this.monitor.indexOf('acc') !== -1) {\n                this.monitorFunc = greater;\n            }\n            else {\n                this.monitorFunc = less;\n            }\n        }\n        if (this.monitorFunc === less) {\n            this.minDelta *= -1;\n        }\n    }\n    async onTrainBegin(logs) {\n        this.wait = 0;\n        this.stoppedEpoch = 0;\n        if (this.baseline != null) {\n            this.best = this.baseline;\n        }\n        else {\n            this.best = this.monitorFunc === less ? Infinity : -Infinity;\n        }\n    }\n    async onEpochEnd(epoch, logs) {\n        await resolveScalarsInLogs(logs);\n        const current = this.getMonitorValue(logs);\n        if (current == null) {\n            return;\n        }\n        if (this.monitorFunc(current - this.minDelta, this.best)) {\n            this.best = current;\n            this.wait = 0;\n            // TODO(cais): Logic for restoreBestWeights.\n        }\n        else {\n            this.wait++;\n            if (this.wait >= this.patience) {\n                this.stoppedEpoch = epoch;\n                this.model.stopTraining = true;\n            }\n            // TODO(cais): Logic for restoreBestWeights.\n        }\n    }\n    async onTrainEnd(logs) {\n        if (this.stoppedEpoch > 0 && this.verbose) {\n            console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);\n        }\n    }\n    getMonitorValue(logs) {\n        if (logs == null) {\n            logs = {};\n        }\n        const monitorValue = logs[this.monitor];\n        if (monitorValue == null) {\n            console.warn(`Metric for EarlyStopping ${this.monitor} is not available. ` +\n                `Available metrics are: ${Object.keys(logs)}`);\n        }\n        return monitorValue;\n    }\n}\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\nexport function earlyStopping(args) {\n    return new EarlyStopping(args);\n}\nexport const callbacks = { earlyStopping };\n//# sourceMappingURL=callbacks.js.map"]},"metadata":{},"sourceType":"module"}