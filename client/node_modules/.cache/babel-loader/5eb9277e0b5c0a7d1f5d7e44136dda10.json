{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer'; // Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\n\nexport function iteratorFromItems(items) {\n  return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\n\nexport function iteratorFromIncrementing(start) {\n  let i = start;\n  return iteratorFromFunction(() => ({\n    value: i++,\n    done: false\n  }));\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\n\nexport function iteratorFromFunction(func) {\n  return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n  return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\nexport function iteratorFromZipped(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n  return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\n\nexport class LazyIterator {\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray() {\n    const result = [];\n    let x = await this.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n\n    return result;\n  }\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n\n\n  async toArrayForTest() {\n    const stream = this.prefetch(100);\n    const result = [];\n    let x = await stream.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n\n    return result;\n  }\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n\n\n  async resolveFully() {\n    let x = await this.next();\n\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n\n\n  async resolveWhile(predicate) {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n\n    while (!x.done && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n\n\n  handleErrors(handler) {\n    return new ErrorHandlingLazyIterator(this, handler);\n  } // TODO(soergel): Implement reduce() etc.\n\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n\n\n  filter(predicate) {\n    return new FilterIterator(this, predicate);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  map(transform) {\n    return new MapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  mapAsync(transform) {\n    return new AsyncMapIterator(this, transform);\n  }\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n\n\n  serialMapAsync(transform) {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n\n\n  flatmap(transform) {\n    return new FlatmapIterator(this, transform);\n  }\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n\n\n  async forEachAsync(f) {\n    return this.map(f).resolveFully();\n  }\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n\n\n  async serialForEach(f) {\n    return this.serialMapAsync(f).resolveWhile(x => x === true);\n  }\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n\n\n  rowMajorBatch(batchSize, smallLastBatch = true) {\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n\n\n  columnMajorBatch(batchSize, smallLastBatch = true, // tslint:disable-next-line:no-any\n  zipFn = zipToList) {\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch); // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n\n\n  concatenate(iterator, baseErrorHandler) {\n    return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n\n\n  take(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new TakeIterator(this, count);\n  }\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n\n\n  skip(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new SkipIterator(this, count);\n  }\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n\n\n  prefetch(bufferSize) {\n    return new PrefetchIterator(this, bufferSize);\n  } // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n\n\n  shuffle(windowSize, seed) {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n\n\n  serial() {\n    return new SerialIterator(this);\n  }\n\n} // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator extends LazyIterator {\n  constructor(items) {\n    super();\n    this.items = items;\n    this.trav = 0;\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next() {\n    if (this.trav >= this.items.length) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const item = this.items[this.trav];\n    this.trav++;\n    return {\n      value: deepClone(item),\n      done: false\n    };\n  }\n\n}\n\nclass FunctionCallIterator extends LazyIterator {\n  constructor(nextFn) {\n    super();\n    this.nextFn = nextFn;\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next() {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message = `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n\n}\n\nclass SerialIterator extends LazyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    return this.upstream.next();\n  }\n\n}\n\nclass SkipIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount; // Local state that should not be clobbered by out-of-order execution.\n\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next(); // short-circuit if upstream is already empty\n\n      if (skipped.done) {\n        return skipped;\n      }\n\n      tf.dispose(skipped.value);\n    }\n\n    return this.upstream.next();\n  }\n\n}\n\nclass TakeIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount;\n    this.count = 0;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next() {\n    if (this.count++ >= this.maxCount) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    return this.upstream.next();\n  }\n\n} // Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\n\n\nclass RowMajorBatchIterator extends LazyIterator {\n  constructor(upstream, batchSize, enableSmallLastBatch = true) {\n    super();\n    this.upstream = upstream;\n    this.batchSize = batchSize;\n    this.enableSmallLastBatch = enableSmallLastBatch;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    const batch = [];\n\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {\n            value: batch,\n            done: false\n          };\n        }\n\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      batch.push(item.value);\n    }\n\n    return {\n      value: batch,\n      done: false\n    };\n  }\n\n}\n\nclass FilterIterator extends LazyIterator {\n  constructor(upstream, predicate) {\n    super();\n    this.upstream = upstream;\n    this.predicate = predicate;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      const item = await this.upstream.next();\n\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n\n      tf.dispose(item.value);\n    }\n  }\n\n}\n\nclass MapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n}\n\nclass ErrorHandlingLazyIterator extends LazyIterator {\n  constructor(upstream, handler) {\n    super();\n    this.upstream = upstream;\n    this.handler = handler;\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {\n            value: null,\n            done: true\n          };\n        } // If the handler returns true, loop and fetch the next upstream item.\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n\n      }\n    }\n  }\n\n}\n\nclass AsyncMapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n} // Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\n\n\nexport class OneToManyIterator extends LazyIterator {\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer();\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!(await this.pump())) {\n        return {\n          value: null,\n          done: true\n        };\n      }\n    }\n\n    return {\n      value: this.outputQueue.shift(),\n      done: false\n    };\n  }\n\n}\n\nclass FlatmapIterator extends OneToManyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return false;\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n\n    const mappedArray = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n    this.outputQueue.pushAll(mappedArray); // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n\n}\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\n\n\nexport class ChainedIterator extends LazyIterator {\n  constructor(iterators, baseErrorHandler) {\n    super();\n    this.baseErrorHandler = baseErrorHandler; // Strict Promise execution order:\n    // a next() call may not even begin until the previous one completes.\n\n    this.lastRead = null; // Local state that should not be clobbered by out-of-order execution.\n\n    this.iterator = null;\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next() {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  async readFromChain(lastRead) {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      this.iterator = iteratorResult.value;\n\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n\n    const itemResult = await this.iterator.next();\n\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n\n    return itemResult;\n  }\n\n}\nexport var ZipMismatchMode;\n\n(function (ZipMismatchMode) {\n  ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n  ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n  ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\n\nclass ZipIterator extends LazyIterator {\n  constructor(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n    super();\n    this.iterators = iterators;\n    this.mismatchMode = mismatchMode;\n    this.count = 0;\n    this.currentPromise = null;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  async nextState(afterState) {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState; // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container) {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n\n            if (x.done) {\n              iteratorsDone++;\n            }\n\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {\n          value: null,\n          recurse: true\n        };\n      }\n    }\n\n    const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error('Zipped streams should have the same length. ' + `Mismatched at element ${this.count}.`);\n\n        case ZipMismatchMode.SHORTEST:\n          return {\n            value: null,\n            done: true\n          };\n\n        case ZipMismatchMode.LONGEST:\n        default: // Continue.  The exhausted streams already produced value: null.\n\n      }\n    }\n\n    this.count++;\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n  async next() {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n\n} // Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\n\n\nexport class PrefetchIterator extends LazyIterator {\n  constructor(upstream, bufferSize) {\n    super();\n    this.upstream = upstream;\n    this.bufferSize = bufferSize;\n    this.buffer = new RingBuffer(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n\n\n  refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next() {\n    this.refill(); // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n\n    return this.buffer.shift();\n  }\n\n}\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\n\nexport class ShuffleIterator extends PrefetchIterator {\n  constructor(upstream, windowSize, seed) {\n    super(upstream, windowSize);\n    this.upstream = upstream;\n    this.windowSize = windowSize; // Local state that should not be clobbered by out-of-order execution.\n\n    this.upstreamExhausted = false;\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  randomInt(max) {\n    return Math.floor(this.random() * max);\n  }\n\n  chooseIndex() {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n\n    return {\n      value: null,\n      done: true\n    };\n  }\n\n}","map":{"version":3,"sources":["../../src/iterators/lazy_iterator.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBG;AAEH,OAAO,KAAK,EAAZ,MAAoB,uBAApB;AACA,OAAO,KAAK,UAAZ,MAA4B,YAA5B;AAGA,SAAQ,SAAR,QAAwB,oBAAxB;AACA,SAAQ,kBAAR,EAA+D,OAA/D,EAAwE,SAAxE,QAAwF,kBAAxF;AACA,SAAQ,iBAAR,QAAgC,6BAAhC;AACA,SAAQ,UAAR,QAAyB,qBAAzB,C,CAOA;AACA;AACA;;AAEA;;AAEG;;AACH,OAAM,SAAU,iBAAV,CAA+B,KAA/B,EAAyC;AAC7C,SAAO,IAAI,aAAJ,CAAkB,KAAlB,CAAP;AACD;AAED;;AAEG;;AACH,OAAM,SAAU,wBAAV,CAAmC,KAAnC,EAAgD;AACpD,MAAI,CAAC,GAAG,KAAR;AACA,SAAO,oBAAoB,CAAC,OAAO;AAAC,IAAA,KAAK,EAAE,CAAC,EAAT;AAAa,IAAA,IAAI,EAAE;AAAnB,GAAP,CAAD,CAA3B;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,oBAAV,CACF,IADE,EAE+C;AACnD,SAAO,IAAI,oBAAJ,CAAyB,IAAzB,CAAP;AACD;AAED;;;;;;;;;;;AAWG;;AACH,OAAM,SAAU,wBAAV,CACF,aADE,EAEF,gBAFE,EAEsC;AAC1C,SAAO,IAAI,eAAJ,CAAoB,aAApB,EAAmC,gBAAnC,CAAP;AACD;AAED;;;;;;;;;;;;;;;AAeG;;AACH,OAAM,SAAU,gCAAV,CACF,YADE,EACmD,KADnD,EAEF,gBAFE,EAEsC;AAC1C,SAAO,wBAAwB,CAC3B,oBAAoB,CAAC,YAAD,CAApB,CAAmC,IAAnC,CAAwC,KAAxC,CAD2B,EACqB,gBADrB,CAA/B;AAED;AAED;;;;;;;;;;;;;;;;;;;;;;;AAuBG;;AACH,OAAM,SAAU,kBAAV,CACF,SADE,EAEF,YAAA,GAAgC,eAAe,CAAC,IAF9C,EAEkD;AACtD,SAAO,IAAI,WAAJ,CAAmB,SAAnB,EAA8B,YAA9B,CAAP;AACD;AAED;;;;;;AAMG;;AACH,OAAM,MAAgB,YAAhB,CAA4B;AAgBhC;;;;;;;AAOG;AACU,QAAP,OAAO,GAAA;AACX,UAAM,MAAM,GAAQ,EAApB;AACA,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,MAAM,CAAC,IAAP,CAAY,CAAC,CAAC,KAAd;AACA,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACD;;AACD,WAAO,MAAP;AACD;AAED;;;;;;;;;;AAUG;;;AACiB,QAAd,cAAc,GAAA;AAClB,UAAM,MAAM,GAAG,KAAK,QAAL,CAAc,GAAd,CAAf;AACA,UAAM,MAAM,GAAQ,EAApB;AACA,QAAI,CAAC,GAAG,MAAM,MAAM,CAAC,IAAP,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,MAAM,CAAC,IAAP,CAAY,CAAC,CAAC,KAAd;AACA,MAAA,CAAC,GAAG,MAAM,MAAM,CAAC,IAAP,EAAV;AACD;;AACD,WAAO,MAAP;AACD;AAED;;;;;;AAMG;;;AACe,QAAZ,YAAY,GAAA;AAChB,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACD;AACF;AAED;;;;;;AAMG;;;AACe,QAAZ,YAAY,CAAC,SAAD,EAA6B;AAC7C,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;AACA,QAAI,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAH,CAA9B;;AACA,WAAQ,CAAC,CAAC,CAAC,IAAJ,IAAa,cAApB,EAAoC;AAClC,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACA,MAAA,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAH,CAA1B;AACD;AACF;AAED;;;;;;;;;;;AAWG;;;AACH,EAAA,YAAY,CAAC,OAAD,EAAmC;AAC7C,WAAO,IAAI,yBAAJ,CAA8B,IAA9B,EAAoC,OAApC,CAAP;AACD,GApG+B,CAsGhC;;AAEA;;;;;;;AAOG;;;AACH,EAAA,MAAM,CAAC,SAAD,EAAiC;AACrC,WAAO,IAAI,cAAJ,CAAmB,IAAnB,EAAyB,SAAzB,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,GAAG,CAAI,SAAJ,EAA8B;AAC/B,WAAO,IAAI,WAAJ,CAAgB,IAAhB,EAAsB,SAAtB,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,QAAQ,CAAI,SAAJ,EAAuC;AAC7C,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,SAA3B,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,cAAc,CAAI,SAAJ,EAAuC;AACnD,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,SAA3B,EAAsC,MAAtC,EAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,OAAO,CAAI,SAAJ,EAAgC;AACrC,WAAO,IAAI,eAAJ,CAAoB,IAApB,EAA0B,SAA1B,CAAP;AACD;AAED;;;;AAIG;;;AACe,QAAZ,YAAY,CAAC,CAAD,EAAsB;AACtC,WAAO,KAAK,GAAL,CAAS,CAAT,EAAY,YAAZ,EAAP;AACD;AAED;;;;;;AAMG;;;AACgB,QAAb,aAAa,CAAC,CAAD,EAAkC;AACnD,WAAO,KAAK,cAAL,CAAoB,CAApB,EAAuB,YAAvB,CAAoC,CAAC,IAAK,CAAC,KAAK,IAAhD,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;AAiBG;;;AACH,EAAA,aAAa,CAAC,SAAD,EAAoB,cAAc,GAAG,IAArC,EAAyC;AACpD,WAAO,IAAI,qBAAJ,CAA0B,IAA1B,EAAgC,SAAhC,EAA2C,cAA3C,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BG;;;AACH,EAAA,gBAAgB,CACZ,SADY,EACO,cAAc,GAAG,IADxB,EAEZ;AACA,EAAA,KAAA,GAAsC,SAH1B,EAGmC;AAEjD;AACA,UAAM,UAAU,GAAG,KAAK,aAAL,CAAmB,SAAnB,EAA8B,cAA9B,CAAnB,CAHiD,CAIjD;AACA;;AACA,WAAO,UAAU,CAAC,GAAX,CAAe,CAAC,IAAI,OAAO,CAAC,CAAD,EAAI,KAAJ,CAA3B,CAAP;AACD;AAED;;;;;;;;;AASG;;;AACH,EAAA,WAAW,CACP,QADO,EAEP,gBAFO,EAEiC;AAC1C,WAAO,IAAI,eAAJ,CACH,iBAAiB,CAAC,CAAC,IAAD,EAAO,QAAP,CAAD,CADd,EACkC,gBADlC,CAAP;AAED;AAED;;;;;;AAMG;;;AACH,EAAA,IAAI,CAAC,KAAD,EAAc;AAChB,QAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAI,YAAJ,CAAiB,IAAjB,EAAuB,KAAvB,CAAP;AACD;AAED;;;;;AAKG;;;AACH,EAAA,IAAI,CAAC,KAAD,EAAc;AAChB,QAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAI,YAAJ,CAAiB,IAAjB,EAAuB,KAAvB,CAAP;AACD;AAED;;;;;;;;AAQG;;;AACH,EAAA,QAAQ,CAAC,UAAD,EAAmB;AACzB,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,UAA3B,CAAP;AACD,GAjT+B,CAmThC;;AAEA;;;;;;;AAOG;;;AACH,EAAA,OAAO,CAAC,UAAD,EAAqB,IAArB,EAAkC;AACvC,WAAO,IAAI,eAAJ,CAAoB,IAApB,EAA0B,UAA1B,EAAsC,IAAtC,CAAP;AACD;AAED;;;AAGG;;;AACH,EAAA,MAAM,GAAA;AACJ,WAAO,IAAI,cAAJ,CAAmB,IAAnB,CAAP;AACD;;AAvU+B,C,CA0UlC;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA,MAAM,aAAN,SAA+B,YAA/B,CAA8C;AAE5C,EAAA,WAAA,CAAsB,KAAtB,EAAgC;AAC9B;AADoB,SAAA,KAAA,GAAA,KAAA;AADd,SAAA,IAAA,GAAO,CAAP;AAGP;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,YAAY,KAAK,KAAL,CAAW,MAAM,QAApC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI,KAAK,IAAL,IAAa,KAAK,KAAL,CAAW,MAA5B,EAAoC;AAClC,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,IAAI,GAAG,KAAK,KAAL,CAAW,KAAK,IAAhB,CAAb;AACA,SAAK,IAAL;AACA,WAAO;AAAC,MAAA,KAAK,EAAE,SAAS,CAAC,IAAD,CAAjB;AAAyB,MAAA,IAAI,EAAE;AAA/B,KAAP;AACD;;AAjB2C;;AAoB9C,MAAM,oBAAN,SAAsC,YAAtC,CAAqD;AACnD,EAAA,WAAA,CACc,MADd,EACyE;AACvE;AADY,SAAA,MAAA,GAAA,MAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,eAAP;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI;AACF,aAAO,KAAK,MAAL,EAAP;AACD,KAFD,CAEE,OAAO,CAAP,EAAU;AACV;AACA,MAAA,CAAC,CAAC,OAAF,GACI,mDAAmD,CAAC,CAAC,OAAO,EADhE;AAEA,YAAM,CAAN;AACD;AACF;;AAnBkD;;AAsBrD,MAAM,cAAN,SAAgC,YAAhC,CAA+C;AAK7C,EAAA,WAAA,CAAsB,QAAtB,EAA+C;AAC7C;AADoB,SAAA,QAAA,GAAA,QAAA;AAEpB,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAzB4C;;AA4B/C,MAAM,YAAN,SAA8B,YAA9B,CAA6C;AAQ3C,EAAA,WAAA,CAAsB,QAAtB,EAA2D,QAA3D,EAA2E;AACzE;AADoB,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,QAAA,GAAA,QAAA,CAAgB,CAH3E;;AACA,SAAA,KAAA,GAAQ,CAAR;AAIE,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB;AACA;AACA;AACA;AACA,WAAO,KAAK,KAAL,KAAe,KAAK,QAA3B,EAAqC;AACnC,YAAM,OAAO,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAtB,CADmC,CAEnC;;AACA,UAAI,OAAO,CAAC,IAAZ,EAAkB;AAChB,eAAO,OAAP;AACD;;AACD,MAAA,EAAE,CAAC,OAAH,CAAW,OAAO,CAAC,KAAnB;AACD;;AACD,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAxC0C;;AA2C7C,MAAM,YAAN,SAA8B,YAA9B,CAA6C;AAE3C,EAAA,WAAA,CAAsB,QAAtB,EAA2D,QAA3D,EAA2E;AACzE;AADoB,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,QAAA,GAAA,QAAA;AAD3D,SAAA,KAAA,GAAQ,CAAR;AAGC;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI,KAAK,KAAL,MAAgB,KAAK,QAAzB,EAAmC;AACjC,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAf0C,C,CAkB7C;AACA;AACA;;;AACA,MAAM,qBAAN,SAAuC,YAAvC,CAAwD;AAKtD,EAAA,WAAA,CACc,QADd,EACmD,SADnD,EAEc,oBAAA,GAAuB,IAFrC,EAEyC;AACvC;AAFY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,SAAA,GAAA,SAAA;AACrC,SAAA,oBAAA,GAAA,oBAAA;AAEZ,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,mBAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,UAAM,KAAK,GAAQ,EAAnB;;AACA,WAAO,KAAK,CAAC,MAAN,GAAe,KAAK,SAA3B,EAAsC;AACpC,YAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,UAAI,IAAI,CAAC,IAAT,EAAe;AACb,YAAI,KAAK,oBAAL,IAA6B,KAAK,CAAC,MAAN,GAAe,CAAhD,EAAmD;AACjD,iBAAO;AAAC,YAAA,KAAK,EAAE,KAAR;AAAe,YAAA,IAAI,EAAE;AAArB,WAAP;AACD;;AACD,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;;AACD,MAAA,KAAK,CAAC,IAAN,CAAW,IAAI,CAAC,KAAhB;AACD;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,KAAR;AAAe,MAAA,IAAI,EAAE;AAArB,KAAP;AACD;;AAtCqD;;AAyCxD,MAAM,cAAN,SAAgC,YAAhC,CAA+C;AAK7C,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAE8C;AAC5C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEZ,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,WAAO,IAAP,EAAa;AACX,YAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,UAAI,IAAI,CAAC,IAAL,IAAa,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAAjB,EAA6C;AAC3C,eAAO,IAAP;AACD;;AACD,MAAA,EAAE,CAAC,OAAH,CAAW,IAAI,CAAC,KAAhB;AACD;AACF;;AAjC4C;;AAoC/C,MAAM,WAAN,SAAgC,YAAhC,CAA+C;AAC7C,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAEwC;AACtC;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,SAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAM,MAAM,GAAG,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAAf;AACA,UAAM,aAAa,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAlC4C;;AAqC/C,MAAM,yBAAN,SAA2C,YAA3C,CAA0D;AAExD,EAAA,WAAA,CACc,QADd,EAEc,OAFd,EAEgD;AAC9C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,OAAA,GAAA,OAAA;AAHd,SAAA,KAAA,GAAQ,CAAR;AAKE,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,kBAAjC;AACD;;AAMS,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEe,QAAV,UAAU,GAAA;AACd,WAAO,IAAP,EAAa;AACX,UAAI;AACF,eAAO,MAAM,KAAK,QAAL,CAAc,IAAd,EAAb;AACD,OAFD,CAEE,OAAO,CAAP,EAAU;AACV,YAAI,CAAC,KAAK,OAAL,CAAa,CAAb,CAAL,EAAsB;AACpB,iBAAO;AAAC,YAAA,KAAK,EAAE,IAAR;AAAc,YAAA,IAAI,EAAE;AAApB,WAAP;AACD,SAHS,CAIV;AAEA;AACA;AACA;;AACD;AACF;AACF;;AAzCuD;;AA4C1D,MAAM,gBAAN,SAAqC,YAArC,CAAoD;AAClD,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAEiD;AAC/C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,cAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAM,MAAM,GAAG,MAAM,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAArB;AACA,UAAM,aAAa,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAlCiD,C,CAqCpD;AACA;;AAEA;;;;;;;AAOG;;;AACH,OAAM,MAAgB,iBAAhB,SAA6C,YAA7C,CAA4D;AAQhE,EAAA,WAAA,GAAA;AACE;AACA,SAAK,WAAL,GAAmB,IAAI,iBAAJ,EAAnB;AACA,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAgBe,QAAV,UAAU,GAAA;AACd;AACA;AACA;AACA,WAAO,KAAK,WAAL,CAAiB,MAAjB,OAA8B,CAArC,EAAwC;AACtC;AACA,UAAI,EAAC,MAAM,KAAK,IAAL,EAAP,CAAJ,EAAwB;AACtB,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,KAAK,WAAL,CAAiB,KAAjB,EAAR;AAAkC,MAAA,IAAI,EAAE;AAAxC,KAAP;AACD;;AAhD+D;;AAkDlE,MAAM,eAAN,SAAoC,iBAApC,CAAwD;AACtD,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAE0C;AACxC;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,aAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO,KAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;;AACA,UAAM,WAAW,GAAG,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAApB;AACA,UAAM,aAAa,GACf,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,WAArC,CADJ;AAEA,SAAK,WAAL,CAAiB,OAAjB,CAAyB,WAAzB,EAdQ,CAgBR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AAED,WAAO,IAAP;AACD;;AApCqD;AAuCxD;;;;;;;;AAQG;;;AACH,OAAM,MAAO,eAAP,SAAkC,YAAlC,CAAiD;AASrD,EAAA,WAAA,CACI,SADJ,EAEqB,gBAFrB,EAE6D;AAC3D;AADmB,SAAA,gBAAA,GAAA,gBAAA,CAAwC,CAV7D;AACA;;AACQ,SAAA,QAAA,GAAuC,IAAvC,CAQqD,CAN7D;;AACQ,SAAA,QAAA,GAA4B,IAA5B;AAON,SAAK,aAAL,GAAqB,SAArB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,UAAM,iBAAiB,GAAG,6CAA1B;AACA,WAAO,GAAG,iBAAiB,aAA3B;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,SAAK,QAAL,GAAgB,KAAK,aAAL,CAAmB,KAAK,QAAxB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAE0B,QAAb,aAAa,CAAC,QAAD,EAAqC;AAE9D;AACA;AACA;AACA;AACA;AACA,UAAM,QAAN;;AACA,QAAI,KAAK,QAAL,IAAiB,IAArB,EAA2B;AACzB,YAAM,cAAc,GAAG,MAAM,KAAK,aAAL,CAAmB,IAAnB,EAA7B;;AACA,UAAI,cAAc,CAAC,IAAnB,EAAyB;AACvB;AACA,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;;AACD,WAAK,QAAL,GAAgB,cAAc,CAAC,KAA/B;;AACA,UAAI,KAAK,gBAAL,IAAyB,IAA7B,EAAmC;AACjC,aAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,YAAd,CAA2B,KAAK,gBAAhC,CAAhB;AACD;AACF;;AACD,UAAM,UAAU,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAzB;;AACA,QAAI,UAAU,CAAC,IAAf,EAAqB;AACnB,WAAK,QAAL,GAAgB,IAAhB;AACA,aAAO,KAAK,aAAL,CAAmB,QAAnB,CAAP;AACD;;AACD,WAAO,UAAP;AACD;;AAnDoD;AAsDvD,OAAA,IAAY,eAAZ;;AAAA,CAAA,UAAY,eAAZ,EAA2B;AACzB,EAAA,eAAA,CAAA,eAAA,CAAA,MAAA,CAAA,GAAA,CAAA,CAAA,GAAA,MAAA;AACA,EAAA,eAAA,CAAA,eAAA,CAAA,UAAA,CAAA,GAAA,CAAA,CAAA,GAAA,UAAA;AACA,EAAA,eAAA,CAAA,eAAA,CAAA,SAAA,CAAA,GAAA,CAAA,CAAA,GAAA,SAAA,CAHyB,CAGd;AACZ,CAJD,EAAY,eAAe,KAAf,eAAe,GAAA,EAAA,CAA3B;AAMA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4BG;;;AACH,MAAM,WAAN,SAAwD,YAAxD,CAAuE;AAIrE,EAAA,WAAA,CACuB,SADvB,EAEuB,YAAA,GAAgC,eAAe,CAAC,IAFvE,EAE2E;AACzE;AAFqB,SAAA,SAAA,GAAA,SAAA;AACA,SAAA,YAAA,GAAA,YAAA;AALf,SAAA,KAAA,GAAQ,CAAR;AACA,SAAA,cAAA,GAA6C,IAA7C;AAMP;;AAED,EAAA,OAAO,GAAA;AACL,UAAM,iBAAiB,GAAG,yCAA1B;AACA,WAAO,IAAI,iBAAiB,UAA5B;AACD;;AAEsB,QAAT,SAAS,CAAC,UAAD,EAAuC;AAE5D;AACA;AACA,UAAM,UAAN,CAJ4D,CAM5D;AACA;;AACA,QAAI,YAAY,GAAG,CAAnB;AACA,QAAI,aAAa,GAAG,CAApB;;AAEA,aAAS,OAAT,CAAiB,SAAjB,EAA6C;AAC3C,UAAI,SAAS,YAAY,YAAzB,EAAuC;AACrC,cAAM,MAAM,GAAG,SAAS,CAAC,IAAV,EAAf;AACA,eAAO;AACL,UAAA,KAAK,EAAE,MAAM,CAAC,IAAP,CAAY,CAAC,IAAG;AACrB,YAAA,YAAY;;AACZ,gBAAI,CAAC,CAAC,IAAN,EAAY;AACV,cAAA,aAAa;AACd;;AACD,mBAAO,CAAC,CAAC,KAAT;AACD,WANM,CADF;AAQL,UAAA,OAAO,EAAE;AARJ,SAAP;AAUD,OAZD,MAYO;AACL,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,OAAO,EAAE;AAAvB,SAAP;AACD;AACF;;AAED,UAAM,MAAM,GAAM,MAAM,kBAAkB,CAAC,KAAK,SAAN,EAAiB,OAAjB,CAA1C;;AAEA,QAAI,YAAY,KAAK,aAArB,EAAoC;AAClC;AACA,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,QAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,cAAQ,KAAK,YAAb;AACE,aAAK,eAAe,CAAC,IAArB;AACE,gBAAM,IAAI,KAAJ,CACF,iDACA,yBAAyB,KAAK,KAAK,GAFjC,CAAN;;AAGF,aAAK,eAAe,CAAC,QAArB;AACE,iBAAO;AAAC,YAAA,KAAK,EAAE,IAAR;AAAc,YAAA,IAAI,EAAE;AAApB,WAAP;;AACF,aAAK,eAAe,CAAC,OAArB;AACA,gBARF,CASI;;AATJ;AAWD;;AAED,SAAK,KAAL;AACA,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,SAAK,cAAL,GAAsB,KAAK,SAAL,CAAe,KAAK,cAApB,CAAtB;AACA,WAAO,KAAK,cAAZ;AACD;;AAvEoE,C,CA0EvE;AACA;;AAEA;;;;;;AAMG;;;AACH,OAAM,MAAO,gBAAP,SAAmC,YAAnC,CAAkD;AAGtD,EAAA,WAAA,CACc,QADd,EACmD,UADnD,EACqE;AACnE;AADY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,UAAA,GAAA,UAAA;AAEjD,SAAK,MAAL,GAAc,IAAI,UAAJ,CAA2C,UAA3C,CAAd;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,cAAjC;AACD;AAED;;;AAGG;;;AACO,EAAA,MAAM,GAAA;AACd,WAAO,CAAC,KAAK,MAAL,CAAY,MAAZ,EAAR,EAA8B;AAC5B,YAAM,CAAC,GAAG,KAAK,QAAL,CAAc,IAAd,EAAV;AACA,WAAK,MAAL,CAAY,IAAZ,CAAiB,CAAjB;AACD;AACF;;AAED,EAAA,IAAI,GAAA;AACF,SAAK,MAAL,GADE,CAEF;AACA;AACA;;AACA,WAAO,KAAK,MAAL,CAAY,KAAZ,EAAP;AACD;;AA9BqD;AAiCxD;;;;;AAKG;;AACH,OAAM,MAAO,eAAP,SAAkC,gBAAlC,CAAqD;AAUzD,EAAA,WAAA,CACc,QADd,EACmD,UADnD,EAEI,IAFJ,EAEiB;AACf,UAAM,QAAN,EAAgB,UAAhB;AAFY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,UAAA,GAAA,UAAA,CAClC,CALjB;;AACQ,SAAA,iBAAA,GAAoB,KAApB;AAMN,SAAK,MAAL,GAAc,UAAU,CAAC,IAAX,CAAgB,IAAI,IAAI,EAAE,CAAC,IAAH,CAAQ,GAAR,GAAc,QAAd,EAAxB,CAAd;AACA,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEO,EAAA,SAAS,CAAC,GAAD,EAAY;AAC3B,WAAO,IAAI,CAAC,KAAL,CAAW,KAAK,MAAL,KAAgB,GAA3B,CAAP;AACD;;AAES,EAAA,WAAW,GAAA;AACnB,WAAO,KAAK,SAAL,CAAe,KAAK,MAAL,CAAY,MAAZ,EAAf,CAAP;AACD;;AAEe,QAAV,UAAU,GAAA;AACd;AACA,QAAI,CAAC,KAAK,iBAAV,EAA6B;AAC3B,WAAK,MAAL;AACD;;AACD,WAAO,CAAC,KAAK,MAAL,CAAY,OAAZ,EAAR,EAA+B;AAC7B,YAAM,WAAW,GAAG,KAAK,WAAL,EAApB;AACA,YAAM,MAAM,GAAG,MAAM,KAAK,MAAL,CAAY,aAAZ,CAA0B,WAA1B,CAArB;;AACA,UAAI,MAAM,CAAC,IAAX,EAAiB;AACf,aAAK,iBAAL,GAAyB,IAAzB;AACD,OAFD,MAEO;AACL,aAAK,MAAL;AACA,eAAO,MAAP;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAP;AACD;;AAnDwD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer';\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems(items) {\n    return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start) {\n    let i = start;\n    return iteratorFromFunction(() => ({ value: i++, done: false }));\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction(func) {\n    return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n    return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n    return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n    return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport class LazyIterator {\n    /**\n     * Collect all remaining elements of a bounded stream into an array.\n     * Obviously this will succeed only for small streams that fit in memory.\n     * Useful for testing.\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    async toArray() {\n        const result = [];\n        let x = await this.next();\n        while (!x.done) {\n            result.push(x.value);\n            x = await this.next();\n        }\n        return result;\n    }\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    async toArrayForTest() {\n        const stream = this.prefetch(100);\n        const result = [];\n        let x = await stream.next();\n        while (!x.done) {\n            result.push(x.value);\n            x = await stream.next();\n        }\n        return result;\n    }\n    /**\n     * Draw items from the stream until it is exhausted.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    async resolveFully() {\n        let x = await this.next();\n        while (!x.done) {\n            x = await this.next();\n        }\n    }\n    /**\n     * Draw items from the stream until it is exhausted, or a predicate fails.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n    async resolveWhile(predicate) {\n        let x = await this.next();\n        let shouldContinue = predicate(x.value);\n        while ((!x.done) && shouldContinue) {\n            x = await this.next();\n            shouldContinue = predicate(x.value);\n        }\n    }\n    /**\n     * Handles errors thrown on this stream using a provided handler function.\n     *\n     * @param handler A function that handles any `Error` thrown during a `next()`\n     *   call and returns true if the stream should continue (dropping the failed\n     *   call) or false if the stream should quietly terminate.  If the handler\n     *   itself throws (or rethrows) an `Error`, that will be propagated.\n     *\n     * @returns A `LazyIterator` of elements passed through from upstream,\n     *   possibly filtering or terminating on upstream `next()` calls that\n     *   throw an `Error`.\n     */\n    handleErrors(handler) {\n        return new ErrorHandlingLazyIterator(this, handler);\n    }\n    // TODO(soergel): Implement reduce() etc.\n    /**\n     * Filters this stream according to `predicate`.\n     *\n     * @param predicate A function mapping a stream element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `LazyIterator` of elements for which the predicate was true.\n     */\n    filter(predicate) {\n        return new FilterIterator(this, predicate);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    map(transform) {\n        return new MapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through an async 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a `Promise` for a\n     *   transformed stream element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    mapAsync(transform) {\n        return new AsyncMapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform, forcing serial execution.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n    serialMapAsync(transform) {\n        return new AsyncMapIterator(this, transform).serial();\n    }\n    /**\n     * Maps this stream through a 1-to-many transform.\n     *\n     * @param transform A function mapping a stream element to an array of\n     *   transformed elements.\n     *\n     * @returns A `DataStream` of transformed elements.\n     */\n    flatmap(transform) {\n        return new FlatmapIterator(this, transform);\n    }\n    /**\n     * Apply a function to every element of the stream.\n     *\n     * @param f A function to apply to each stream element.\n     */\n    async forEachAsync(f) {\n        return this.map(f).resolveFully();\n    }\n    /**\n     * Apply a function to every element of the stream, forcing serial execution.\n     *\n     * @param f A function to apply to each stream element.  Should return 'true'\n     *   to indicate that the stream should continue, or 'false' to cause it to\n     *   terminate.\n     */\n    async serialForEach(f) {\n        return this.serialMapAsync(f).resolveWhile(x => (x === true));\n    }\n    /**\n     * Groups elements into batches, represented as arrays of elements.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n     * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n     * form, which is needed for vectorized computation.\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `LazyIterator` of batches of elements, represented as arrays\n     *   of the original element type.\n     */\n    rowMajorBatch(batchSize, smallLastBatch = true) {\n        return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n    }\n    /**\n     * Groups elements into batches, represented in column-major form.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"column-major\" means that the resulting batch is a (potentially\n     * nested) structure representing the columns.  Each column entry, then,\n     * contains a collection of the values found in that column for a range of\n     * input elements.  This representation allows for vectorized computation, in\n     * contrast to the row-major form.\n     *\n     * The inputs should all have the same nested structure (i.e., of arrays and\n     * dicts).  The result is a single object with the same nested structure,\n     * where the leaves are arrays collecting the values of the inputs at that\n     * location (or, optionally, the result of a custom function applied to those\n     * arrays).\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @param zipFn: (optional) A function that expects an array of elements at a\n     *   single node of the object tree, and returns a `DeepMapResult`.  The\n     *   `DeepMapResult` either provides a result value for that node (i.e.,\n     *   representing the subtree), or indicates that the node should be processed\n     *   recursively.  The default zipFn recurses as far as possible and places\n     *   arrays at the leaves.\n     * @returns A `LazyIterator` of batches of elements, represented as an object\n     *   with collections at the leaves.\n     */\n    columnMajorBatch(batchSize, smallLastBatch = true, \n    // tslint:disable-next-line:no-any\n    zipFn = zipToList) {\n        // First collect the desired number of input elements as a row-major batch.\n        const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n        // Now 'rotate' or 'pivot' the data, collecting all values from each column\n        // in the batch (i.e., for each key within the elements) into an array.\n        return rowBatches.map(x => deepZip(x, zipFn));\n    }\n    /**\n     * Concatenate this `LazyIterator` with another.\n     *\n     * @param iterator A `LazyIterator` to be concatenated onto this one.\n     * @param baseErrorHandler An optional function that can intercept `Error`s\n     *   raised during a `next()` call on the base stream.  This function can\n     *   decide whether the error should be propagated, whether the error should\n     *   be ignored, or whether the base stream should be terminated.\n     * @returns A `LazyIterator`.\n     */\n    concatenate(iterator, baseErrorHandler) {\n        return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n    }\n    /**\n     * Limits this stream to return at most `count` items.\n     *\n     * @param count The maximum number of items to provide from the stream. If\n     * a negative or undefined value is given, the entire stream is returned\n     *   unaltered.\n     */\n    take(count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new TakeIterator(this, count);\n    }\n    /**\n     * Skips the first `count` items in this stream.\n     *\n     * @param count The number of items to skip.  If a negative or undefined\n     * value is given, the entire stream is returned unaltered.\n     */\n    skip(count) {\n        if (count < 0 || count == null) {\n            return this;\n        }\n        return new SkipIterator(this, count);\n    }\n    /**\n     * Prefetch the first `bufferSize` items in this stream.\n     *\n     * Note this prefetches Promises, but makes no guarantees about when those\n     * Promises resolve.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     */\n    prefetch(bufferSize) {\n        return new PrefetchIterator(this, bufferSize);\n    }\n    // TODO(soergel): deep sharded shuffle, where supported\n    /**\n     * Randomly shuffles the elements of this stream.\n     *\n     * @param bufferSize: An integer specifying the number of elements from\n     * this stream from which the new stream will sample.\n     * @param seed: (Optional.) An integer specifying the random seed that\n     * will be used to create the distribution.\n     */\n    shuffle(windowSize, seed) {\n        return new ShuffleIterator(this, windowSize, seed);\n    }\n    /**\n     * Force an iterator to execute serially: each next() call will await the\n     * prior one, so that they cannot execute concurrently.\n     */\n    serial() {\n        return new SerialIterator(this);\n    }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\nclass ArrayIterator extends LazyIterator {\n    constructor(items) {\n        super();\n        this.items = items;\n        this.trav = 0;\n    }\n    summary() {\n        return `Array of ${this.items.length} items`;\n    }\n    async next() {\n        if (this.trav >= this.items.length) {\n            return { value: null, done: true };\n        }\n        const item = this.items[this.trav];\n        this.trav++;\n        return { value: deepClone(item), done: false };\n    }\n}\nclass FunctionCallIterator extends LazyIterator {\n    constructor(nextFn) {\n        super();\n        this.nextFn = nextFn;\n    }\n    summary() {\n        return `Function call`;\n    }\n    async next() {\n        try {\n            return this.nextFn();\n        }\n        catch (e) {\n            // Modify the error message but leave the stack trace intact\n            e.message =\n                `Error thrown while iterating through a dataset: ${e.message}`;\n            throw e;\n        }\n    }\n}\nclass SerialIterator extends LazyIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Serial`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        return this.upstream.next();\n    }\n}\nclass SkipIterator extends LazyIterator {\n    constructor(upstream, maxCount) {\n        super();\n        this.upstream = upstream;\n        this.maxCount = maxCount;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.count = 0;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Skip`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n        // collecting next() promises in an Array and then waiting for\n        // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n        // maybe delayed GC.\n        while (this.count++ < this.maxCount) {\n            const skipped = await this.upstream.next();\n            // short-circuit if upstream is already empty\n            if (skipped.done) {\n                return skipped;\n            }\n            tf.dispose(skipped.value);\n        }\n        return this.upstream.next();\n    }\n}\nclass TakeIterator extends LazyIterator {\n    constructor(upstream, maxCount) {\n        super();\n        this.upstream = upstream;\n        this.maxCount = maxCount;\n        this.count = 0;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Take`;\n    }\n    async next() {\n        if (this.count++ >= this.maxCount) {\n            return { value: null, done: true };\n        }\n        return this.upstream.next();\n    }\n}\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator extends LazyIterator {\n    constructor(upstream, batchSize, enableSmallLastBatch = true) {\n        super();\n        this.upstream = upstream;\n        this.batchSize = batchSize;\n        this.enableSmallLastBatch = enableSmallLastBatch;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> RowMajorBatch`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        const batch = [];\n        while (batch.length < this.batchSize) {\n            const item = await this.upstream.next();\n            if (item.done) {\n                if (this.enableSmallLastBatch && batch.length > 0) {\n                    return { value: batch, done: false };\n                }\n                return { value: null, done: true };\n            }\n            batch.push(item.value);\n        }\n        return { value: batch, done: false };\n    }\n}\nclass FilterIterator extends LazyIterator {\n    constructor(upstream, predicate) {\n        super();\n        this.upstream = upstream;\n        this.predicate = predicate;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Filter`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        while (true) {\n            const item = await this.upstream.next();\n            if (item.done || this.predicate(item.value)) {\n                return item;\n            }\n            tf.dispose(item.value);\n        }\n    }\n}\nclass MapIterator extends LazyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Map`;\n    }\n    async next() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return { value: null, done: true };\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // That's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying\n        // any intermediate Tensors.  Here we are concerned only about the\n        // inputs.\n        const mapped = this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n        // TODO(soergel) faster intersection\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return { value: mapped, done: false };\n    }\n}\nclass ErrorHandlingLazyIterator extends LazyIterator {\n    constructor(upstream, handler) {\n        super();\n        this.upstream = upstream;\n        this.handler = handler;\n        this.count = 0;\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    summary() {\n        return `${this.upstream.summary()} -> handleErrors`;\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        while (true) {\n            try {\n                return await this.upstream.next();\n            }\n            catch (e) {\n                if (!this.handler(e)) {\n                    return { value: null, done: true };\n                }\n                // If the handler returns true, loop and fetch the next upstream item.\n                // If the upstream iterator throws an endless stream of errors, and if\n                // the handler says to ignore them, then we loop forever here.  That is\n                // the correct behavior-- it's up to the handler to decide when to stop.\n            }\n        }\n    }\n}\nclass AsyncMapIterator extends LazyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> AsyncMap`;\n    }\n    async next() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return { value: null, done: true };\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // That's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying\n        // any intermediate Tensors.  Here we are concerned only about the\n        // inputs.\n        const mapped = await this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mapped);\n        // TODO(soergel) faster intersection\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return { value: mapped, done: false };\n    }\n}\n// Iterators that maintain a queue of pending items\n// ============================================================================\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport class OneToManyIterator extends LazyIterator {\n    constructor() {\n        super();\n        this.outputQueue = new GrowingRingBuffer();\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    async serialNext() {\n        // Fetch so that the queue contains at least one item if possible.\n        // If the upstream source is exhausted, AND there are no items left in\n        // the output queue, then this stream is also exhausted.\n        while (this.outputQueue.length() === 0) {\n            // TODO(soergel): consider parallel reads.\n            if (!await this.pump()) {\n                return { value: null, done: true };\n            }\n        }\n        return { value: this.outputQueue.shift(), done: false };\n    }\n}\nclass FlatmapIterator extends OneToManyIterator {\n    constructor(upstream, transform) {\n        super();\n        this.upstream = upstream;\n        this.transform = transform;\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Flatmap`;\n    }\n    async pump() {\n        const item = await this.upstream.next();\n        if (item.done) {\n            return false;\n        }\n        const inputTensors = tf.tensor_util.getTensorsInContainer(item.value);\n        // Careful: the transform may mutate the item in place.\n        // that's why we have to remember the input Tensors above, and then\n        // below dispose only those that were not passed through to the output.\n        // Note too that the transform function is responsible for tidying any\n        // intermediate Tensors.  Here we are concerned only about the inputs.\n        const mappedArray = this.transform(item.value);\n        const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n        this.outputQueue.pushAll(mappedArray);\n        // TODO(soergel) faster intersection, and deduplicate outputTensors\n        // TODO(soergel) move to tf.disposeExcept(in, out)?\n        for (const t of inputTensors) {\n            if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                t.dispose();\n            }\n        }\n        return true;\n    }\n}\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator extends LazyIterator {\n    constructor(iterators, baseErrorHandler) {\n        super();\n        this.baseErrorHandler = baseErrorHandler;\n        // Strict Promise execution order:\n        // a next() call may not even begin until the previous one completes.\n        this.lastRead = null;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.iterator = null;\n        this.moreIterators = iterators;\n    }\n    summary() {\n        const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n        return `${upstreamSummaries} -> Chained`;\n    }\n    async next() {\n        this.lastRead = this.readFromChain(this.lastRead);\n        return this.lastRead;\n    }\n    async readFromChain(lastRead) {\n        // Must await on the previous read since the previous read may have advanced\n        // the stream of streams, from which we need to read.\n        // This is unfortunate since we can't parallelize reads. Which means\n        // prefetching of chained streams is a no-op.\n        // One solution is to prefetch immediately upstream of this.\n        await lastRead;\n        if (this.iterator == null) {\n            const iteratorResult = await this.moreIterators.next();\n            if (iteratorResult.done) {\n                // No more streams to stream from.\n                return { value: null, done: true };\n            }\n            this.iterator = iteratorResult.value;\n            if (this.baseErrorHandler != null) {\n                this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n            }\n        }\n        const itemResult = await this.iterator.next();\n        if (itemResult.done) {\n            this.iterator = null;\n            return this.readFromChain(lastRead);\n        }\n        return itemResult;\n    }\n}\nexport var ZipMismatchMode;\n(function (ZipMismatchMode) {\n    ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n    ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n    ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator extends LazyIterator {\n    constructor(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n        super();\n        this.iterators = iterators;\n        this.mismatchMode = mismatchMode;\n        this.count = 0;\n        this.currentPromise = null;\n    }\n    summary() {\n        const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n        return `{${upstreamSummaries}} -> Zip`;\n    }\n    async nextState(afterState) {\n        // This chaining ensures that the underlying next() are not even called\n        // before the previous ones have resolved.\n        await afterState;\n        // Collect underlying iterator \"done\" signals as a side effect in\n        // getNext()\n        let numIterators = 0;\n        let iteratorsDone = 0;\n        function getNext(container) {\n            if (container instanceof LazyIterator) {\n                const result = container.next();\n                return {\n                    value: result.then(x => {\n                        numIterators++;\n                        if (x.done) {\n                            iteratorsDone++;\n                        }\n                        return x.value;\n                    }),\n                    recurse: false\n                };\n            }\n            else {\n                return { value: null, recurse: true };\n            }\n        }\n        const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n        if (numIterators === iteratorsDone) {\n            // The streams have all ended.\n            return { value: null, done: true };\n        }\n        if (iteratorsDone > 0) {\n            switch (this.mismatchMode) {\n                case ZipMismatchMode.FAIL:\n                    throw new Error('Zipped streams should have the same length. ' +\n                        `Mismatched at element ${this.count}.`);\n                case ZipMismatchMode.SHORTEST:\n                    return { value: null, done: true };\n                case ZipMismatchMode.LONGEST:\n                default:\n                // Continue.  The exhausted streams already produced value: null.\n            }\n        }\n        this.count++;\n        return { value: mapped, done: false };\n    }\n    async next() {\n        this.currentPromise = this.nextState(this.currentPromise);\n        return this.currentPromise;\n    }\n}\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator extends LazyIterator {\n    constructor(upstream, bufferSize) {\n        super();\n        this.upstream = upstream;\n        this.bufferSize = bufferSize;\n        this.buffer = new RingBuffer(bufferSize);\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Prefetch`;\n    }\n    /**\n     * Refill the prefetch buffer.  Returns only after the buffer is full, or\n     * the upstream source is exhausted.\n     */\n    refill() {\n        while (!this.buffer.isFull()) {\n            const v = this.upstream.next();\n            this.buffer.push(v);\n        }\n    }\n    next() {\n        this.refill();\n        // This shift will never throw an error because the buffer is always\n        // full after a refill. If the stream is exhausted, the buffer will be\n        // full of Promises that will resolve to the end-of-stream signal.\n        return this.buffer.shift();\n    }\n}\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator extends PrefetchIterator {\n    constructor(upstream, windowSize, seed) {\n        super(upstream, windowSize);\n        this.upstream = upstream;\n        this.windowSize = windowSize;\n        // Local state that should not be clobbered by out-of-order execution.\n        this.upstreamExhausted = false;\n        this.random = seedrandom.alea(seed || tf.util.now().toString());\n        this.lastRead = Promise.resolve({ value: null, done: false });\n    }\n    async next() {\n        // This sets this.lastRead to a new Promise right away, as opposed to\n        // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n        // would not work because this.nextRead would be updated only after the\n        // promise resolves.\n        this.lastRead = this.lastRead.then(() => this.serialNext());\n        return this.lastRead;\n    }\n    randomInt(max) {\n        return Math.floor(this.random() * max);\n    }\n    chooseIndex() {\n        return this.randomInt(this.buffer.length());\n    }\n    async serialNext() {\n        // TODO(soergel): consider performance\n        if (!this.upstreamExhausted) {\n            this.refill();\n        }\n        while (!this.buffer.isEmpty()) {\n            const chosenIndex = this.chooseIndex();\n            const result = await this.buffer.shuffleExcise(chosenIndex);\n            if (result.done) {\n                this.upstreamExhausted = true;\n            }\n            else {\n                this.refill();\n                return result;\n            }\n        }\n        return { value: null, done: true };\n    }\n}\n//# sourceMappingURL=lazy_iterator.js.map"]},"metadata":{},"sourceType":"module"}