{"ast":null,"code":"import _regeneratorRuntime from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport var ByteChunkIterator = /*#__PURE__*/function (_LazyIterator) {\n  _inherits(ByteChunkIterator, _LazyIterator);\n\n  var _super = _createSuper(ByteChunkIterator);\n\n  function ByteChunkIterator() {\n    _classCallCheck(this, ByteChunkIterator);\n\n    return _super.apply(this, arguments);\n  }\n\n  _createClass(ByteChunkIterator, [{\n    key: \"decodeUTF8\",\n    value:\n    /**\n     * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n     *\n     * The byte arrays producetd from the ByteChunkIterator on which this is\n     * called will be interpreted as concatenated.  No assumptions are made about\n     * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n     * character may span the boundary between chunks.  This naturally happens,\n     * for instance, when reading fixed-size byte arrays from a file.\n     */\n    function decodeUTF8() {\n      return new Utf8Iterator(this);\n    }\n  }]);\n\n  return ByteChunkIterator;\n}(LazyIterator); // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\n\nvar Utf8Iterator = /*#__PURE__*/function (_StringIterator) {\n  _inherits(Utf8Iterator, _StringIterator);\n\n  var _super2 = _createSuper(Utf8Iterator);\n\n  function Utf8Iterator(upstream) {\n    var _this;\n\n    _classCallCheck(this, Utf8Iterator);\n\n    _this = _super2.call(this);\n    _this.upstream = upstream;\n    _this.impl = new Utf8IteratorImpl(upstream);\n    return _this;\n  }\n\n  _createClass(Utf8Iterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return this.impl.summary();\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                return _context.abrupt(\"return\", this.impl.next());\n\n              case 1:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function next() {\n        return _next.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return Utf8Iterator;\n}(StringIterator);\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\n\n\nvar Utf8IteratorImpl = /*#__PURE__*/function (_OneToManyIterator) {\n  _inherits(Utf8IteratorImpl, _OneToManyIterator);\n\n  var _super3 = _createSuper(Utf8IteratorImpl);\n\n  function Utf8IteratorImpl(upstream) {\n    var _this2;\n\n    _classCallCheck(this, Utf8IteratorImpl);\n\n    _this2 = _super3.call(this);\n    _this2.upstream = upstream;\n\n    if (env().get('IS_BROWSER')) {\n      _this2.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      var _require = require('string_decoder'),\n          StringDecoder = _require.StringDecoder;\n\n      _this2.decoder = new StringDecoder('utf8');\n    }\n\n    return _this2;\n  }\n\n  _createClass(Utf8IteratorImpl, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Utf8\");\n    }\n  }, {\n    key: \"pump\",\n    value: function () {\n      var _pump = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        var chunkResult, chunk, text;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return this.upstream.next();\n\n              case 2:\n                chunkResult = _context2.sent;\n\n                if (!chunkResult.done) {\n                  _context2.next = 7;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\", false);\n\n              case 7:\n                chunk = chunkResult.value;\n\n              case 8:\n                if (env().get('IS_BROWSER')) {\n                  text = this.decoder.decode(chunk, {\n                    stream: true\n                  });\n                } else {\n                  text = this.decoder.write(Buffer.from(chunk.buffer));\n                }\n\n                this.outputQueue.push(text);\n                return _context2.abrupt(\"return\", true);\n\n              case 11:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function pump() {\n        return _pump.apply(this, arguments);\n      }\n\n      return pump;\n    }()\n  }]);\n\n  return Utf8IteratorImpl;\n}(OneToManyIterator);","map":{"version":3,"sources":["../../src/iterators/byte_chunk_iterator.ts"],"names":[],"mappings":";;;;;;;AAAA;;;;;;;;;;;;;;;;AAgBG;AAEH,SAAQ,GAAR,QAAkB,uBAAlB;AACA,SAAQ,YAAR,EAAsB,iBAAtB,QAA8C,iBAA9C;AACA,SAAQ,cAAR,QAA6B,mBAA7B;AAEA,WAAsB,iBAAtB;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AACE;;;;;;;;AAQG;AACH,0BAAU;AACR,aAAO,IAAI,YAAJ,CAAiB,IAAjB,CAAP;AACD;AAZH;;AAAA;AAAA,EAAgD,YAAhD,E,CAeA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;;IAEM,Y;;;;;AAGJ,wBAAsB,QAAtB,EAAwD;AAAA;;AAAA;;AACtD;AADoB,UAAA,QAAA,GAAA,QAAA;AAEpB,UAAK,IAAL,GAAY,IAAI,gBAAJ,CAAqB,QAArB,CAAZ;AAFsD;AAGvD;;;;WAED,mBAAO;AACL,aAAO,KAAK,IAAL,CAAU,OAAV,EAAP;AACD;;;;2EAED;AAAA;AAAA;AAAA;AAAA;AAAA,iDACS,KAAK,IAAL,CAAU,IAAV,EADT;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;EAZyB,c;AAiB3B;;;;;;;;;;;;;;;;;;;;;AAqBG;;;IACG,gB;;;;;AAMJ,4BAA+B,QAA/B,EAAiE;AAAA;;AAAA;;AAC/D;AAD6B,WAAA,QAAA,GAAA,QAAA;;AAE7B,QAAI,GAAG,GAAG,GAAN,CAAU,YAAV,CAAJ,EAA6B;AAC3B,aAAK,OAAL,GAAe,IAAI,WAAJ,CAAgB,OAAhB,CAAf;AACD,KAFD,MAEO;AACL;AADK,qBAEmB,OAAO,CAAC,gBAAD,CAF1B;AAAA,UAEE,aAFF,YAEE,aAFF;;AAGL,aAAK,OAAL,GAAe,IAAI,aAAJ,CAAkB,MAAlB,CAAf;AACD;;AAR8D;AAShE;;;;WACD,mBAAO;AACL,uBAAU,KAAK,QAAL,CAAc,OAAd,EAAV;AACD;;;;2EAED;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAC4B,KAAK,QAAL,CAAc,IAAd,EAD5B;;AAAA;AACQ,gBAAA,WADR;;AAAA,qBAGM,WAAW,CAAC,IAHlB;AAAA;AAAA;AAAA;;AAAA,kDAIW,KAJX;;AAAA;AAMI,gBAAA,KAAK,GAAG,WAAW,CAAC,KAApB;;AANJ;AAUE,oBAAI,GAAG,GAAG,GAAN,CAAU,YAAV,CAAJ,EAA6B;AAC3B,kBAAA,IAAI,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,KAApB,EAA2B;AAAC,oBAAA,MAAM,EAAE;AAAT,mBAA3B,CAAP;AACD,iBAFD,MAEO;AACL,kBAAA,IAAI,GAAG,KAAK,OAAL,CAAa,KAAb,CAAmB,MAAM,CAAC,IAAP,CAAY,KAAK,CAAC,MAAlB,CAAnB,CAAP;AACD;;AACD,qBAAK,WAAL,CAAiB,IAAjB,CAAsB,IAAtB;AAfF,kDAgBS,IAhBT;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;EApB6B,iB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport class ByteChunkIterator extends LazyIterator {\n    /**\n     * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n     *\n     * The byte arrays producetd from the ByteChunkIterator on which this is\n     * called will be interpreted as concatenated.  No assumptions are made about\n     * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n     * character may span the boundary between chunks.  This naturally happens,\n     * for instance, when reading fixed-size byte arrays from a file.\n     */\n    decodeUTF8() {\n        return new Utf8Iterator(this);\n    }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nclass Utf8Iterator extends StringIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        this.impl = new Utf8IteratorImpl(upstream);\n    }\n    summary() {\n        return this.impl.summary();\n    }\n    async next() {\n        return this.impl.next();\n    }\n}\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nclass Utf8IteratorImpl extends OneToManyIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        if (env().get('IS_BROWSER')) {\n            this.decoder = new TextDecoder('utf-8');\n        }\n        else {\n            // tslint:disable-next-line:no-require-imports\n            const { StringDecoder } = require('string_decoder');\n            this.decoder = new StringDecoder('utf8');\n        }\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Utf8`;\n    }\n    async pump() {\n        const chunkResult = await this.upstream.next();\n        let chunk;\n        if (chunkResult.done) {\n            return false;\n        }\n        else {\n            chunk = chunkResult.value;\n        }\n        let text;\n        if (env().get('IS_BROWSER')) {\n            text = this.decoder.decode(chunk, { stream: true });\n        }\n        else {\n            text = this.decoder.write(Buffer.from(chunk.buffer));\n        }\n        this.outputQueue.push(text);\n        return true;\n    }\n}\n//# sourceMappingURL=byte_chunk_iterator.js.map"]},"metadata":{},"sourceType":"module"}