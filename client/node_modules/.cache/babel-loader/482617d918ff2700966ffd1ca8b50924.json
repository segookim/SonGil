{"ast":null,"code":"import _slicedToArray from \"/Users/kimkiwoong/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\n\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n\n  if (strides == null) {\n    strides = 1;\n  }\n\n  if (pad === 0) {\n    pad = 'valid';\n  }\n\n  var $x = convertToTensor(input, 'x', 'maxPool');\n  var x4D = $x;\n  var reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n    return 'Error in pool: Either strides or dilations must be 1. ' + \"Got strides \".concat(strides, \" and dilations '\").concat(dilations, \"'\");\n  });\n  var convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n  var dilation = [convInfo.dilationHeight, convInfo.dilationWidth]; // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n  // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n\n  var basePadding;\n\n  if (pad === 'same') {\n    basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n  } else {\n    basePadding = [[0, 0], [0, 0]];\n  }\n\n  var isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n\n  var _requiredSpaceToBatch = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding),\n      _requiredSpaceToBatch2 = _slicedToArray(_requiredSpaceToBatch, 2),\n      adjustedPadding = _requiredSpaceToBatch2[0],\n      adjustedCrops = _requiredSpaceToBatch2[1];\n\n  var convertedPad = isDilationOne ? pad : 'valid';\n  var convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n  var forwardOp = poolingType === 'avg' ? function () {\n    return avgPool(convertedX, windowShape, strides, convertedPad);\n  } : function () {\n    return maxPool(convertedX, windowShape, strides, convertedPad);\n  };\n  var y = forwardOp();\n  var res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n\n  if (reshapedTo4D) {\n    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n  }\n\n  return res;\n} // Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\n\n\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n  var padStart = basePadding.map(function (b) {\n    return b[0];\n  });\n  var origPadEnd = basePadding.map(function (b) {\n    return b[1];\n  });\n  var fullInputShape = inputShape.concat(padStart, origPadEnd);\n  var padEndExtra = blockShape.map(function (b, i) {\n    return (b - fullInputShape[i] % b) % b;\n  });\n  var padEnd = origPadEnd.map(function (s, i) {\n    return s + padEndExtra[i];\n  });\n  var paddings = blockShape.map(function (_, i) {\n    return [padStart[i], padEnd[i]];\n  });\n  var crops = blockShape.map(function (_, i) {\n    return [0, padEndExtra[i]];\n  });\n  return [paddings, crops];\n} // Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\n\n\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n  // Spatial dimensions of the filters and the upsampled filters in which we\n  // introduce (rate - 1) zeros between consecutive filter values.\n  var dilatedFilterShape = filterShape.map(function (s, i) {\n    return s + (s - 1) * (dilation[i] - 1);\n  });\n  var padExtraShape = dilatedFilterShape.map(function (s) {\n    return s - 1;\n  }); // When padding is odd, we pad more at end, following the same\n  // convention as conv2d.\n\n  var padExtraStart = padExtraShape.map(function (s) {\n    return Math.floor(s / 2);\n  });\n  var padExtraEnd = padExtraShape.map(function (s, i) {\n    return s - padExtraStart[i];\n  });\n  return padExtraShape.map(function (_, i) {\n    return [padExtraStart[i], padExtraEnd[i]];\n  });\n}\n\nexport var pool = op({\n  pool_: pool_\n});","map":{"version":3,"sources":["../../src/ops/pool.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAGH,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AAEA,SAAQ,OAAR,QAAsB,YAAtB;AACA,SAAQ,cAAR,QAA6B,qBAA7B;AACA,OAAO,KAAK,SAAZ,MAA2B,aAA3B;AACA,SAAQ,OAAR,QAAsB,YAAtB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,cAAR,QAA6B,qBAA7B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;AAyBG;;AACH,SAAS,KAAT,CACI,KADJ,EACyB,WADzB,EAEI,WAFJ,EAE8B,GAF9B,EAGI,SAHJ,EAGyC,OAHzC,EAG0E;AACxE,MAAI,SAAS,IAAI,IAAjB,EAAuB;AACrB,IAAA,SAAS,GAAG,CAAC,CAAD,EAAI,CAAJ,CAAZ;AACD;;AACD,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,IAAA,OAAO,GAAG,CAAV;AACD;;AACD,MAAI,GAAG,KAAK,CAAZ,EAAe;AACb,IAAA,GAAG,GAAG,OAAN;AACD;;AAED,MAAM,EAAE,GAAG,eAAe,CAAC,KAAD,EAAQ,GAAR,EAAa,SAAb,CAA1B;AACA,MAAI,GAAG,GAAG,EAAV;AACA,MAAI,YAAY,GAAG,KAAnB;;AAEA,MAAI,EAAE,CAAC,IAAH,KAAY,CAAhB,EAAmB;AACjB,IAAA,YAAY,GAAG,IAAf;AACA,IAAA,GAAG,GAAG,OAAO,CAAC,EAAD,EAAK,CAAC,CAAD,EAAI,EAAE,CAAC,KAAH,CAAS,CAAT,CAAJ,EAAiB,EAAE,CAAC,KAAH,CAAS,CAAT,CAAjB,EAA8B,EAAE,CAAC,KAAH,CAAS,CAAT,CAA9B,CAAL,CAAb;AACD;;AAED,EAAA,IAAI,CAAC,MAAL,CACI,SAAS,CAAC,8BAAV,CAAyC,OAAzC,EAAkD,SAAlD,CADJ,EAEI;AAAA,WAAM,iFACa,OADb,6BACuC,SADvC,MAAN;AAAA,GAFJ;AAKA,MAAM,QAAQ,GAAG,SAAS,CAAC,iBAAV,CACb,GAAG,CAAC,KADS,EACF,WADE,EACW,OADX,EACoB,SADpB,EAC+B,GAD/B,CAAjB;AAEA,MAAM,QAAQ,GACV,CAAC,QAAQ,CAAC,cAAV,EAA0B,QAAQ,CAAC,aAAnC,CADJ,CA3BwE,CA8BxE;AACA;AACA;AACA;;AAEA,MAAI,WAAJ;;AACA,MAAI,GAAG,KAAK,MAAZ,EAAoB;AAClB,IAAA,WAAW,GAAG,4BAA4B,CACtC,CAAC,QAAQ,CAAC,YAAV,EAAwB,QAAQ,CAAC,WAAjC,CADsC,EACS,QADT,CAA1C;AAED,GAHD,MAGO;AACL,IAAA,WAAW,GAAG,CAAC,CAAC,CAAD,EAAI,CAAJ,CAAD,EAAS,CAAC,CAAD,EAAI,CAAJ,CAAT,CAAd;AACD;;AAED,MAAM,aAAa,GAAG,QAAQ,CAAC,CAAD,CAAR,KAAgB,CAAhB,IAAqB,QAAQ,CAAC,CAAD,CAAR,KAAgB,CAA3D;;AA3CwE,8BA4C/B,4BAA4B,CACjE,CAAC,QAAQ,CAAC,QAAV,EAAoB,QAAQ,CAAC,OAA7B,CADiE,EAC1B,QAD0B,EAChB,WADgB,CA5CG;AAAA;AAAA,MA4CjE,eA5CiE;AAAA,MA4ChD,aA5CgD;;AA8CxE,MAAM,YAAY,GAAG,aAAa,GAAG,GAAH,GAAS,OAA3C;AACA,MAAM,UAAU,GACZ,aAAa,GAAG,GAAH,GAAS,cAAc,CAAC,GAAD,EAAM,QAAN,EAAgB,eAAhB,CADxC;AAGA,MAAM,SAAS,GAAG,WAAW,KAAK,KAAhB,GACd;AAAA,WAAM,OAAO,CAAC,UAAD,EAAa,WAAb,EAA0B,OAA1B,EAAmC,YAAnC,CAAb;AAAA,GADc,GAEd;AAAA,WAAM,OAAO,CAAC,UAAD,EAAa,WAAb,EAA0B,OAA1B,EAAmC,YAAnC,CAAb;AAAA,GAFJ;AAGA,MAAM,CAAC,GAAG,SAAS,EAAnB;AAEA,MAAM,GAAG,GAAG,aAAa,GAAG,CAAH,GAAO,cAAc,CAAC,CAAD,EAAI,QAAJ,EAAc,aAAd,CAA9C;;AAEA,MAAI,YAAJ,EAAkB;AAChB,WAAO,OAAO,CAAC,GAAD,EAAM,CAAC,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAD,EAAe,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAf,EAA6B,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA7B,CAAN,CAAd;AACD;;AAED,SAAO,GAAP;AACD,C,CAED;AACA;AACA;;;AACA,SAAS,4BAAT,CACI,UADJ,EACkC,UADlC,EAEI,WAFJ,EAE2B;AACzB,MAAM,QAAQ,GAAG,WAAW,CAAC,GAAZ,CAAgB,UAAA,CAAC;AAAA,WAAI,CAAC,CAAC,CAAD,CAAL;AAAA,GAAjB,CAAjB;AACA,MAAM,UAAU,GAAG,WAAW,CAAC,GAAZ,CAAgB,UAAA,CAAC;AAAA,WAAI,CAAC,CAAC,CAAD,CAAL;AAAA,GAAjB,CAAnB;AACA,MAAM,cAAc,GAAG,UAAU,CAAC,MAAX,CAAkB,QAAlB,EAA4B,UAA5B,CAAvB;AACA,MAAM,WAAW,GAAG,UAAU,CAAC,GAAX,CAAe,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,CAAC,GAAG,cAAc,CAAC,CAAD,CAAd,GAAoB,CAAzB,IAA8B,CAAxC;AAAA,GAAf,CAApB;AACA,MAAM,MAAM,GAAG,UAAU,CAAC,GAAX,CAAe,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,GAAG,WAAW,CAAC,CAAD,CAAzB;AAAA,GAAf,CAAf;AACA,MAAM,QAAQ,GAAG,UAAU,CAAC,GAAX,CAAe,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,QAAQ,CAAC,CAAD,CAAT,EAAc,MAAM,CAAC,CAAD,CAApB,CAAV;AAAA,GAAf,CAAjB;AACA,MAAM,KAAK,GAAG,UAAU,CAAC,GAAX,CAAe,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,CAAD,EAAI,WAAW,CAAC,CAAD,CAAf,CAAV;AAAA,GAAf,CAAd;AACA,SAAO,CAAC,QAAD,EAAW,KAAX,CAAP;AACD,C,CAED;AACA;AACA;;;AACA,SAAS,4BAAT,CACI,WADJ,EACmC,QADnC,EAC6D;AAC3D;AACA;AACA,MAAM,kBAAkB,GAAG,WAAW,CAAC,GAAZ,CAAgB,UAAC,CAAD,EAAI,CAAJ,EAAS;AAClD,WAAO,CAAC,GAAG,CAAC,CAAC,GAAG,CAAL,KAAW,QAAQ,CAAC,CAAD,CAAR,GAAc,CAAzB,CAAX;AACD,GAF0B,CAA3B;AAGA,MAAM,aAAa,GAAG,kBAAkB,CAAC,GAAnB,CAAuB,UAAA,CAAC;AAAA,WAAI,CAAC,GAAG,CAAR;AAAA,GAAxB,CAAtB,CAN2D,CAQ3D;AACA;;AACA,MAAM,aAAa,GAAG,aAAa,CAAC,GAAd,CAAkB,UAAA,CAAC;AAAA,WAAI,IAAI,CAAC,KAAL,CAAW,CAAC,GAAG,CAAf,CAAJ;AAAA,GAAnB,CAAtB;AACA,MAAM,WAAW,GAAG,aAAa,CAAC,GAAd,CAAkB,UAAC,CAAD,EAAI,CAAJ;AAAA,WAAU,CAAC,GAAG,aAAa,CAAC,CAAD,CAA3B;AAAA,GAAlB,CAApB;AACA,SAAO,aAAa,CAAC,GAAd,CAAkB,UAAC,CAAD,EAAI,CAAJ,EAAS;AAChC,WAAO,CAAC,aAAa,CAAC,CAAD,CAAd,EAAmB,WAAW,CAAC,CAAD,CAA9B,CAAP;AACD,GAFM,CAAP;AAGD;;AAED,OAAO,IAAM,IAAI,GAAG,EAAE,CAAC;AAAC,EAAA,KAAK,EAAL;AAAD,CAAD,CAAf","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    const $x = convertToTensor(input, 'x', 'maxPool');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in pool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    let basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n    const convertedPad = isDilationOne ? pad : 'valid';\n    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n    const forwardOp = poolingType === 'avg' ?\n        () => avgPool(convertedX, windowShape, strides, convertedPad) :\n        () => maxPool(convertedX, windowShape, strides, convertedPad);\n    const y = forwardOp();\n    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    const padStart = basePadding.map(b => b[0]);\n    const origPadEnd = basePadding.map(b => b[1]);\n    const fullInputShape = inputShape.concat(padStart, origPadEnd);\n    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n    const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n    const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    const dilatedFilterShape = filterShape.map((s, i) => {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    const padExtraShape = dilatedFilterShape.map(s => s - 1);\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n    return padExtraShape.map((_, i) => {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\nexport const pool = op({ pool_ });\n//# sourceMappingURL=pool.js.map"]},"metadata":{},"sourceType":"module"}