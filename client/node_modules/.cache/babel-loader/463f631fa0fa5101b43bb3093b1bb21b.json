{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\n\nfunction softmax_(logits, dim = -1) {\n  const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n\n  if (dim === -1) {\n    dim = $logits.rank - 1;\n  }\n\n  if (dim !== $logits.rank - 1) {\n    throw Error('Softmax along a non-last dimension is not yet supported. ' + `Logits was rank ${$logits.rank} and dim was ${dim}`);\n  }\n\n  const inputs = {\n    logits: $logits\n  };\n  const attrs = {\n    dim\n  };\n  return ENGINE.runKernel(Softmax, inputs, attrs);\n}\n\nexport const softmax = op({\n  softmax_\n});","map":{"version":3,"sources":["../../src/ops/softmax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,OAAR,QAAmD,iBAAnD;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,EAAR,QAAiB,aAAjB;AAEA;;;;;;;;;;;;;;;;;;;;AAoBG;;AACH,SAAS,QAAT,CAAoC,MAApC,EAA0D,GAAG,GAAG,CAAC,CAAjE,EAAkE;AAChE,QAAM,OAAO,GAAG,eAAe,CAAC,MAAD,EAAS,QAAT,EAAmB,SAAnB,EAA8B,SAA9B,CAA/B;;AAEA,MAAI,GAAG,KAAK,CAAC,CAAb,EAAgB;AACd,IAAA,GAAG,GAAG,OAAO,CAAC,IAAR,GAAe,CAArB;AACD;;AACD,MAAI,GAAG,KAAK,OAAO,CAAC,IAAR,GAAe,CAA3B,EAA8B;AAC5B,UAAM,KAAK,CACP,8DACA,mBAAmB,OAAO,CAAC,IAAI,gBAAgB,GAAG,EAF3C,CAAX;AAGD;;AAED,QAAM,MAAM,GAAkB;AAAC,IAAA,MAAM,EAAE;AAAT,GAA9B;AACA,QAAM,KAAK,GAAiB;AAAC,IAAA;AAAD,GAA5B;AAEA,SAAO,MAAM,CAAC,SAAP,CACH,OADG,EACM,MADN,EACsC,KADtC,CAAP;AAED;;AAED,OAAO,MAAM,OAAO,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAlB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_(logits, dim = -1) {\n    const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n    if (dim === -1) {\n        dim = $logits.rank - 1;\n    }\n    if (dim !== $logits.rank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            `Logits was rank ${$logits.rank} and dim was ${dim}`);\n    }\n    const inputs = { logits: $logits };\n    const attrs = { dim };\n    return ENGINE.runKernel(Softmax, inputs, attrs);\n}\nexport const softmax = op({ softmax_ });\n//# sourceMappingURL=softmax.js.map"]},"metadata":{},"sourceType":"module"}