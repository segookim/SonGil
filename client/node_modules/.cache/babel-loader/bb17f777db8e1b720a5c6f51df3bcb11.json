{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function unaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  cpuKernelImpl,\n  dtype\n}) {\n  return ({\n    inputs,\n    backend\n  }) => {\n    const {\n      x\n    } = inputs;\n    const webglBackend = backend;\n    const $dtype = dtype || x.dtype;\n\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webglBackend.texData.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function binaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  checkOutOfBounds = false,\n  supportsComplex = false,\n  cpuKernelImpl,\n  dtype\n}) {\n  return ({\n    inputs,\n    backend\n  }) => {\n    const {\n      a,\n      b\n    } = inputs;\n    const webglBackend = backend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n      const [real, imag] = [[aData.complexTensorInfos.real, bData.complexTensorInfos.real], [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]].map(complexParts => {\n        const [aPart, bPart] = complexParts;\n        const aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        const bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n        const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      });\n      const complexOutput = complex({\n        inputs: {\n          real,\n          imag\n        },\n        backend: webglBackend\n      });\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag); // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n\n    if (webglBackend.shouldExecuteOnCPU([a, b]) && cpuKernelImpl != null) {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, aData.values, bData.values, $dtype);\n      const out = webglBackend.makeTensorInfo(outShape, $dtype);\n      const outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\nexport function mapActivationToShaderProgram(activation, packed = false) {\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n\n    return LEAKYRELU;\n  }\n\n  throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);\n}","map":{"version":3,"sources":["../../src/kernel_utils/kernel_funcs_utils.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAA8C,GAA9C,EAAwF,UAAxF,QAAyG,uBAAzG;AAGA,SAAQ,eAAR,QAA8B,iBAA9B;AACA,SAAQ,qBAAR,QAAoC,wBAApC;AACA,SAAQ,OAAR,QAAsB,oBAAtB;AACA,SAAQ,SAAR,EAAmB,gBAAnB,QAA0C,sBAA1C;AACA,SAAQ,KAAR,EAAe,YAAf,QAAkC,kBAAlC;AACA,OAAO,KAAK,QAAZ,MAA0B,gBAA1B;AACA,SAAQ,cAAR,QAA6B,gBAA7B;AACA,OAAO,KAAK,eAAZ,MAAiC,uBAAjC;AACA,SAAQ,oBAAR,QAAmC,uBAAnC;AAIA,OAAO,MAAM,uBAAuB,GAAG,yBAAhC;AAEP,OAAO,MAAM,wBAAwB,GAAG;;;AAGvC,CAHM;AAKP,OAAO,MAAM,+BAA+B,GAAG;;;;;AAK9C,CALM;AAcP;;;;;;;AAOG;;AACH,OAAM,SAAU,eAAV,CACF;AAAC,EAAA,SAAD;AAAY,EAAA,eAAZ;AAA6B,EAAA,aAA7B;AAA4C,EAAA;AAA5C,CADE,EACuE;AAE3E,SAAO,CAAC;AAAC,IAAA,MAAD;AAAS,IAAA;AAAT,GAAD,KAAsB;AAC3B,UAAM;AAAC,MAAA;AAAD,QAAM,MAAZ;AACA,UAAM,YAAY,GAAG,OAArB;AAEA,UAAM,MAAM,GAAG,KAAK,IAAI,CAAC,CAAC,KAA1B;;AACA,QAAI,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,CAAhC,KAAwC,aAAa,IAAI,IAA7D,EAAmE;AACjE,YAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,YAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,MAAP,EAA6B,MAA7B,CAA/B;AACA,aAAO,YAAY,CAAC,cAAb,CAA4B,CAAC,CAAC,KAA9B,EAAqC,MAArC,EAA6C,SAA7C,CAAP;AACD;;AAED,UAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,6BAAd,KAAgD,eAAe,IAAI,IADvE;AAEA,QAAI,OAAJ;;AACA,QAAI,sBAAJ,EAA4B;AAC1B,MAAA,OAAO,GAAG,IAAI,oBAAJ,CAAyB,CAAC,CAAC,KAA3B,EAAkC,eAAlC,CAAV;AACD,KAFD,MAEO;AACL,MAAA,OAAO,GAAG,IAAI,cAAJ,CAAmB,CAAC,CAAC,KAArB,EAA4B,SAA5B,CAAV;AACD;;AAED,WAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,CAAtC,EAA2C,MAA3C,CAAP;AACD,GArBD;AAsBD;AAWD;;;;;;;;;AASG;;AACH,OAAM,SAAU,gBAAV,CAA2B;AAC/B,EAAA,SAD+B;AAE/B,EAAA,eAF+B;AAG/B,EAAA,gBAAgB,GAAG,KAHY;AAI/B,EAAA,eAAe,GAAG,KAJa;AAK/B,EAAA,aAL+B;AAM/B,EAAA;AAN+B,CAA3B,EAOmB;AACvB,SAAO,CAAC;AAAC,IAAA,MAAD;AAAS,IAAA;AAAT,GAAD,KAAsB;AAC3B,UAAM;AAAC,MAAA,CAAD;AAAI,MAAA;AAAJ,QAAS,MAAf;AACA,UAAM,YAAY,GAAG,OAArB;;AAEA,QAAI,eAAe,IAAI,CAAC,CAAC,KAAF,KAAY,WAAnC,EAAgD;AAC9C,YAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,YAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AAEA,YAAM,CAAC,IAAD,EAAO,IAAP,IAAe,CACnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CADmB,EAEnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CAFmB,EAGnB,GAHmB,CAGf,YAAY,IAAG;AACnB,cAAM,CAAC,KAAD,EAAQ,KAAR,IAAiB,YAAvB;AAEA,cAAM,OAAO,GAAG;AACd,UAAA,MAAM,EAAE,KAAK,CAAC,MADA;AAEd,UAAA,KAAK,EAAE,KAAK,CAAC,KAFC;AAGd,UAAA,KAAK,EAAE,CAAC,CAAC;AAHK,SAAhB;AAKA,cAAM,OAAO,GAAG;AACd,UAAA,MAAM,EAAE,KAAK,CAAC,MADA;AAEd,UAAA,KAAK,EAAE,KAAK,CAAC,KAFC;AAGd,UAAA,KAAK,EAAE,CAAC,CAAC;AAHK,SAAhB;AAMA,cAAM,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAhB;AACA,eAAO,YAAY,CAAC,eAAb,CACH,OADG,EACM,CAAC,OAAD,EAAU,OAAV,CADN,EAC0B,UAAU,CAAC,KAAK,CAAC,KAAP,EAAc,KAAK,CAAC,KAApB,CADpC,CAAP;AAED,OApBoB,CAArB;AAsBA,YAAM,aAAa,GACf,OAAO,CAAC;AAAC,QAAA,MAAM,EAAE;AAAC,UAAA,IAAD;AAAO,UAAA;AAAP,SAAT;AAAuB,QAAA,OAAO,EAAE;AAAhC,OAAD,CADX;AAGA,MAAA,YAAY,CAAC,6BAAb,CAA2C,IAA3C;AACA,MAAA,YAAY,CAAC,6BAAb,CAA2C,IAA3C,EA9B8C,CAgC9C;;AAEA,aAAO,aAAP;AACD;;AAED,UAAM,MAAM,GAAG,KAAK,IAAI,UAAU,CAAC,CAAC,CAAC,KAAH,EAAU,CAAC,CAAC,KAAZ,CAAlC;;AACA,QAAI,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,EAAI,CAAJ,CAAhC,KAA2C,aAAa,IAAI,IAAhE,EAAsE;AACpE,YAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,YAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,YAAM,CAAC,SAAD,EAAY,QAAZ,IAAwB,aAAa,CACvC,CAAC,CAAC,KADqC,EAC9B,CAAC,CAAC,KAD4B,EACrB,KAAK,CAAC,MADe,EAEvC,KAAK,CAAC,MAFiC,EAEX,MAFW,CAA3C;AAIA,YAAM,GAAG,GAAG,YAAY,CAAC,cAAb,CAA4B,QAA5B,EAAsC,MAAtC,CAAZ;AACA,YAAM,OAAO,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,GAAG,CAAC,MAA7B,CAAhB;AACA,MAAA,OAAO,CAAC,MAAR,GAAiB,SAAjB;AACA,aAAO,GAAP;AACD;;AAED,UAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,8BAAd,KACA,eAAe,IAAI,IAFvB;AAGA,QAAI,OAAJ;;AACA,QAAI,sBAAJ,EAA4B;AAC1B,MAAA,OAAO,GAAG,IAAI,qBAAJ,CACN,eADM,EACW,CAAC,CAAC,KADb,EACoB,CAAC,CAAC,KADtB,EAC6B,gBAD7B,CAAV;AAED,KAHD,MAGO;AACL,MAAA,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAV;AACD;;AAED,WAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,EAAI,CAAJ,CAAtC,EAA8C,MAA9C,CAAP;AACD,GAnED;AAoED;AAED,OAAM,SAAU,4BAAV,CACF,UADE,EACmC,MAAM,GAAG,KAD5C,EACiD;AACrD,MAAI,UAAU,KAAK,QAAnB,EAA6B;AAC3B,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,MAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,MAAhB;AACD,GALD,MAKO,IAAI,UAAU,KAAK,MAAnB,EAA2B;AAChC,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,IAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,IAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,KAAnB,EAA0B;AAC/B,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,GAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,GAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;AACjC,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,KAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,KAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;AACjC,QAAI,MAAJ,EAAY;AACV,aAAO,YAAP;AACD;;AACD,WAAO,KAAP;AACD,GALM,MAKA,IAAI,UAAU,KAAK,WAAnB,EAAgC;AACrC,QAAI,MAAJ,EAAY;AACV,aAAO,gBAAP;AACD;;AACD,WAAO,SAAP;AACD;;AACD,QAAM,IAAI,KAAJ,CAAU,cACZ,UAAU,kDADR,CAAN;AAED","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc({ opSnippet, packedOpSnippet, cpuKernelImpl, dtype }) {\n    return ({ inputs, backend }) => {\n        const { x } = inputs;\n        const webglBackend = backend;\n        const $dtype = dtype || x.dtype;\n        if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n            const xData = webglBackend.texData.get(x.dataId);\n            const outValues = cpuKernelImpl(xData.values, $dtype);\n            return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n        }\n        const shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n        let program;\n        if (shouldUsePackedProgram) {\n            program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n        }\n        else {\n            program = new UnaryOpProgram(x.shape, opSnippet);\n        }\n        return webglBackend.runWebGLProgram(program, [x], $dtype);\n    };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc({ opSnippet, packedOpSnippet, checkOutOfBounds = false, supportsComplex = false, cpuKernelImpl, dtype }) {\n    return ({ inputs, backend }) => {\n        const { a, b } = inputs;\n        const webglBackend = backend;\n        if (supportsComplex && a.dtype === 'complex64') {\n            const aData = webglBackend.texData.get(a.dataId);\n            const bData = webglBackend.texData.get(b.dataId);\n            const [real, imag] = [\n                [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n                [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n            ].map(complexParts => {\n                const [aPart, bPart] = complexParts;\n                const aHandle = {\n                    dataId: aPart.dataId,\n                    dtype: aPart.dtype,\n                    shape: a.shape\n                };\n                const bHandle = {\n                    dataId: bPart.dataId,\n                    dtype: bPart.dtype,\n                    shape: b.shape\n                };\n                const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n                return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n            });\n            const complexOutput = complex({ inputs: { real, imag }, backend: webglBackend });\n            webglBackend.disposeIntermediateTensorInfo(real);\n            webglBackend.disposeIntermediateTensorInfo(imag);\n            // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n            return complexOutput;\n        }\n        const $dtype = dtype || upcastType(a.dtype, b.dtype);\n        if (webglBackend.shouldExecuteOnCPU([a, b]) && cpuKernelImpl != null) {\n            const aData = webglBackend.texData.get(a.dataId);\n            const bData = webglBackend.texData.get(b.dataId);\n            const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, aData.values, bData.values, $dtype);\n            const out = webglBackend.makeTensorInfo(outShape, $dtype);\n            const outData = webglBackend.texData.get(out.dataId);\n            outData.values = outValues;\n            return out;\n        }\n        const shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') &&\n            packedOpSnippet != null;\n        let program;\n        if (shouldUsePackedProgram) {\n            program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n        }\n        else {\n            program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        }\n        return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n    };\n}\nexport function mapActivationToShaderProgram(activation, packed = false) {\n    if (activation === 'linear') {\n        if (packed) {\n            return unary_packed_op.LINEAR;\n        }\n        return unary_op.LINEAR;\n    }\n    else if (activation === 'relu') {\n        if (packed) {\n            return unary_packed_op.RELU;\n        }\n        return unary_op.RELU;\n    }\n    else if (activation === 'elu') {\n        if (packed) {\n            return unary_packed_op.ELU;\n        }\n        return unary_op.ELU;\n    }\n    else if (activation === 'relu6') {\n        if (packed) {\n            return unary_packed_op.RELU6;\n        }\n        return unary_op.RELU6;\n    }\n    else if (activation === 'prelu') {\n        if (packed) {\n            return PRELU_PACKED;\n        }\n        return PRELU;\n    }\n    else if (activation === 'leakyrelu') {\n        if (packed) {\n            return LEAKYRELU_PACKED;\n        }\n        return LEAKYRELU;\n    }\n    throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);\n}\n//# sourceMappingURL=kernel_funcs_utils.js.map"]},"metadata":{},"sourceType":"module"}