{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\n\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\n\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\n\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\n\nasync function fitLoop( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n  if (batchSize == null) {\n    batchSize = 32;\n  }\n\n  if (epochs == null) {\n    epochs = 1;\n  }\n\n  if (shuffle == null) {\n    shuffle = true;\n  }\n\n  if (initialEpoch == null) {\n    initialEpoch = 0;\n  } // TODO(cais): Change const to let below when implementing validation.\n\n\n  let doValidation = false;\n\n  if (valF != null && valIns != null) {\n    doValidation = true; // TODO(cais): verbose message.\n  }\n\n  if (validationSteps != null) {\n    doValidation = true;\n\n    if (stepsPerEpoch == null) {\n      throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n    }\n  }\n\n  const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n  let indexArray;\n\n  if (numTrainSamples != null) {\n    indexArray = range(0, numTrainSamples);\n  }\n\n  if (verbose == null) {\n    verbose = 1;\n  }\n\n  const {\n    callbackList,\n    history\n  } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n  callbackList.setModel(model);\n  model.history = history;\n  await callbackList.onTrainBegin();\n  model.stopTraining_ = false; // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n  // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n  for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n    await callbackList.onEpochBegin(epoch);\n    const epochLogs = {};\n\n    if (stepsPerEpoch != null) {\n      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n    } else {\n      if (shuffle === 'batch') {\n        throw new NotImplementedError('batch shuffling is not implemneted yet');\n      } else if (shuffle) {\n        util.shuffle(indexArray);\n      } // Convert the potentially shuffled indices to Tensor1D, to avoid the\n      // cost of repeated creation of Array1Ds later on.\n\n\n      const epochIndexArray1D = tensor1d(indexArray);\n      const batches = makeBatches(numTrainSamples, batchSize);\n\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchLogs = {};\n        await callbackList.onBatchBegin(batchIndex, batchLogs);\n        tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = batchEnd - batchStart; // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const outs = f(insBatch);\n\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n          }\n\n          if (batchIndex === batches.length - 1) {\n            // Last batch.\n            if (doValidation) {\n              const valOuts = model.testLoop(valF, valIns, batchSize); // Porting Notes: In tfjs-layers, valOuts is always an Array.\n\n              for (let i = 0; i < outLabels.length; ++i) {\n                const label = outLabels[i];\n                const out = valOuts[i];\n                tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n\n                epochLogs['val_' + label] = out;\n              }\n            }\n          }\n        });\n        await callbackList.onBatchEnd(batchIndex, batchLogs);\n        disposeTensorsInLogs(batchLogs);\n\n        if (model.stopTraining_) {\n          break;\n        } // TODO(cais): return outs as list of Tensor.\n\n      }\n\n      epochIndexArray1D.dispose();\n    } // TODO(cais): Run validation at the end of the epoch.\n\n\n    await callbackList.onEpochEnd(epoch, epochLogs);\n\n    if (model.stopTraining_) {\n      break;\n    }\n  }\n\n  await callbackList.onTrainEnd();\n  await model.history.syncData();\n  return model.history;\n}\n\nexport async function fitTensors( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n  if (model.isTraining) {\n    throw new Error('Cannot start training because another fit() call is ongoing.');\n  }\n\n  model.isTraining = true;\n  let inputs;\n  let targets;\n  let inputValX;\n  let inputValY;\n  let valX;\n  let valY;\n  let sampleWeights;\n\n  try {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize); // Validate user data.\n    // TODO(cais): Support sampleWeight.\n\n    const checkBatchAxis = false;\n    const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n    inputs = standardizedOuts[0];\n    targets = standardizedOuts[1];\n    sampleWeights = standardizedOuts[2]; // Prepare validation data.\n\n    let doValidation = false;\n    let valIns;\n\n    if (args.validationData != null && args.validationData.length > 0) {\n      doValidation = true;\n\n      if (args.validationData.length === 2) {\n        // config.validationData consists of valX and valY.\n        inputValX = args.validationData[0];\n        inputValY = args.validationData[1];\n      } else if (args.validationData.length === 3) {\n        throw new NotImplementedError('validationData including sample weights is not supported yet.');\n      } else {\n        throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` + `or 3 (valX, valY, valSampleWeight) items; ` + `${args.validationData} is invalid.`);\n      }\n\n      const checkBatchAxis = true;\n      const valStandardized = await model.standardizeUserData(inputValX, inputValY, null,\n      /** Unused sample weights. */\n      null,\n      /** Unused class weights. */\n      checkBatchAxis, batchSize);\n      valX = valStandardized[0];\n      valY = valStandardized[1];\n      valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n      doValidation = true; // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n\n      const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n      const originalBatchSize = inputs[0].shape[0];\n      valX = sliceArrays(inputs, splitAt, originalBatchSize);\n      inputs = sliceArrays(inputs, 0, splitAt);\n      valY = sliceArrays(targets, splitAt, originalBatchSize);\n      targets = sliceArrays(targets, 0, splitAt); // TODO(cais): Once sampleWeights becomes available, slice it to get\n      //   valSampleWeights.\n\n      valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n    } else if (args.validationSteps != null) {\n      doValidation = true; // TODO(cais): Add useLearningPhase.\n    }\n\n    const ins = inputs.concat(targets).concat(sampleWeights);\n    model.checkTrainableWeightsConsistency(); // TODO(cais): Handle use_learning_phase and learning_phase?\n    // Porting Note: Here we see a key deviation of tfjs-layers from\n    // Keras.\n    //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n    //  we do not construct symbolic computation graphs to embody the\n    //  training process. Instead, we define a function that performs the\n    //  training action. In PyKeras, the data (inputs and targets) are fed\n    //  through graph placeholders. In tfjs-layers, the data are fed as\n    //  function arguments. Since the function are defined below in the\n    //  scope, we don't have equivalents of PyKeras's\n    //  `_make_train_funciton`.\n\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames();\n    let valFunction;\n    let callbackMetrics;\n\n    if (doValidation) {\n      model.makeTestFunction();\n      valFunction = model.testFunction;\n      callbackMetrics = outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      valFunction = null;\n      valIns = [];\n      callbackMetrics = outLabels.slice();\n    }\n\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n    return out;\n  } finally {\n    model.isTraining = false; // Memory clean up.\n\n    disposeNewTensors(inputs, x);\n    disposeNewTensors(targets, y);\n    disposeNewTensors(valX, inputValX);\n    disposeNewTensors(valY, inputValY);\n\n    if (sampleWeights != null) {\n      tfc.dispose(sampleWeights);\n    }\n  } // TODO(cais): Add value to outLabels.\n\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\n\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  } // Make Tensors at least 2D.\n\n\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\n\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  const oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  const tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"sources":["../../src/engine/training_tensors.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;AAEH;;AAEG;AAEH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAgB,MAAhB,EAAkC,QAAlC,EAA4C,IAA5C,QAAuD,uBAAvD;AAEA,SAAQ,UAAR,EAAoB,MAApB,EAA4B,mBAA5B,QAAsD,yBAAtD;AACA,SAAsB,kBAAtB,EAA8F,oBAA9F,QAA4I,mBAA5I;AACA,SAAQ,mBAAR,EAA6B,UAA7B,QAA8C,WAA9C;AACA,SAAQ,oBAAR,QAAmD,SAAnD;AACA,SAAQ,KAAR,QAAoB,qBAApB;AA4IA,OAAM,SAAU,cAAV,CAAyB,SAAzB,EAA0C;AAC9C,EAAA,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,SAAS,GAAG,CAAZ,IAAiB,MAAM,CAAC,SAAP,CAAiB,SAAjB,CADrB,EAEI,MAAM,2DACF,SAAS,EAHjB;AAID;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,WAAV,CACF,MADE,EACuB,KADvB,EACsC,IADtC,EACkD;AACtD,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,WAAO,CAAC,IAAD,CAAP;AACD,GAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;AAChC,WAAO,MAAM,CAAC,GAAP,CAAW,KAAK,IAAI,mBAAmB,CAAC,KAAD,EAAQ,KAAR,EAAe,IAAI,GAAG,KAAtB,CAAvC,CAAP;AACD,GAFM,MAEA;AAAG;AACR,WAAO,mBAAmB,CAAC,MAAD,EAAS,KAAT,EAAgB,IAAI,GAAG,KAAvB,CAA1B;AACD;AACF;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,oBAAV,CACF,MADE,EACuB,OADvB,EACwC;AAC5C,SAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;AACnB,QAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,aAAO,IAAP;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;AAChC,aAAO,MAAM,CAAC,GAAP,CACH,KAAK,IAAK,oBAAoB,CAAC,KAAD,EAAQ,OAAR,CAD3B,CAAP;AAED,KAHM,MAGA;AACL;AACA;AACA,aAAO,MAAM,CACT,MADS,EACD,OAAO,CAAC,KAAR,KAAkB,OAAlB,GAA4B,OAA5B,GAAsC,OAAO,CAAC,KAAR,EADrC,CAAb;AAED;AACF,GAZM,CAAP;AAaD;AAED;;;;;;;AAOG;;AACH,OAAM,SAAU,WAAV,CACF,IADE,EACY,SADZ,EAC6B;AACjC,QAAM,MAAM,GAA4B,EAAxC;AACA,MAAI,UAAU,GAAG,CAAjB;AACA,MAAI,QAAQ,GAAW,IAAvB;;AACA,SAAO,UAAU,GAAG,IAApB,EAA0B;AACxB,IAAA,QAAQ,GAAG,UAAU,GAAG,SAAxB;;AACA,QAAI,QAAQ,IAAI,IAAhB,EAAsB;AACpB,MAAA,QAAQ,GAAG,IAAX;AACD;;AACD,IAAA,MAAM,CAAC,IAAP,CAAY,CAAC,UAAD,EAAa,QAAb,CAAZ;AACA,IAAA,UAAU,GAAG,QAAb;AACD;;AACD,SAAO,MAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BG;;AACH,eAAe,OAAf,EACI;AACA;AACA,KAHJ,EAGgB,CAHhB,EAGiD,GAHjD,EAII,SAJJ,EAI0B,SAJ1B,EAI8C,MAJ9C,EAI+D,OAJ/D,EAKI,SALJ,EAKgC,IALhC,EAMI,MANJ,EAMuB,OANvB,EAMiD,eANjD,EAOI,YAPJ,EAO2B,aAP3B,EAQI,eARJ,EAQ4B;AAC1B,MAAI,SAAS,IAAI,IAAjB,EAAuB;AACrB,IAAA,SAAS,GAAG,EAAZ;AACD;;AACD,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,IAAA,MAAM,GAAG,CAAT;AACD;;AACD,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,IAAA,OAAO,GAAG,IAAV;AACD;;AACD,MAAI,YAAY,IAAI,IAApB,EAA0B;AACxB,IAAA,YAAY,GAAG,CAAf;AACD,GAZyB,CAc1B;;;AACA,MAAI,YAAY,GAAG,KAAnB;;AACA,MAAI,IAAI,IAAI,IAAR,IAAgB,MAAM,IAAI,IAA9B,EAAoC;AAClC,IAAA,YAAY,GAAG,IAAf,CADkC,CAElC;AACD;;AACD,MAAI,eAAe,IAAI,IAAvB,EAA6B;AAC3B,IAAA,YAAY,GAAG,IAAf;;AACA,QAAI,aAAa,IAAI,IAArB,EAA2B;AACzB,YAAM,IAAI,UAAJ,CACF,mEACA,oCAFE,CAAN;AAGD;AACF;;AAED,QAAM,eAAe,GACjB,KAAK,CAAC,eAAN,CAAsB,GAAtB,EAA2B,SAA3B,EAAsC,aAAtC,EAAqD,iBAArD,CADJ;AAEA,MAAI,UAAJ;;AACA,MAAI,eAAe,IAAI,IAAvB,EAA6B;AAC3B,IAAA,UAAU,GAAG,KAAK,CAAC,CAAD,EAAI,eAAJ,CAAlB;AACD;;AAED,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,IAAA,OAAO,GAAG,CAAV;AACD;;AAED,QAAM;AAAC,IAAA,YAAD;AAAe,IAAA;AAAf,MAA0B,kBAAkB,CAC9C,SAD8C,EACnC,OADmC,EAC1B,MAD0B,EAClB,YADkB,EACJ,eADI,EACa,aADb,EAE9C,SAF8C,EAEnC,YAFmC,EAErB,eAFqB,CAAlD;AAGA,EAAA,YAAY,CAAC,QAAb,CAAsB,KAAtB;AACA,EAAA,KAAK,CAAC,OAAN,GAAgB,OAAhB;AACA,QAAM,YAAY,CAAC,YAAb,EAAN;AACA,EAAA,KAAK,CAAC,aAAN,GAAsB,KAAtB,CA9C0B,CA+C1B;AACA;;AAEA,OAAK,IAAI,KAAK,GAAG,YAAjB,EAA+B,KAAK,GAAG,MAAvC,EAA+C,EAAE,KAAjD,EAAwD;AACtD,UAAM,YAAY,CAAC,YAAb,CAA0B,KAA1B,CAAN;AACA,UAAM,SAAS,GAAmB,EAAlC;;AACA,QAAI,aAAa,IAAI,IAArB,EAA2B;AACzB,YAAM,IAAI,mBAAJ,CACF,4CADE,CAAN;AAED,KAHD,MAGO;AACL,UAAI,OAAO,KAAK,OAAhB,EAAyB;AACvB,cAAM,IAAI,mBAAJ,CAAwB,wCAAxB,CAAN;AACD,OAFD,MAEO,IAAI,OAAJ,EAAa;AAClB,QAAA,IAAI,CAAC,OAAL,CAAa,UAAb;AACD,OALI,CAML;AACA;;;AACA,YAAM,iBAAiB,GAAG,QAAQ,CAAC,UAAD,CAAlC;AAEA,YAAM,OAAO,GAAG,WAAW,CAAC,eAAD,EAAkB,SAAlB,CAA3B;;AACA,WAAK,IAAI,UAAU,GAAG,CAAtB,EAAyB,UAAU,GAAG,OAAO,CAAC,MAA9C,EAAsD,EAAE,UAAxD,EAAoE;AAClE,cAAM,SAAS,GAAmB,EAAlC;AACA,cAAM,YAAY,CAAC,YAAb,CAA0B,UAA1B,EAAsC,SAAtC,CAAN;AAEA,QAAA,GAAG,CAAC,IAAJ,CAAS,MAAK;AACZ,gBAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gBAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;AACA,gBAAM,QAAQ,GAAG,mBAAmB,CACf,iBADe,EACI,UADJ,EAEf,QAAQ,GAAG,UAFI,CAApC;AAGA,UAAA,SAAS,CAAC,OAAD,CAAT,GAAqB,UAArB;AACA,UAAA,SAAS,CAAC,MAAD,CAAT,GAAoB,QAAQ,GAAG,UAA/B,CAPY,CASZ;AACA;;AACA,gBAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAD,EAAM,QAAN,CAArC;AACA,gBAAM,IAAI,GAAG,CAAC,CAAC,QAAD,CAAd;;AACA,eAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,kBAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;AACA,kBAAM,GAAG,GAAG,IAAI,CAAC,CAAD,CAAhB;AACA,YAAA,SAAS,CAAC,KAAD,CAAT,GAAmB,GAAnB;AACA,YAAA,GAAG,CAAC,IAAJ,CAAS,GAAT,EAJyC,CAKzC;AACD;;AAED,cAAI,UAAU,KAAK,OAAO,CAAC,MAAR,GAAiB,CAApC,EAAuC;AAAG;AACxC,gBAAI,YAAJ,EAAkB;AAChB,oBAAM,OAAO,GAAG,KAAK,CAAC,QAAN,CAAe,IAAf,EAAqB,MAArB,EAA6B,SAA7B,CAAhB,CADgB,CAEhB;;AACA,mBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,sBAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;AACA,sBAAM,GAAG,GAAG,OAAO,CAAC,CAAD,CAAnB;AACA,gBAAA,GAAG,CAAC,IAAJ,CAAS,GAAT,EAHyC,CAIzC;;AACA,gBAAA,SAAS,CAAC,SAAS,KAAV,CAAT,GAA4B,GAA5B;AACD;AACF;AACF;AACF,SAlCD;AAoCA,cAAM,YAAY,CAAC,UAAb,CAAwB,UAAxB,EAAoC,SAApC,CAAN;AACA,QAAA,oBAAoB,CAAC,SAAD,CAApB;;AAEA,YAAI,KAAK,CAAC,aAAV,EAAyB;AACvB;AACD,SA7CiE,CA8ClE;;AACD;;AAED,MAAA,iBAAiB,CAAC,OAAlB;AACD,KAnEqD,CAoEtD;;;AACA,UAAM,YAAY,CAAC,UAAb,CAAwB,KAAxB,EAA+B,SAA/B,CAAN;;AACA,QAAI,KAAK,CAAC,aAAV,EAAyB;AACvB;AACD;AACF;;AACD,QAAM,YAAY,CAAC,UAAb,EAAN;AAEA,QAAM,KAAK,CAAC,OAAN,CAAc,QAAd,EAAN;AACA,SAAO,KAAK,CAAC,OAAb;AACD;;AAED,OAAO,eAAe,UAAf,EACH;AACA;AACA,KAHG,EAGS,CAHT,EAIH,CAJG,EAKH,IAAA,GAAqB,EALlB,EAKoB;AACzB,MAAI,KAAK,CAAC,UAAV,EAAsB;AACpB,UAAM,IAAI,KAAJ,CACF,8DADE,CAAN;AAED;;AACD,EAAA,KAAK,CAAC,UAAN,GAAmB,IAAnB;AACA,MAAI,MAAJ;AACA,MAAI,OAAJ;AACA,MAAI,SAAJ;AACA,MAAI,SAAJ;AACA,MAAI,IAAJ;AACA,MAAI,IAAJ;AACA,MAAI,aAAJ;;AACA,MAAI;AACF,UAAM,SAAS,GAAG,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAArD;AACA,IAAA,cAAc,CAAC,SAAD,CAAd,CAFE,CAIF;AACA;;AACA,UAAM,cAAc,GAAG,KAAvB;AACA,UAAM,gBAAgB,GAClB,MAAM,KAAK,CAAC,mBAAN,CACF,CADE,EACC,CADD,EACI,IAAI,CAAC,YADT,EACuB,IAAI,CAAC,WAD5B,EACyC,cADzC,EAEF,SAFE,CADV;AAIA,IAAA,MAAM,GAAG,gBAAgB,CAAC,CAAD,CAAzB;AACA,IAAA,OAAO,GAAG,gBAAgB,CAAC,CAAD,CAA1B;AACA,IAAA,aAAa,GAAG,gBAAgB,CAAC,CAAD,CAAhC,CAbE,CAeF;;AACA,QAAI,YAAY,GAAG,KAAnB;AACA,QAAI,MAAJ;;AACA,QAAI,IAAI,CAAC,cAAL,IAAuB,IAAvB,IAA+B,IAAI,CAAC,cAAL,CAAoB,MAApB,GAA6B,CAAhE,EAAmE;AACjE,MAAA,YAAY,GAAG,IAAf;;AACA,UAAI,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CAAnC,EAAsC;AACpC;AACA,QAAA,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;AACA,QAAA,SAAS,GAAG,IAAI,CAAC,cAAL,CAAoB,CAApB,CAAZ;AACD,OAJD,MAIO,IAAI,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CAAnC,EAAsC;AAC3C,cAAM,IAAI,mBAAJ,CACF,+DADE,CAAN;AAED,OAHM,MAGA;AACL,cAAM,IAAI,UAAJ,CACF,+DAAA,GACA,4CADA,GAEA,GAAG,IAAI,CAAC,cAAc,cAHpB,CAAN;AAID;;AAED,YAAM,cAAc,GAAG,IAAvB;AACA,YAAM,eAAe,GACjB,MAAM,KAAK,CAAC,mBAAN,CACF,SADE,EACS,SADT,EACoB,IADpB;AAC0B;AAC5B,UAFE;AAE0B;AAC5B,MAAA,cAHE,EAGc,SAHd,CADV;AAKA,MAAA,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;AACA,MAAA,IAAI,GAAG,eAAe,CAAC,CAAD,CAAtB;AACA,MAAA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT,CAxBiE,CAyBjE;AACD,KA1BD,MA0BO,IACH,IAAI,CAAC,eAAL,IAAwB,IAAxB,IAAgC,IAAI,CAAC,eAAL,GAAuB,CAAvD,IACA,IAAI,CAAC,eAAL,GAAuB,CAFpB,EAEuB;AAC5B,MAAA,YAAY,GAAG,IAAf,CAD4B,CAE5B;;AACA,YAAM,OAAO,GACT,IAAI,CAAC,KAAL,CAAW,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,KAAsB,IAAI,IAAI,CAAC,eAA/B,CAAX,CADJ;AAEA,YAAM,iBAAiB,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,CAA1B;AACA,MAAA,IAAI,GAAG,WAAW,CAAC,MAAD,EAAS,OAAT,EAAkB,iBAAlB,CAAlB;AACA,MAAA,MAAM,GAAG,WAAW,CAAC,MAAD,EAAS,CAAT,EAAY,OAAZ,CAApB;AACA,MAAA,IAAI,GAAG,WAAW,CAAC,OAAD,EAAU,OAAV,EAAmB,iBAAnB,CAAlB;AACA,MAAA,OAAO,GAAG,WAAW,CAAC,OAAD,EAAU,CAAV,EAAa,OAAb,CAArB,CAT4B,CAU5B;AACA;;AACA,MAAA,MAAM,GAAG,IAAI,CAAC,MAAL,CAAY,IAAZ,CAAT,CAZ4B,CAc5B;AACD,KAjBM,MAiBA,IAAI,IAAI,CAAC,eAAL,IAAwB,IAA5B,EAAkC;AACvC,MAAA,YAAY,GAAG,IAAf,CADuC,CAEvC;AACD;;AAED,UAAM,GAAG,GAAG,MAAM,CAAC,MAAP,CAAc,OAAd,EAAuB,MAAvB,CAA8B,aAA9B,CAAZ;AAEA,IAAA,KAAK,CAAC,gCAAN,GApEE,CAsEF;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAM,aAAa,GAAG,KAAK,CAAC,iBAAN,EAAtB;AACA,UAAM,SAAS,GAAG,KAAK,CAAC,sBAAN,EAAlB;AAEA,QAAI,WAAJ;AACA,QAAI,eAAJ;;AACA,QAAI,YAAJ,EAAkB;AAChB,MAAA,KAAK,CAAC,gBAAN;AACA,MAAA,WAAW,GAAG,KAAK,CAAC,YAApB;AACA,MAAA,eAAe,GACX,SAAS,CAAC,KAAV,GAAkB,MAAlB,CAAyB,SAAS,CAAC,GAAV,CAAc,CAAC,IAAI,SAAS,CAA5B,CAAzB,CADJ;AAED,KALD,MAKO;AACL,MAAA,WAAW,GAAG,IAAd;AACA,MAAA,MAAM,GAAG,EAAT;AACA,MAAA,eAAe,GAAG,SAAS,CAAC,KAAV,EAAlB;AACD;;AAED,UAAM,SAAS,GAAG,oBAAoB,CAAC,IAAI,CAAC,SAAN,EAAiB,IAAI,CAAC,UAAtB,CAAtC;AACA,UAAM,GAAG,GAAG,MAAM,OAAO,CACrB,KADqB,EACd,aADc,EACC,GADD,EACM,SADN,EACiB,SADjB,EAC4B,IAAI,CAAC,MADjC,EAErB,IAAI,CAAC,OAFgB,EAEP,SAFO,EAEI,WAFJ,EAEiB,MAFjB,EAEyB,IAAI,CAAC,OAF9B,EAGrB,eAHqB,EAGJ,IAAI,CAAC,YAHD,EAGe,IAHf,EAGqB,IAHrB,CAAzB;AAIA,WAAO,GAAP;AACD,GAxGD,SAwGU;AACR,IAAA,KAAK,CAAC,UAAN,GAAmB,KAAnB,CADQ,CAER;;AACA,IAAA,iBAAiB,CAAC,MAAD,EAAS,CAAT,CAAjB;AACA,IAAA,iBAAiB,CAAC,OAAD,EAAU,CAAV,CAAjB;AACA,IAAA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;AACA,IAAA,iBAAiB,CAAC,IAAD,EAAmB,SAAnB,CAAjB;;AACA,QAAI,aAAa,IAAI,IAArB,EAA2B;AACzB,MAAA,GAAG,CAAC,OAAJ,CAAY,aAAZ;AACD;AACF,GA/HwB,CAgIzB;;AACD;AAED;;;;;AAKG;;AACH,OAAM,SAAU,0BAAV,CAAqC,OAArC,EAA6D;AACjE,QAAM,IAAI,GAAa,EAAvB;;AACA,MAAI,OAAO,YAAY,MAAvB,EAA+B;AAC7B,IAAA,OAAO,GAAG,CAAC,OAAD,CAAV;AACD,GAJgE,CAMjE;;;AACA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;AACvC,UAAM,MAAM,GAAG,OAAO,CAAC,CAAD,CAAtB;;AACA,QAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;AACrB,MAAA,IAAI,CAAC,IAAL,CAAU,UAAU,CAAC,MAAD,EAAS,CAAT,CAApB;AACD,KAFD,MAEO,IAAI,MAAM,CAAC,IAAP,KAAgB,CAApB,EAAuB;AAC5B,YAAM,IAAI,KAAJ,CACF,iEACA,WAFE,CAAN;AAGD,KAJM,MAIA;AACL,MAAA,IAAI,CAAC,IAAL,CAAU,MAAV;AACD;AACF;;AACD,SAAO,IAAP;AACD;AAED;;;;;;;;;;AAUG;AACH;;AACA,OAAM,SAAU,iBAAV,CACF,OADE,EAEF,UAFE,EAEuD;AAC3D,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB;AACD;;AACD,QAAM,YAAY,GAAa,EAA/B;;AACA,MAAI,UAAU,YAAY,MAA1B,EAAkC;AAChC,IAAA,YAAY,CAAC,IAAb,CAAkB,UAAU,CAAC,EAA7B;AACD,GAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,UAAd,CAAJ,EAA+B;AACpC,IAAA,UAAU,CAAC,OAAX,CAAmB,CAAC,IAAI,YAAY,CAAC,IAAb,CAAkB,CAAC,CAAC,EAApB,CAAxB;AACD,GAFM,MAEA,IAAI,UAAU,IAAI,IAAlB,EAAwB;AAC7B;AACA,SAAK,MAAM,IAAX,IAAmB,UAAnB,EAA+B;AAC7B,YAAM,SAAS,GAAG,UAAU,CAAC,IAAD,CAA5B;AACA,MAAA,YAAY,CAAC,IAAb,CAAkB,SAAS,CAAC,EAA5B;AACD;AACF;;AAED,QAAM,gBAAgB,GAAa,EAAnC;;AACA,MAAI,OAAO,YAAY,MAAvB,EAA+B;AAC7B,QAAI,YAAY,CAAC,OAAb,CAAqB,OAAO,CAAC,EAA7B,MAAqC,CAAC,CAA1C,EAA6C;AAC3C,MAAA,gBAAgB,CAAC,IAAjB,CAAsB,OAAtB;AACD;AACF,GAJD,MAIO,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,CAAJ,EAA4B;AACjC,IAAA,OAAO,CAAC,OAAR,CAAgB,CAAC,IAAG;AAClB,UAAI,YAAY,CAAC,OAAb,CAAqB,CAAC,CAAC,EAAvB,MAA+B,CAAC,CAApC,EAAuC;AACrC,QAAA,gBAAgB,CAAC,IAAjB,CAAsB,CAAtB;AACD;AACF,KAJD;AAKD,GANM,MAMA,IAAI,OAAO,IAAI,IAAf,EAAqB;AAC1B;AACA,SAAK,MAAM,IAAX,IAAmB,OAAnB,EAA4B;AAC1B,YAAM,MAAM,GAAG,OAAO,CAAC,IAAD,CAAtB;;AACA,UAAI,YAAY,CAAC,OAAb,CAAqB,MAAM,CAAC,EAA5B,MAAoC,CAAC,CAAzC,EAA4C;AAC1C,QAAA,gBAAgB,CAAC,IAAjB,CAAsB,MAAtB;AACD;AACF;AACF;;AAED,EAAA,gBAAgB,CAAC,OAAjB,CAAyB,CAAC,IAAG;AAC3B,QAAI,CAAC,CAAC,CAAC,UAAP,EAAmB;AACjB,MAAA,CAAC,CAAC,OAAF;AACD;AACF,GAJD;AAKD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n    }\n    else { // Tensor.\n        return sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(() => {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(array => sliceArraysByIndices(array, indices));\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n    const output = [];\n    let batchStart = 0;\n    let batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n        batchSize = 32;\n    }\n    if (epochs == null) {\n        epochs = 1;\n    }\n    if (shuffle == null) {\n        shuffle = true;\n    }\n    if (initialEpoch == null) {\n        initialEpoch = 0;\n    }\n    // TODO(cais): Change const to let below when implementing validation.\n    let doValidation = false;\n    if (valF != null && valIns != null) {\n        doValidation = true;\n        // TODO(cais): verbose message.\n    }\n    if (validationSteps != null) {\n        doValidation = true;\n        if (stepsPerEpoch == null) {\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                'i.e., `stepsPerEpoch` must be set.');\n        }\n    }\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n    if (numTrainSamples != null) {\n        indexArray = range(0, numTrainSamples);\n    }\n    if (verbose == null) {\n        verbose = 1;\n    }\n    const { callbackList, history } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n        await callbackList.onEpochBegin(epoch);\n        const epochLogs = {};\n        if (stepsPerEpoch != null) {\n            throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n        }\n        else {\n            if (shuffle === 'batch') {\n                throw new NotImplementedError('batch shuffling is not implemneted yet');\n            }\n            else if (shuffle) {\n                util.shuffle(indexArray);\n            }\n            // Convert the potentially shuffled indices to Tensor1D, to avoid the\n            // cost of repeated creation of Array1Ds later on.\n            const epochIndexArray1D = tensor1d(indexArray);\n            const batches = makeBatches(numTrainSamples, batchSize);\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchLogs = {};\n                await callbackList.onBatchBegin(batchIndex, batchLogs);\n                tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = batchEnd - batchStart;\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const outs = f(insBatch);\n                    for (let i = 0; i < outLabels.length; ++i) {\n                        const label = outLabels[i];\n                        const out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                        // TODO(cais): Use scope() to avoid ownership.\n                    }\n                    if (batchIndex === batches.length - 1) { // Last batch.\n                        if (doValidation) {\n                            const valOuts = model.testLoop(valF, valIns, batchSize);\n                            // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                            for (let i = 0; i < outLabels.length; ++i) {\n                                const label = outLabels[i];\n                                const out = valOuts[i];\n                                tfc.keep(out);\n                                // TODO(cais): Use scope() to avoid ownership.\n                                epochLogs['val_' + label] = out;\n                            }\n                        }\n                    }\n                });\n                await callbackList.onBatchEnd(batchIndex, batchLogs);\n                disposeTensorsInLogs(batchLogs);\n                if (model.stopTraining_) {\n                    break;\n                }\n                // TODO(cais): return outs as list of Tensor.\n            }\n            epochIndexArray1D.dispose();\n        }\n        // TODO(cais): Run validation at the end of the epoch.\n        await callbackList.onEpochEnd(epoch, epochLogs);\n        if (model.stopTraining_) {\n            break;\n        }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n    if (model.isTraining) {\n        throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n    try {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // Validate user data.\n        // TODO(cais): Support sampleWeight.\n        const checkBatchAxis = false;\n        const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        sampleWeights = standardizedOuts[2];\n        // Prepare validation data.\n        let doValidation = false;\n        let valIns;\n        if (args.validationData != null && args.validationData.length > 0) {\n            doValidation = true;\n            if (args.validationData.length === 2) {\n                // config.validationData consists of valX and valY.\n                inputValX = args.validationData[0];\n                inputValY = args.validationData[1];\n            }\n            else if (args.validationData.length === 3) {\n                throw new NotImplementedError('validationData including sample weights is not supported yet.');\n            }\n            else {\n                throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` +\n                    `or 3 (valX, valY, valSampleWeight) items; ` +\n                    `${args.validationData} is invalid.`);\n            }\n            const checkBatchAxis = true;\n            const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis, batchSize);\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSplit != null && args.validationSplit > 0 &&\n            args.validationSplit < 1) {\n            doValidation = true;\n            // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            const originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            // TODO(cais): Once sampleWeights becomes available, slice it to get\n            //   valSampleWeights.\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSteps != null) {\n            doValidation = true;\n            // TODO(cais): Add useLearningPhase.\n        }\n        const ins = inputs.concat(targets).concat(sampleWeights);\n        model.checkTrainableWeightsConsistency();\n        // TODO(cais): Handle use_learning_phase and learning_phase?\n        // Porting Note: Here we see a key deviation of tfjs-layers from\n        // Keras.\n        //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n        //  we do not construct symbolic computation graphs to embody the\n        //  training process. Instead, we define a function that performs the\n        //  training action. In PyKeras, the data (inputs and targets) are fed\n        //  through graph placeholders. In tfjs-layers, the data are fed as\n        //  function arguments. Since the function are defined below in the\n        //  scope, we don't have equivalents of PyKeras's\n        //  `_make_train_funciton`.\n        const trainFunction = model.makeTrainFunction();\n        const outLabels = model.getDedupedMetricsNames();\n        let valFunction;\n        let callbackMetrics;\n        if (doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics =\n                outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n        }\n        else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n        }\n        const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n        const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n        return out;\n    }\n    finally {\n        model.isTraining = false;\n        // Memory clean up.\n        disposeNewTensors(inputs, x);\n        disposeNewTensors(targets, y);\n        disposeNewTensors(valX, inputValX);\n        disposeNewTensors(valY, inputValY);\n        if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n        }\n    }\n    // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n    const outs = [];\n    if (tensors instanceof Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (let i = 0; i < tensors.length; ++i) {\n        const tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    const oldTensorIds = [];\n    if (refTensors instanceof Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(t => oldTensorIds.push(t.id));\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in refTensors) {\n            const oldTensor = refTensors[name];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    const tensorsToDispose = [];\n    if (tensors instanceof Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(t => {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in tensors) {\n            const tensor = tensors[name];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(t => {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\n//# sourceMappingURL=training_tensors.js.map"]},"metadata":{},"sourceType":"module"}