{"ast":null,"code":"import _regeneratorRuntime from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\n\nexport var FileChunkIterator = /*#__PURE__*/function (_ByteChunkIterator) {\n  _inherits(FileChunkIterator, _ByteChunkIterator);\n\n  var _super = _createSuper(FileChunkIterator);\n\n  function FileChunkIterator(file) {\n    var _this;\n\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, FileChunkIterator);\n\n    _this = _super.call(this);\n    _this.file = file;\n    _this.options = options;\n    util.assert(file instanceof Uint8Array || (env().get('IS_BROWSER') ? file instanceof File || file instanceof Blob : false), function () {\n      return 'FileChunkIterator only supports File, Blob and Uint8Array ' + 'right now.';\n    });\n    _this.offset = options.offset || 0; // default 1MB chunk has tolerable perf on large files\n\n    _this.chunkSize = options.chunkSize || 1024 * 1024;\n    return _this;\n  }\n\n  _createClass(FileChunkIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"FileChunks \".concat(this.file);\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this2 = this;\n\n        var chunk;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size))) {\n                  _context.next = 2;\n                  break;\n                }\n\n                return _context.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 2:\n                chunk = new Promise(function (resolve, reject) {\n                  var end = _this2.offset + _this2.chunkSize;\n\n                  if (_this2.file instanceof Uint8Array) {\n                    // Note if end > this.uint8Array.byteLength, we just get a small last\n                    // chunk.\n                    resolve(new Uint8Array(_this2.file.slice(_this2.offset, end)));\n                  } else {\n                    // This branch assumes that this.file type is File or Blob, which\n                    // means it is in the browser environment.\n                    // TODO(soergel): is this a performance issue?\n                    var fileReader = new FileReader();\n\n                    fileReader.onload = function (event) {\n                      var data = fileReader.result; // Not sure we can trust the return type of\n                      // FileReader.readAsArrayBuffer See e.g.\n                      // https://github.com/node-file-api/FileReader/issues/2\n\n                      if (data instanceof ArrayBuffer) {\n                        data = new Uint8Array(data);\n                      }\n\n                      if (!(data instanceof Uint8Array)) {\n                        return reject(new TypeError('FileReader returned unknown type.'));\n                      }\n\n                      resolve(data);\n                    };\n\n                    fileReader.onabort = function (event) {\n                      return reject(new Error('Aborted'));\n                    };\n\n                    fileReader.onerror = function (event) {\n                      return reject(new Error(event.type));\n                    }; // TODO(soergel): better handle onabort, onerror\n                    // Note if end > this.file.size, we just get a small last chunk.\n\n\n                    var slice = _this2.file.slice(_this2.offset, end); // We can't use readAsText here (even if we know the file is text)\n                    // because the slice boundary may fall within a multi-byte character.\n\n\n                    fileReader.readAsArrayBuffer(slice);\n                  }\n\n                  _this2.offset = end;\n                });\n                _context.next = 5;\n                return chunk;\n\n              case 5:\n                _context.t0 = _context.sent;\n                return _context.abrupt(\"return\", {\n                  value: _context.t0,\n                  done: false\n                });\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function next() {\n        return _next.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return FileChunkIterator;\n}(ByteChunkIterator);","map":{"version":3,"sources":["../../src/iterators/file_chunk_iterator.ts"],"names":[],"mappings":";;;;;;;AAAA;;;;;;;;;;;;;;;;AAgBG;AAEH;AACA,SAAQ,GAAR,EAAa,IAAb,QAAwB,uBAAxB;AAEA,SAAQ,iBAAR,QAAgC,uBAAhC;AASA;;;;;;AAMG;;AACH,WAAa,iBAAb;AAAA;;AAAA;;AAIE,6BACc,IADd,EAEoD;AAAA;;AAAA,QAAtC,OAAsC,uEAAF,EAAE;;AAAA;;AAClD;AAFY,UAAA,IAAA,GAAA,IAAA;AACA,UAAA,OAAA,GAAA,OAAA;AAEZ,IAAA,IAAI,CAAC,MAAL,CACK,IAAI,YAAY,UAAjB,KACK,GAAG,GAAG,GAAN,CAAU,YAAV,IACK,IAAI,YAAY,IAAhB,IAAwB,IAAI,YAAY,IAD7C,GAEI,KAHT,CADJ,EAKI;AAAA,aAAM,+DACF,YADJ;AAAA,KALJ;AAOA,UAAK,MAAL,GAAc,OAAO,CAAC,MAAR,IAAkB,CAAhC,CATkD,CAUlD;;AACA,UAAK,SAAL,GAAiB,OAAO,CAAC,SAAR,IAAqB,OAAO,IAA7C;AAXkD;AAYnD;;AAlBH;AAAA;AAAA,WAoBE,mBAAO;AACL,kCAAqB,KAAK,IAA1B;AACD;AAtBH;AAAA;AAAA;AAAA,2EAwBE;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBACM,KAAK,MAAL,KAAiB,KAAK,IAAL,YAAqB,UAAtB,GACI,KAAK,IAAL,CAAU,UADd,GAEI,KAAK,IAAL,CAAU,IAF9B,CADN;AAAA;AAAA;AAAA;;AAAA,iDAIW;AAAC,kBAAA,KAAK,EAAE,IAAR;AAAc,kBAAA,IAAI,EAAE;AAApB,iBAJX;;AAAA;AAMQ,gBAAA,KANR,GAMgB,IAAI,OAAJ,CAAwB,UAAC,OAAD,EAAU,MAAV,EAAoB;AACxD,sBAAM,GAAG,GAAG,MAAI,CAAC,MAAL,GAAc,MAAI,CAAC,SAA/B;;AACA,sBAAI,MAAI,CAAC,IAAL,YAAqB,UAAzB,EAAqC;AACnC;AACA;AACA,oBAAA,OAAO,CAAC,IAAI,UAAJ,CAAe,MAAI,CAAC,IAAL,CAAU,KAAV,CAAgB,MAAI,CAAC,MAArB,EAA6B,GAA7B,CAAf,CAAD,CAAP;AACD,mBAJD,MAIO;AACL;AACA;AAEA;AACA,wBAAM,UAAU,GAAG,IAAI,UAAJ,EAAnB;;AACA,oBAAA,UAAU,CAAC,MAAX,GAAoB,UAAC,KAAD,EAAU;AAC5B,0BAAI,IAAI,GAAkC,UAAU,CAAC,MAArD,CAD4B,CAE5B;AACA;AACA;;AACA,0BAAI,IAAI,YAAY,WAApB,EAAiC;AAC/B,wBAAA,IAAI,GAAG,IAAI,UAAJ,CAAe,IAAf,CAAP;AACD;;AACD,0BAAI,EAAE,IAAI,YAAY,UAAlB,CAAJ,EAAmC;AACjC,+BAAO,MAAM,CAAC,IAAI,SAAJ,CAAc,mCAAd,CAAD,CAAb;AACD;;AACD,sBAAA,OAAO,CAAC,IAAD,CAAP;AACD,qBAZD;;AAaA,oBAAA,UAAU,CAAC,OAAX,GAAqB,UAAC,KAAD,EAAU;AAC7B,6BAAO,MAAM,CAAC,IAAI,KAAJ,CAAU,SAAV,CAAD,CAAb;AACD,qBAFD;;AAGA,oBAAA,UAAU,CAAC,OAAX,GAAqB,UAAC,KAAD,EAAU;AAC7B,6BAAO,MAAM,CAAC,IAAI,KAAJ,CAAU,KAAK,CAAC,IAAhB,CAAD,CAAb;AACD,qBAFD,CAtBK,CAyBL;AACA;;;AACA,wBAAM,KAAK,GAAG,MAAI,CAAC,IAAL,CAAU,KAAV,CAAgB,MAAI,CAAC,MAArB,EAA6B,GAA7B,CAAd,CA3BK,CA4BL;AACA;;;AACA,oBAAA,UAAU,CAAC,iBAAX,CAA6B,KAA7B;AACD;;AACD,kBAAA,MAAI,CAAC,MAAL,GAAc,GAAd;AACD,iBAvCa,CANhB;AAAA;AAAA,uBA8CwB,KA9CxB;;AAAA;AAAA;AAAA;AA8CU,kBAAA,KA9CV;AA8CgC,kBAAA,IA9ChC,EA8CsC;AA9CtC;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAxBF;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA,EAAuC,iBAAvC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\nexport class FileChunkIterator extends ByteChunkIterator {\n    constructor(file, options = {}) {\n        super();\n        this.file = file;\n        this.options = options;\n        util.assert((file instanceof Uint8Array) ||\n            (env().get('IS_BROWSER') ?\n                (file instanceof File || file instanceof Blob) :\n                false), () => 'FileChunkIterator only supports File, Blob and Uint8Array ' +\n            'right now.');\n        this.offset = options.offset || 0;\n        // default 1MB chunk has tolerable perf on large files\n        this.chunkSize = options.chunkSize || 1024 * 1024;\n    }\n    summary() {\n        return `FileChunks ${this.file}`;\n    }\n    async next() {\n        if (this.offset >= ((this.file instanceof Uint8Array) ?\n            this.file.byteLength :\n            this.file.size)) {\n            return { value: null, done: true };\n        }\n        const chunk = new Promise((resolve, reject) => {\n            const end = this.offset + this.chunkSize;\n            if (this.file instanceof Uint8Array) {\n                // Note if end > this.uint8Array.byteLength, we just get a small last\n                // chunk.\n                resolve(new Uint8Array(this.file.slice(this.offset, end)));\n            }\n            else {\n                // This branch assumes that this.file type is File or Blob, which\n                // means it is in the browser environment.\n                // TODO(soergel): is this a performance issue?\n                const fileReader = new FileReader();\n                fileReader.onload = (event) => {\n                    let data = fileReader.result;\n                    // Not sure we can trust the return type of\n                    // FileReader.readAsArrayBuffer See e.g.\n                    // https://github.com/node-file-api/FileReader/issues/2\n                    if (data instanceof ArrayBuffer) {\n                        data = new Uint8Array(data);\n                    }\n                    if (!(data instanceof Uint8Array)) {\n                        return reject(new TypeError('FileReader returned unknown type.'));\n                    }\n                    resolve(data);\n                };\n                fileReader.onabort = (event) => {\n                    return reject(new Error('Aborted'));\n                };\n                fileReader.onerror = (event) => {\n                    return reject(new Error(event.type));\n                };\n                // TODO(soergel): better handle onabort, onerror\n                // Note if end > this.file.size, we just get a small last chunk.\n                const slice = this.file.slice(this.offset, end);\n                // We can't use readAsText here (even if we know the file is text)\n                // because the slice boundary may fall within a multi-byte character.\n                fileReader.readAsArrayBuffer(slice);\n            }\n            this.offset = end;\n        });\n        return { value: (await chunk), done: false };\n    }\n}\n//# sourceMappingURL=file_chunk_iterator.js.map"]},"metadata":{},"sourceType":"module"}