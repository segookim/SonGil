{"ast":null,"code":"import _slicedToArray from \"/Users/kimkiwoong/songil2/SonGil/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport var CHECK_NAN_SNIPPET_UNARY = \"if (isnan(x)) return x;\";\nexport var CHECK_NAN_SNIPPET_BINARY = \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\";\nexport var CHECK_NAN_SNIPPET_BINARY_PACKED = \"\\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\";\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function unaryKernelFunc(_ref) {\n  var opSnippet = _ref.opSnippet,\n      packedOpSnippet = _ref.packedOpSnippet,\n      cpuKernelImpl = _ref.cpuKernelImpl,\n      dtype = _ref.dtype;\n  return function (_ref2) {\n    var inputs = _ref2.inputs,\n        backend = _ref2.backend;\n    var x = inputs.x;\n    var webglBackend = backend;\n    var $dtype = dtype || x.dtype;\n\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      var xData = webglBackend.texData.get(x.dataId);\n      var outValues = cpuKernelImpl(xData.values, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    var shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    var program;\n\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function binaryKernelFunc(_ref3) {\n  var opSnippet = _ref3.opSnippet,\n      packedOpSnippet = _ref3.packedOpSnippet,\n      _ref3$checkOutOfBound = _ref3.checkOutOfBounds,\n      checkOutOfBounds = _ref3$checkOutOfBound === void 0 ? false : _ref3$checkOutOfBound,\n      _ref3$supportsComplex = _ref3.supportsComplex,\n      supportsComplex = _ref3$supportsComplex === void 0 ? false : _ref3$supportsComplex,\n      cpuKernelImpl = _ref3.cpuKernelImpl,\n      dtype = _ref3.dtype;\n  return function (_ref4) {\n    var inputs = _ref4.inputs,\n        backend = _ref4.backend;\n    var a = inputs.a,\n        b = inputs.b;\n    var webglBackend = backend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      var aData = webglBackend.texData.get(a.dataId);\n      var bData = webglBackend.texData.get(b.dataId);\n\n      var _map = [[aData.complexTensorInfos.real, bData.complexTensorInfos.real], [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]].map(function (complexParts) {\n        var _complexParts = _slicedToArray(complexParts, 2),\n            aPart = _complexParts[0],\n            bPart = _complexParts[1];\n\n        var aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        var bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n        var program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      }),\n          _map2 = _slicedToArray(_map, 2),\n          real = _map2[0],\n          imag = _map2[1];\n\n      var complexOutput = complex({\n        inputs: {\n          real: real,\n          imag: imag\n        },\n        backend: webglBackend\n      });\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag); // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    var $dtype = dtype || upcastType(a.dtype, b.dtype);\n\n    if (webglBackend.shouldExecuteOnCPU([a, b]) && cpuKernelImpl != null) {\n      var _aData = webglBackend.texData.get(a.dataId);\n\n      var _bData = webglBackend.texData.get(b.dataId);\n\n      var _cpuKernelImpl = cpuKernelImpl(a.shape, b.shape, _aData.values, _bData.values, $dtype),\n          _cpuKernelImpl2 = _slicedToArray(_cpuKernelImpl, 2),\n          outValues = _cpuKernelImpl2[0],\n          outShape = _cpuKernelImpl2[1];\n\n      var out = webglBackend.makeTensorInfo(outShape, $dtype);\n      var outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n\n    var shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') && packedOpSnippet != null;\n    var program;\n\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\nexport function mapActivationToShaderProgram(activation) {\n  var packed = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n\n    return LEAKYRELU;\n  }\n\n  throw new Error(\"Activation \".concat(activation, \" has not been implemented for the WebGL backend.\"));\n}","map":{"version":3,"sources":["../../src/kernel_utils/kernel_funcs_utils.ts"],"names":[],"mappings":";;AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAA8C,GAA9C,EAAwF,UAAxF,QAAyG,uBAAzG;AAGA,SAAQ,eAAR,QAA8B,iBAA9B;AACA,SAAQ,qBAAR,QAAoC,wBAApC;AACA,SAAQ,OAAR,QAAsB,oBAAtB;AACA,SAAQ,SAAR,EAAmB,gBAAnB,QAA0C,sBAA1C;AACA,SAAQ,KAAR,EAAe,YAAf,QAAkC,kBAAlC;AACA,OAAO,KAAK,QAAZ,MAA0B,gBAA1B;AACA,SAAQ,cAAR,QAA6B,gBAA7B;AACA,OAAO,KAAK,eAAZ,MAAiC,uBAAjC;AACA,SAAQ,oBAAR,QAAmC,uBAAnC;AAIA,OAAO,IAAM,uBAAuB,4BAA7B;AAEP,OAAO,IAAM,wBAAwB,6DAA9B;AAKP,OAAO,IAAM,+BAA+B,2LAArC;AAcP;;;;;;;AAOG;;AACH,OAAM,SAAU,eAAV,OACuE;AAAA,MAAxE,SAAwE,QAAxE,SAAwE;AAAA,MAA7D,eAA6D,QAA7D,eAA6D;AAAA,MAA5C,aAA4C,QAA5C,aAA4C;AAAA,MAA7B,KAA6B,QAA7B,KAA6B;AAE3E,SAAO,iBAAsB;AAAA,QAApB,MAAoB,SAApB,MAAoB;AAAA,QAAZ,OAAY,SAAZ,OAAY;AAAA,QACpB,CADoB,GACf,MADe,CACpB,CADoB;AAE3B,QAAM,YAAY,GAAG,OAArB;AAEA,QAAM,MAAM,GAAG,KAAK,IAAI,CAAC,CAAC,KAA1B;;AACA,QAAI,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,CAAhC,KAAwC,aAAa,IAAI,IAA7D,EAAmE;AACjE,UAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,UAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,MAAP,EAA6B,MAA7B,CAA/B;AACA,aAAO,YAAY,CAAC,cAAb,CAA4B,CAAC,CAAC,KAA9B,EAAqC,MAArC,EAA6C,SAA7C,CAAP;AACD;;AAED,QAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,6BAAd,KAAgD,eAAe,IAAI,IADvE;AAEA,QAAI,OAAJ;;AACA,QAAI,sBAAJ,EAA4B;AAC1B,MAAA,OAAO,GAAG,IAAI,oBAAJ,CAAyB,CAAC,CAAC,KAA3B,EAAkC,eAAlC,CAAV;AACD,KAFD,MAEO;AACL,MAAA,OAAO,GAAG,IAAI,cAAJ,CAAmB,CAAC,CAAC,KAArB,EAA4B,SAA5B,CAAV;AACD;;AAED,WAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,CAAtC,EAA2C,MAA3C,CAAP;AACD,GArBD;AAsBD;AAWD;;;;;;;;;AASG;;AACH,OAAM,SAAU,gBAAV,QAOmB;AAAA,MANvB,SAMuB,SANvB,SAMuB;AAAA,MALvB,eAKuB,SALvB,eAKuB;AAAA,oCAJvB,gBAIuB;AAAA,MAJvB,gBAIuB,sCAJJ,KAII;AAAA,oCAHvB,eAGuB;AAAA,MAHvB,eAGuB,sCAHL,KAGK;AAAA,MAFvB,aAEuB,SAFvB,aAEuB;AAAA,MADvB,KACuB,SADvB,KACuB;AACvB,SAAO,iBAAsB;AAAA,QAApB,MAAoB,SAApB,MAAoB;AAAA,QAAZ,OAAY,SAAZ,OAAY;AAAA,QACpB,CADoB,GACZ,MADY,CACpB,CADoB;AAAA,QACjB,CADiB,GACZ,MADY,CACjB,CADiB;AAE3B,QAAM,YAAY,GAAG,OAArB;;AAEA,QAAI,eAAe,IAAI,CAAC,CAAC,KAAF,KAAY,WAAnC,EAAgD;AAC9C,UAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;AACA,UAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;;AAF8C,iBAIzB,CACnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CADmB,EAEnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CAFmB,EAGnB,GAHmB,CAGf,UAAA,YAAY,EAAG;AAAA,2CACI,YADJ;AAAA,YACZ,KADY;AAAA,YACL,KADK;;AAGnB,YAAM,OAAO,GAAG;AACd,UAAA,MAAM,EAAE,KAAK,CAAC,MADA;AAEd,UAAA,KAAK,EAAE,KAAK,CAAC,KAFC;AAGd,UAAA,KAAK,EAAE,CAAC,CAAC;AAHK,SAAhB;AAKA,YAAM,OAAO,GAAG;AACd,UAAA,MAAM,EAAE,KAAK,CAAC,MADA;AAEd,UAAA,KAAK,EAAE,KAAK,CAAC,KAFC;AAGd,UAAA,KAAK,EAAE,CAAC,CAAC;AAHK,SAAhB;AAMA,YAAM,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAhB;AACA,eAAO,YAAY,CAAC,eAAb,CACH,OADG,EACM,CAAC,OAAD,EAAU,OAAV,CADN,EAC0B,UAAU,CAAC,KAAK,CAAC,KAAP,EAAc,KAAK,CAAC,KAApB,CADpC,CAAP;AAED,OApBoB,CAJyB;AAAA;AAAA,UAIvC,IAJuC;AAAA,UAIjC,IAJiC;;AA0B9C,UAAM,aAAa,GACf,OAAO,CAAC;AAAC,QAAA,MAAM,EAAE;AAAC,UAAA,IAAI,EAAJ,IAAD;AAAO,UAAA,IAAI,EAAJ;AAAP,SAAT;AAAuB,QAAA,OAAO,EAAE;AAAhC,OAAD,CADX;AAGA,MAAA,YAAY,CAAC,6BAAb,CAA2C,IAA3C;AACA,MAAA,YAAY,CAAC,6BAAb,CAA2C,IAA3C,EA9B8C,CAgC9C;;AAEA,aAAO,aAAP;AACD;;AAED,QAAM,MAAM,GAAG,KAAK,IAAI,UAAU,CAAC,CAAC,CAAC,KAAH,EAAU,CAAC,CAAC,KAAZ,CAAlC;;AACA,QAAI,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,EAAI,CAAJ,CAAhC,KAA2C,aAAa,IAAI,IAAhE,EAAsE;AACpE,UAAM,MAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;;AACA,UAAM,MAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;;AAFoE,2BAGtC,aAAa,CACvC,CAAC,CAAC,KADqC,EAC9B,CAAC,CAAC,KAD4B,EACrB,MAAK,CAAC,MADe,EAEvC,MAAK,CAAC,MAFiC,EAEX,MAFW,CAHyB;AAAA;AAAA,UAG7D,SAH6D;AAAA,UAGlD,QAHkD;;AAOpE,UAAM,GAAG,GAAG,YAAY,CAAC,cAAb,CAA4B,QAA5B,EAAsC,MAAtC,CAAZ;AACA,UAAM,OAAO,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,GAAG,CAAC,MAA7B,CAAhB;AACA,MAAA,OAAO,CAAC,MAAR,GAAiB,SAAjB;AACA,aAAO,GAAP;AACD;;AAED,QAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,8BAAd,KACA,eAAe,IAAI,IAFvB;AAGA,QAAI,OAAJ;;AACA,QAAI,sBAAJ,EAA4B;AAC1B,MAAA,OAAO,GAAG,IAAI,qBAAJ,CACN,eADM,EACW,CAAC,CAAC,KADb,EACoB,CAAC,CAAC,KADtB,EAC6B,gBAD7B,CAAV;AAED,KAHD,MAGO;AACL,MAAA,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAV;AACD;;AAED,WAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,EAAI,CAAJ,CAAtC,EAA8C,MAA9C,CAAP;AACD,GAnED;AAoED;AAED,OAAM,SAAU,4BAAV,CACF,UADE,EACiD;AAAA,MAAd,MAAc,uEAAL,KAAK;;AACrD,MAAI,UAAU,KAAK,QAAnB,EAA6B;AAC3B,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,MAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,MAAhB;AACD,GALD,MAKO,IAAI,UAAU,KAAK,MAAnB,EAA2B;AAChC,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,IAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,IAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,KAAnB,EAA0B;AAC/B,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,GAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,GAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;AACjC,QAAI,MAAJ,EAAY;AACV,aAAO,eAAe,CAAC,KAAvB;AACD;;AACD,WAAO,QAAQ,CAAC,KAAhB;AACD,GALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;AACjC,QAAI,MAAJ,EAAY;AACV,aAAO,YAAP;AACD;;AACD,WAAO,KAAP;AACD,GALM,MAKA,IAAI,UAAU,KAAK,WAAnB,EAAgC;AACrC,QAAI,MAAJ,EAAY;AACV,aAAO,gBAAP;AACD;;AACD,WAAO,SAAP;AACD;;AACD,QAAM,IAAI,KAAJ,sBACF,UADE,sDAAN;AAED","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc({ opSnippet, packedOpSnippet, cpuKernelImpl, dtype }) {\n    return ({ inputs, backend }) => {\n        const { x } = inputs;\n        const webglBackend = backend;\n        const $dtype = dtype || x.dtype;\n        if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n            const xData = webglBackend.texData.get(x.dataId);\n            const outValues = cpuKernelImpl(xData.values, $dtype);\n            return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n        }\n        const shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n        let program;\n        if (shouldUsePackedProgram) {\n            program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n        }\n        else {\n            program = new UnaryOpProgram(x.shape, opSnippet);\n        }\n        return webglBackend.runWebGLProgram(program, [x], $dtype);\n    };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc({ opSnippet, packedOpSnippet, checkOutOfBounds = false, supportsComplex = false, cpuKernelImpl, dtype }) {\n    return ({ inputs, backend }) => {\n        const { a, b } = inputs;\n        const webglBackend = backend;\n        if (supportsComplex && a.dtype === 'complex64') {\n            const aData = webglBackend.texData.get(a.dataId);\n            const bData = webglBackend.texData.get(b.dataId);\n            const [real, imag] = [\n                [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n                [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n            ].map(complexParts => {\n                const [aPart, bPart] = complexParts;\n                const aHandle = {\n                    dataId: aPart.dataId,\n                    dtype: aPart.dtype,\n                    shape: a.shape\n                };\n                const bHandle = {\n                    dataId: bPart.dataId,\n                    dtype: bPart.dtype,\n                    shape: b.shape\n                };\n                const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n                return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n            });\n            const complexOutput = complex({ inputs: { real, imag }, backend: webglBackend });\n            webglBackend.disposeIntermediateTensorInfo(real);\n            webglBackend.disposeIntermediateTensorInfo(imag);\n            // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n            return complexOutput;\n        }\n        const $dtype = dtype || upcastType(a.dtype, b.dtype);\n        if (webglBackend.shouldExecuteOnCPU([a, b]) && cpuKernelImpl != null) {\n            const aData = webglBackend.texData.get(a.dataId);\n            const bData = webglBackend.texData.get(b.dataId);\n            const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, aData.values, bData.values, $dtype);\n            const out = webglBackend.makeTensorInfo(outShape, $dtype);\n            const outData = webglBackend.texData.get(out.dataId);\n            outData.values = outValues;\n            return out;\n        }\n        const shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') &&\n            packedOpSnippet != null;\n        let program;\n        if (shouldUsePackedProgram) {\n            program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n        }\n        else {\n            program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        }\n        return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n    };\n}\nexport function mapActivationToShaderProgram(activation, packed = false) {\n    if (activation === 'linear') {\n        if (packed) {\n            return unary_packed_op.LINEAR;\n        }\n        return unary_op.LINEAR;\n    }\n    else if (activation === 'relu') {\n        if (packed) {\n            return unary_packed_op.RELU;\n        }\n        return unary_op.RELU;\n    }\n    else if (activation === 'elu') {\n        if (packed) {\n            return unary_packed_op.ELU;\n        }\n        return unary_op.ELU;\n    }\n    else if (activation === 'relu6') {\n        if (packed) {\n            return unary_packed_op.RELU6;\n        }\n        return unary_op.RELU6;\n    }\n    else if (activation === 'prelu') {\n        if (packed) {\n            return PRELU_PACKED;\n        }\n        return PRELU;\n    }\n    else if (activation === 'leakyrelu') {\n        if (packed) {\n            return LEAKYRELU_PACKED;\n        }\n        return LEAKYRELU;\n    }\n    throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);\n}\n//# sourceMappingURL=kernel_funcs_utils.js.map"]},"metadata":{},"sourceType":"module"}